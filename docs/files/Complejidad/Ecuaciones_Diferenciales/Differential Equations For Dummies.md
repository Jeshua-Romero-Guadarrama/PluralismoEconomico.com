






**Differential**

**Equations**

FOR

DUMmIES

‰

**by Steven Holzner, PhD**









**Differential**

**Equations**

FOR

DUMmIES

‰









**Differential**

**Equations**

FOR

DUMmIES

‰

**by Steven Holzner, PhD**





**Differential Equations For Dummies**

**®**

Published by

**Wiley Publishing, Inc.**

111 River St.

Hoboken, NJ 07030-5774

www.wiley.com

Copyright © 2008 by Wiley Publishing, Inc., Indianapolis, Indiana

Published simultaneously in Canada

No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form

or by any means, electronic, mechanical, photocopying, recording, scanning, or otherwise, except as per-

mitted under Sections 107 or 108 of the 1976 United States Copyright Act, without either the prior written

permission of the Publisher, or authorization through payment of the appropriate per-copy fee to the

Copyright Clearance Center, 222 Rosewood Drive, Danvers, MA 01923, 978-750-8400, fax 978-646-8600.

Requests to the Publisher for permission should be addressed to the Legal Department, Wiley Publishing,

Inc., 10475 Crosspoint Blvd., Indianapolis, IN 46256, 317-572-3447, fax 317-572-4355, or online at

http://www.wiley.com/go/permissions.

Trademarks: Wiley, the Wiley Publishing logo, For Dummies, the Dummies Man logo, A Reference for the

Rest of Us!, The Dummies Way, Dummies Daily, The Fun and Easy Way, Dummies.com and related trade

dress are trademarks or registered trademarks of John Wiley & Sons, Inc. and/or its affiliates in the United

States and other countries, and may not be used without written permission. All other trademarks are the

property of their respective owners. Wiley Publishing, Inc., is not associated with any product or vendor

mentioned in this book.

**LIMIT OF LIABILITY/DISCLAIMER OF WARRANTY: THE PUBLISHER AND THE AUTHOR MAKE NO REP-**

**RESENTATIONS OR WARRANTIES WITH RESPECT TO THE ACCURACY OR COMPLETENESS OF THE CON-**

**TENTS OF THIS WORK AND SPECIFICALLY DISCLAIM ALL WARRANTIES, INCLUDING WITHOUT**

**LIMITATION WARRANTIES OF FITNESS FOR A PARTICULAR PURPOSE. NO WARRANTY MAY BE CRE-**

**ATED OR EXTENDED BY SALES OR PROMOTIONAL MATERIALS. THE ADVICE AND STRATEGIES CON-**

**TAINED HEREIN MAY NOT BE SUITABLE FOR EVERY SITUATION. THIS WORK IS SOLD WITH THE**

**UNDERSTANDING THAT THE PUBLISHER IS NOT ENGAGED IN RENDERING LEGAL, ACCOUNTING, OR**

**OTHER PROFESSIONAL SERVICES. IF PROFESSIONAL ASSISTANCE IS REQUIRED, THE SERVICES OF A**

**COMPETENT PROFESSIONAL PERSON SHOULD BE SOUGHT. NEITHER THE PUBLISHER NOR THE**

**AUTHOR SHALL BE LIABLE FOR DAMAGES ARISING HEREFROM. THE FACT THAT AN ORGANIZATION**

**OR WEBSITE IS REFERRED TO IN THIS WORK AS A CITATION AND/OR A POTENTIAL SOURCE OF FUR-**

**THER INFORMATION DOES NOT MEAN THAT THE AUTHOR OR THE PUBLISHER ENDORSES THE INFOR-**

**MATION THE ORGANIZATION OR WEBSITE MAY PROVIDE OR RECOMMENDATIONS IT MAY MAKE.**

**FURTHER, READERS SHOULD BE AWARE THAT INTERNET WEBSITES LISTED IN THIS WORK MAY HAVE**

**CHANGED OR DISAPPEARED BETWEEN WHEN THIS WORK WAS WRITTEN AND WHEN IT IS READ.**

For general information on our other products and services, please contact our Customer Care

Department within the U.S. at 800-762-2974, outside the U.S. at 317-572-3993, or fax 317-572-4002.

For technical support, please visit www.wiley.com/techsupport.

Wiley also publishes its books in a variety of electronic formats. Some content that appears in print may

not be available in electronic books.

Library of Congress Control Number: 2008925781

ISBN: 978-0-470-17814-0

Manufactured in the United States of America

10

9 8 7 6 5 4 3 2 1





About the Author

**Steven Holzner** is an award-winning author of science, math, and technical

books. He got his training in differential equations at MIT and at Cornell

University, where he got his PhD. He has been on the faculty at both MIT and

Cornell University, and has written such bestsellers as Physics For Dummies

and Physics Workbook For Dummies.









Dedication

To Nancy, always and forever.

Author’s Acknowledgments

The book you hold in your hands is the work of many people. I’d especially

like to thank Tracy Boggier, Georgette Beatty, Jessica Smith, technical

reviewer Jamie Song, PhD, and the folks in Composition Services who put the

book together so beautifully.





**Publisher’s Acknowledgments**

We’re proud of this book; please send us your comments through our Dummies online registration

form located at www.dummies.com/register/.

Some of the people who helped bring this book to market include the following:

**Acquisitions, Editorial, and**

**Media Development**

**Composition Services**

**Project Coordinator:** Erin Smith

**Project Editor:** Georgette Beatty

**Acquisitions Editor:** Tracy Boggier

**Copy Editor:** Jessica Smith

**Layout and Graphics:** Carrie A. Cesavice,

Stephanie D. Jumper

**Proofreaders:** Caitie Kelly, Linda D. Morris

**Indexer:** Broccoli Information Management

**Editorial Program Coordinator:**

Erin Calligan Mooney

**Technical Editor:** Jamie Song, PhD

**Editorial Manager:** Michelle Hacker

**Editorial Assistants:** Joe Niesen, Leeann Harney

**Cartoons:** Rich Tennant

(www.the5thwave.com)

**Publishing and Editorial for Consumer Dummies**

**Diane Graves Steele,** Vice President and Publisher, Consumer Dummies

**Joyce Pepple,** Acquisitions Director, Consumer Dummies

**Kristin A. Cocks,** Product Development Director, Consumer Dummies

**Michael Spring,** Vice President and Publisher, Travel

**Kelly Regan,** Editorial Director, Travel

**Publishing for Technology Dummies**

**Andy Cummings,** Vice President and Publisher, Dummies Technology/General User

**Composition Services**

**Gerry Fahey,** Vice President of Production Services

**Debbie Stailey,** Director of Composition Services





**Contents at a Glance**

Introduction .................................................................1

Part I: Focusing on First Order Differential Equations......5

Chapter 1: Welcome to the World of Differential Equations .........................................7

Chapter 2: Looking at Linear First Order Differential Equations................................23

Chapter 3: Sorting Out Separable First Order Differential Equations........................41

Chapter 4: Exploring Exact First Order Differential Equations

and Euler’s Method........................................................................................................63

Part II: Surveying Second and Higher Order

Differential Equations.................................................89

Chapter 5: Examining Second Order Linear Homogeneous

Differential Equations....................................................................................................91

Chapter 6: Studying Second Order Linear Nonhomogeneous

Differential Equations..................................................................................................123

Chapter 7: Handling Higher Order Linear Homogeneous Differential

Equations ......................................................................................................................151

Chapter 8: Taking On Higher Order Linear Nonhomogeneous

Differential Equations..................................................................................................173

Part III: The Power Stuff: Advanced Techniques..........189

Chapter 9: Getting Serious with Power Series and Ordinary Points........................191

Chapter 10: Powering through Singular Points ..........................................................213

Chapter 11: Working with Laplace Transforms ..........................................................239

Chapter 12: Tackling Systems of First Order Linear Differential Equations ...........265

Chapter 13: Discovering Three Fail-Proof Numerical Methods................................293

Part IV: The Part of Tens ...........................................315

Chapter 14: Ten Super-Helpful Online Differential Equation Tutorials....................317

Chapter 15: Ten Really Cool Online Differential Equation Solving Tools ................321

Index .......................................................................325









**Tabl e of Contents**

Introduction..................................................................1

About This Book...............................................................................................1

Conventions Used in This Book .....................................................................1

What You’re Not to Read.................................................................................2

Foolish Assumptions .......................................................................................2

How This Book Is Organized...........................................................................2

Part I: Focusing on First Order Differential Equations.......................3

Part II: Surveying Second and Higher Order

Differential Equations.........................................................................3

Part III: The Power Stuff: Advanced Techniques ................................3

Part IV: The Part of Tens........................................................................3

Icons Used in This Book..................................................................................4

Where to Go from Here....................................................................................4

Part I: Focusing on First Order Differential Equations ......5

**Chapter 1: Welcome to the World of Differential Equations . . . . . . . . .7**

The Essence of Differential Equations...........................................................8

Derivatives: The Foundation of Differential Equations .............................11

Derivatives that are constants............................................................11

Derivatives that are powers................................................................12

Derivatives involving trigonometry...................................................12

Derivatives involving multiple functions ..........................................12

Seeing the Big Picture with Direction Fields...............................................13

Plotting a direction field......................................................................13

Connecting slopes into an integral curve .........................................14

Recognizing the equilibrium value.....................................................16

Classifying Differential Equations ................................................................17

Classifying equations by order...........................................................17

Classifying ordinary versus partial equations..................................17

Classifying linear versus nonlinear equations..................................18

Solving First Order Differential Equations ..................................................19

Tackling Second Order and Higher Order Differential Equations............20

Having Fun with Advanced Techniques......................................................21





xii

**Differential Equations For Dummies**

**Chapter 2: Looking at Linear First Order Differential Equations . . . . .23**

First Things First: The Basics of Solving Linear First Order

Differential Equations ................................................................................24

Applying initial conditions from the start.........................................24

Stepping up to solving differential

equations involving functions.........................................................25

Adding a couple of constants to the mix...........................................26

Solving Linear First Order Differential Equations

with Integrating Factors ............................................................................26

Solving for an integrating factor.........................................................27

Using an integrating factor to solve a differential equation ...........28

Moving on up: Using integrating factors in differential

equations with functions .................................................................29

Trying a special shortcut ....................................................................30

Solving an advanced example.............................................................32

Determining Whether a Solution for a Linear First Order

Equation Exists ...........................................................................................35

Spelling out the existence and uniqueness theorem

for linear differential equations ......................................................35

Finding the general solution ...............................................................36

Checking out some existence and uniqueness examples ...............37

Figuring Out Whether a Solution for a Nonlinear

Differential Equation Exists.......................................................................38

The existence and uniqueness theorem for

nonlinear differential equations......................................................39

A couple of nonlinear existence and uniqueness examples...........39

**Chapter 3: Sorting Out Separable First Order**

**Differential Equations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .41**

Beginning with the Basics of Separable Differential Equations ...............42

Starting easy: Linear separable equations........................................43

Introducing implicit solutions ............................................................43

Finding explicit solutions from implicit solutions ...........................45

Tough to crack: When you can’t find an explicit solution ..............48

A neat trick: Turning nonlinear separable equations into

linear separable equations..............................................................49

Trying Out Some Real World Separable Equations....................................52

Getting in control with a sample flow problem ................................52

Striking it rich with a sample monetary problem ............................55

Break It Up! Using Partial Fractions in Separable Equations....................59





xiii

**Table of Contents**

**Chapter 4: Exploring Exact First Order Differential**

**Equations and Euler’s Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .63**

Exploring the Basics of Exact Differential Equations ................................63

Defining exact differential equations.................................................64

Working out a typical exact differential equation ............................65

Determining Whether a Differential Equation Is Exact..............................66

Checking out a useful theorem...........................................................66

Applying the theorem ..........................................................................67

Conquering Nonexact Differential Equations

with Integrating Factors ............................................................................70

Finding an integrating factor...............................................................71

Using an integrating factor to get an exact equation.......................73

The finishing touch: Solving the exact equation..............................74

Getting Numerical with Euler’s Method ......................................................75

Understanding the method.................................................................76

Checking the method’s accuracy on a computer.............................77

Delving into Difference Equations................................................................83

Some handy terminology ....................................................................84

Iterative solutions ................................................................................84

Equilibrium solutions ..........................................................................85

Part II: Surveying Second and Higher Order

Differential Equations..................................................89

**Chapter 5: Examining Second Order Linear**

**Homogeneous Differential Equations . . . . . . . . . . . . . . . . . . . . . . . . . . .91**

The Basics of Second Order Differential Equations...................................91

Linear equations...................................................................................92

Homogeneous equations.....................................................................93

Second Order Linear Homogeneous Equations

with Constant Coefficients ........................................................................94

Elementary solutions...........................................................................94

Initial conditions...................................................................................95

Checking Out Characteristic Equations......................................................96

Real and distinct roots.........................................................................97

Complex roots.....................................................................................100

Identical real roots .............................................................................106

Getting a Second Solution by Reduction of Order...................................109

Seeing how reduction of order works..............................................110

Trying out an example.......................................................................111





xiv

**Differential Equations For Dummies**

Putting Everything Together with Some Handy Theorems ....................114

Superposition......................................................................................114

Linear independence .........................................................................115

The Wronskian....................................................................................117

**Chapter 6: Studying Second Order Linear Nonhomogeneous**

**Differential Equations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .123**

The General Solution of Second Order Linear

Nonhomogeneous Equations..................................................................124

Understanding an important theorem.............................................124

Putting the theorem to work.............................................................125

Finding Particular Solutions with the Method of

Undetermined Coefficients......................................................................127

When g(x) is in the form of erx ..........................................................127

When g(x) is a polynomial of order n ..............................................128

When g(x) is a combination of sines and cosines..........................131

When g(x) is a product of two different forms ...............................133

Breaking Down Equations with the Variation of Parameters Method ....135

Nailing down the basics of the method...........................................136

Solving a typical example..................................................................137

Applying the method to any linear equation..................................138

What a pair! The variation of parameters method

meets the Wronskian......................................................................142

Bouncing Around with Springs ’n’ Things ................................................143

A mass without friction .....................................................................144

A mass with drag force ......................................................................148

**Chapter 7: Handling Higher Order Linear Homogeneous**

**Differential Equations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .151**

The Write Stuff: The Notation of Higher Order

Differential Equations ..............................................................................152

Introducing the Basics of Higher Order Linear

Homogeneous Equations.........................................................................153

The format, solutions, and initial conditions .................................153

A couple of cool theorems ................................................................155

Tackling Different Types of Higher Order Linear

Homogeneous Equations.........................................................................156

Real and distinct roots.......................................................................156

Real and imaginary roots ..................................................................161

Complex roots.....................................................................................164

Duplicate roots ...................................................................................166





xv

**Table of Contents**

**Chapter 8: Taking On Higher Order Linear Nonhomogeneous**

**Differential Equations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .173**

Mastering the Method of Undetermined Coefficients

for Higher Order Equations.....................................................................174

When g(x) is in the form erx ...............................................................176

When g(x) is a polynomial of order n ..............................................179

When g(x) is a combination of sines and cosines..........................182

Solving Higher Order Equations with Variation of Parameters..............185

The basics of the method..................................................................185

Working through an example............................................................186

Part III: The Power Stuff: Advanced Techniques...........189

**Chapter 9: Getting Serious with Power Series**

**and Ordinary Points . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .191**

Perusing the Basics of Power Series..........................................................191

Determining Whether a Power Series Converges

with the Ratio Test ...................................................................................192

The fundamentals of the ratio test...................................................192

Plugging in some numbers................................................................193

Shifting the Series Index..............................................................................195

Taking a Look at the Taylor Series.............................................................195

Solving Second Order Differential Equations with Power Series...........196

When you already know the solution ..............................................198

When you don’t know the solution beforehand.............................204

A famous problem: Airy’s equation..................................................207

**Chapter 10: Powering through Singular Points . . . . . . . . . . . . . . . . . .213**

Pointing Out the Basics of Singular Points ...............................................213

Finding singular points ......................................................................214

The behavior of singular points .......................................................214

Regular versus irregular singular points.........................................215

Exploring Exciting Euler Equations ...........................................................219

Real and distinct roots.......................................................................220

Real and equal roots ..........................................................................222

Complex roots.....................................................................................223

Putting it all together with a theorem..............................................224

Figuring Series Solutions Near Regular Singular Points..........................225

Identifying the general solution........................................................225

The basics of solving equations near singular points...................227

A numerical example of solving an equation

near singular points........................................................................230

Taking a closer look at indicial equations.......................................235





xvi

**Differential Equations For Dummies**

**Chapter 11: Working with Laplace Transforms . . . . . . . . . . . . . . . . . .239**

Breaking Down a Typical Laplace Transform...........................................239

Deciding Whether a Laplace Transform Converges ................................240

Calculating Basic Laplace Transforms ......................................................241

The transform of 1..............................................................................242

The transform of eat............................................................................242

The transform of sin at ......................................................................242

Consulting a handy table for some relief ........................................244

Solving Differential Equations with Laplace Transforms........................245

A few theorems to send you on your way.......................................246

Solving a second order homogeneous equation ............................247

Solving a second order nonhomogeneous equation .....................251

Solving a higher order equation.......................................................255

Factoring Laplace Transforms and Convolution Integrals .....................258

Factoring a Laplace transform into fractions .................................258

Checking out convolution integrals.................................................259

Surveying Step Functions............................................................................261

Defining the step function.................................................................261

Figuring the Laplace transform of the step function .....................262

**Chapter 12: Tackling Systems of First Order Linear**

**Differential Equations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .265**

Introducing the Basics of Matrices............................................................266

Setting up a matrix .............................................................................266

Working through the algebra ............................................................267

Examining matrices............................................................................268

Mastering Matrix Operations......................................................................269

Equality................................................................................................269

Addition...............................................................................................270

Subtraction..........................................................................................270

Multiplication of a matrix and a number.........................................270

Multiplication of two matrices..........................................................270

Multiplication of a matrix and a vector...........................................271

Identity.................................................................................................272

The inverse of a matrix......................................................................272

Having Fun with Eigenvectors ’n’ Things..................................................278

Linear independence .........................................................................278

Eigenvalues and eigenvectors ..........................................................281

Solving Systems of First-Order Linear Homogeneous

Differential Equations ..............................................................................283

Understanding the basics..................................................................284

Making your way through an example ............................................285

Solving Systems of First Order Linear Nonhomogeneous Equations.....288

Assuming the correct form of the particular solution...................289

Crunching the numbers.....................................................................290

Winding up your work .......................................................................292





xvii

**Table of Contents**

**Chapter 13: Discovering Three Fail-Proof Numerical Methods . . . . .293**

Number Crunching with Euler’s Method ..................................................294

The fundamentals of the method.....................................................294

Using code to see the method in action..........................................295

Moving On Up with the Improved Euler’s Method ..................................299

Understanding the improvements ...................................................300

Coming up with new code.................................................................300

Plugging a steep slope into the new code.......................................304

Adding Even More Precision with the Runge-Kutta Method ..................308

The method’s recurrence relation....................................................308

Working with the method in code....................................................309

Part IV: The Part of Tens............................................315

**Chapter 14: Ten Super-Helpful Online Differential**

**Equation Tutorials . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .317**

AnalyzeMath.com’s Introduction to Differential Equations ...................317

Harvey Mudd College Mathematics Online Tutorial ...............................318

John Appleby’s Introduction to Differential Equations...........................318

Kardi Teknomo’s Page .................................................................................318

Martin J. Osborne’s Differential Equation Tutorial..................................318

Midnight Tutor’s Video Tutorial.................................................................319

The Ohio State University Physics Department’s

Introduction to Differential Equations...................................................319

Paul’s Online Math Notes............................................................................319

S.O.S. Math....................................................................................................319

University of Surrey Tutorial ......................................................................320

**Chapter 15: Ten Really Cool Online Differential**

**Equation Solving Tools . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .321**

AnalyzeMath.com’s Runge-Kutta Method Applet ....................................321

Coolmath.com’s Graphing Calculator .......................................................321

Direction Field Plotter .................................................................................322

An Equation Solver from QuickMath Automatic Math Solutions...........322

First Order Differential Equation Solver....................................................322

GCalc Online Graphing Calculator.............................................................322

JavaView Ode Solver....................................................................................323

Math @ CowPi’s System Solver...................................................................323

A Matrix Inverter from QuickMath Automatic Math Solutions..............323

Visual Differential Equation Solving Applet..............................................323

Index........................................................................325





xviii

**Differential Equations For Dummies**





**Introduction**

F

or too many people who study differential equations, their only exposure

to this amazingly rich and rewarding field of mathematics is through a

textbook that lands with an 800-page whump on their desk. And what follows

is a weary struggle as the reader tries to scale the impenetrable fortress of

the massive tome.

Has no one ever thought to write a book on differential equations from the

reader’s point of view? Ye s indeed — that’s where this book comes in.

About This Book

Differential Equations For Dummies is all about differential equations from

your point of view. I’ve watched many people struggle with differential equa-

tions the standard way, and most of them share one common feeling:

Confusion as to what they did to deserve such torture.

This book is different; rather than being written from the professor’s point

of view, it has been written from the reader’s point of view. This book was

designed to be crammed full of the good stuff, and only the good stuff. No

extra filler has been added; and that means the issues aren’t clouded. In this

book, you discover ways that professors and instructors make solving prob-

lems simple.

You can leaf through this book as you like. In other words, it isn’t important

that you read it from beginning to end. Like other For Dummies books, this one

has been designed to let you skip around as much as possible — this is your

book, and now differential equations are your oyster.

Conventions Used in This Book

Some books have a dozen confusing conventions that you need to know

before you can even start reading. Not this one. Here are the few simple con-

ventions that I include to help you navigate this book:





2

**Differential Equations For Dummies**

` `Italics indicate definitions and emphasize certain words. As is customary

in the math world, I also use italics to highlight variables.

` `**Boldfaced** text highlights important theorems, matrices (arrays of num-

bers), keywords in bulleted lists, and actions to take in numbered steps.

` `Monofont points out Web addresses.

When this book was printed, some Web addresses may have needed to break

across two lines of text. If that happens, rest assured that I haven’t put in any

extra characters (such as hyphens) to indicate the break. So when using one

of these Web addresses, type in exactly what you see in this book, pretending

as though the line break doesn’t exist.

What You’re Not to Read

Throughout this book, I share bits of information that may be interesting to

you but not crucial to your understanding of an aspect of differential equa-

tions. You’ll see this information either placed in a sidebar (a shaded gray

box) or marked with a Technical Stuff icon. I won’t be offended if you skip

any of this text — really!

Foolish Assumptions

This book assumes that you have no experience solving differential equations.

Maybe you’re a college student freshly enrolled in a class on differential equa-

tions, and you need a little extra help wrapping your brain around them. Or

perhaps you’re a student studying physics, chemistry, biology, economics,

or engineering, and you quickly need to get a handle on differential equations

to better understand your subject area.

Any study of differential equations takes as its starting point a knowledge of

calculus. So I wrote this book with the assumption in mind that you know

how to take basic derivatives and how to integrate. If you’re totally at sea

with these tasks, pick up a copy of Calculus For Dummies by Mark Ryan

(Wiley) before you pick up this book.

How This Book Is Organized

The world of differential equations is, well, big. And to handle it, I break that

world down into different parts. Here are the various parts you see in this book.





3

**Introduction**

Part I: Focusing on First Order

Differential Equations

I start this book with first order differential equations — that is, differential

equations that involve derivatives to the first power. You see how to work

with linear first order differential equations (linear means that the derivatives

aren’t squared, cubed, or anything like that). You also discover how to work

with separable first order differential equations, which can be separated so

that only terms in y appear on one side, and only terms in x (and constants)

appear on the other. And, finally, in this part, you figure out how to handle

exact differential equations. With this type of equation you try to find a func-

tion whose partial derivatives correspond to the terms in a differential equa-

tion (which makes solving the equation much easier).

Part II: Surveying Second and Higher

Order Differential Equations

In this part, I take things to a whole new level as I show you how to deal with

second order and higher order differential equations. I divide equations into

two main types: linear homogeneous equations and linear nonhomogeneous

equations. You also find out that a whole new array of dazzling techniques

can be used here, such as the method of undetermined coefficients and the

method of variation of parameters.

Part III: The Power Stuff: Advanced

Techniques

Some differential equations are tougher than others, and in this part, I bring

out the big guns. You see heavy-duty techniques like Laplace transforms and

series solutions, and you start working with systems of differential equations.

You also figure out how to use numerical methods to solve differential equa-

tions. These are methods of last resort, but they rarely fail.

Part IV: The Part of Tens

You see the Part of Tens in all For Dummies books. This part is made up of

fast-paced lists of ten items each; in this book, you find ten online differential

equation tutorials and ten top online tools for solving differential equations.





4

**Differential Equations For Dummies**

Icons Used in This Book

You can find several icons in the margins of this book, and here’s what they

mean:

This icon marks something to remember, such as a law of differential equa-

tions or a particularly juicy equation.

The text next to this icon is technical, insider stuff. You don’t have to read it

if you don’t want to, but if you want to become a differential equations pro

(and who doesn’t?), take a look.

This icon alerts you to helpful hints in solving differential equations. If you’re

looking for shortcuts, search for this icon.

When you see this icon, watch out! It indicates something particularly tough

to keep an eye out for.

Where to Go from Here

You’re ready to jump into Chapter 1. However, you don’t have to start there if

you don’t want to; you can jump in anywhere you like — this book was writ-

ten to allow you to do just that. But if you want to get the full story on differ-

ential equations from the beginning, jump into Chapter 1 first — that’s where

all the action starts.





**~~Par t I~~**

**Focusing on First**

**Order Dif ferential**

**Equations**





In this part . . .

I

n this part, I welcome you to the world of differential

equations and start you off easy with linear first order

differential equations. With first order equations, you

have first order derivatives that are raised to the first

power, not squared or raised to any higher power. I also

show you how to work with separable first order differen-

tial equations, which are those equations that can be sep-

arated so that terms in y appear on one side and terms in

x (and constants) appear on the other. Finally, I introduce

exact differential equations and Euler’s method.





**Chapter 1**

**Welcome to the World of**

**Differential Equations**

In This Chapter

` `Breaking into the basics of differential equations

` `Getting the scoop on derivatives

` `Checking out direction fields

` `Putting differential equations into different categories

` `Distinguishing among different orders of differential equations

` `Surveying some advanced methods

I

t’s a tense moment in the physics lab. The international team of high-

powered physicists has attached a weight to a spring, and the weight is

bouncing up and down.

“What’s happening?” the physicists cry. “We have to understand this in terms

of math! We need a formula to describe the motion of the weight!”

You, the renowned Differential Equations Expert, enter the conversation

calmly. “No problem,” you say. “I can derive a formula for you that will

describe the motion you’re seeing. But it’s going to cost you.”

The physicists look worried. “How much?” they ask, checking their grants

and funding sources. You tell them.

“Okay, anything,” they cry. “Just give us a formula.”

You take out your clipboard and start writing.

“What’s that?” one of the physicists asks, pointing at your calculations.





8

**Part I: Focusing on First Order Differential Equations**

“That,” you say, “is a differential equation. Now all I have to do is to solve it,

and you’ll have your formula.” The physicists watch intently as you do your

math at lightning speed.

“I’ve got it,” you announce. “Your formula is y = 10 sin (5t), where y is the

weight’s vertical position, and t is time, measured in seconds.”

“Wow,” the physicists cry, “all that just from solving a differential equation?”

“Yep,” you say, “now pay up.”

Well, you’re probably not a renowned differential equations expert — not yet,

at least! But with the help of this book, you very well may become one. In this

chapter, I give you the basics to get started with differential equations, such

as derivatives, direction fields, and equation classifications.

The Essence of Differential Equations

In essence, differential equations involve derivatives, which specify how a

quantity changes; by solving the differential equation, you get a formula for

the quantity itself that doesn’t involve derivatives.

Because derivatives are essential to differential equations, I take the time in

the next section to get you up to speed on them. (If you’re already an expert

on derivatives, feel free to skip the next section.) In this section, however,

I take a look at a qualitative example, just to get things started in an easily

digestible way.

Say that you’re a long-time shopper at your local grocery store, and you’ve

noticed prices have been increasing with time. Here’s the table you’ve been

writing down, tracking the price of a jar of peanut butter:

**Month**

**Price**

$2.40

$2.50

$2.60

$2.70

$2.80

$2.90

1

2

3

4

5

6





9

**Chapter 1: Welcome to the World of Differential Equations**

Looks like prices have been going up steadily, as you can see in the graph

of the prices in Figure 1-1. With that large of a price hike, what’s the price of

peanut butter going to be a year from now?

2.90

2.80

2.70

2.60

2.50

2.40

**Figure 1-1:**

The price of

peanut

butter by

month.

1

2

3

4

5

6

**Time**

You know that the slope of a line is ∆y/∆x (that is, the change in y divided by

the change in x). Here, you use the symbols ∆p for the change in price and ∆t

for the change in time. So the slope of the line in Figure 1-1 is ∆p/∆t.

Because the price of peanut butter is going up 10 cents every month, you

know that the slope of the line in Figure 1-1 is:

∆p

∆t

= 10¢/month

The slope of a line is a constant, indicating its rate of change. The derivative

of a quantity also gives its rate of change at any one point, so you can think of

the derivative as the slope at a particular point. Because the rate of change of

a line is constant, you can write:

dp ∆p

dt

\=

= 10¢/month

∆t

In this case, dp/dt is the derivative of the price of peanut butter with respect

to time. (When you see the d symbol, you know it’s a derivative.)

And so you get this differential equation:

dp

dt

= 10¢/month





10

**Part I: Focusing on First Order Differential Equations**

The previous equation is a differential equation because it’s an equation that

involves a derivative, in this case, dp/dt. It’s a pretty simple differential equa-

tion, and you can solve for price as a function of time like this:

p = 10t + c

In this equation, p is price (measured in cents), t is time (measured in months),

and c is an arbitrary constant that you use to match the initial conditions of

the problem. (You need a constant, c, because when you take the derivative of

10t + c, you just get 10, so you can’t tell whether there’s a constant that should

be added to 10t — matching the initial conditions will tell you.)

The missing link is the value of c, so just plug in the numbers you have for

price and time to solve for it. For example, the cost of peanut butter in month 1

is $2.40, so you can solve for c by plugging in 1 for t and $2.40 for p (240 cents),

giving you:

240 = 10 + c

By solving this equation, you calculate that c = 230, so the solution to your

differential equation is:

p = 10t + 230

And that’s your solution — that’s the price of peanut butter by month. You

started with a differential equation, which gave the rate of change in the price

of peanut butter, and then you solved that differential equation to get the

price as a function of time, p = 10t + 230.

Want to see the solution to your differential equation in action? Go for it! Find

out what the price of peanut butter is going to be in month 12. Now that you

have your equation, it’s easy enough to figure out:

p = 10t + 230

10(12) + 230 = 350

As you can see, in month 12, peanut butter is going to cost a steep $3.50,

which you were able to figure out because you knew the rate at which the

price was increasing. This is how any typical differential equation may work:

You have a differential equation for the rate at which some quantity changes

(in this case, price), and then you solve the differential equation to get

another equation, which in this case related price to time.

Note that when you substitute the solution (p = 10t + 230) into the differential

equation, dp/dt indeed gives you 10 cents per month, as it should.





11

**Chapter 1: Welcome to the World of Differential Equations**

Derivatives: The Foundation of

Differential Equations

As I mention in the previous section, a derivative simply specifies the rate at

which a quantity changes. In math terms, the derivative of a function f(x),

which is depicted as df(x)/dx, or more commonly in this book, as f'(x), indi-

cates how f(x) is changing at any value of x. The function f(x) has to be con-

tinuous at a particular point for the derivative to exist at that point.

Take a closer look at this concept. The amount f(x) changes in a small distance

along the x axis ∆x is:

f(x + ∆x) – f(x)

The rate at which f(x) changes over the change ∆x is:

~~^~~

~~h~~

~~^ h~~

f x + ∆x - f x

∆x

So far so good. Now to get the derivative dy/dx, where y = f(x), you must let

∆x get very small, approaching zero. You can do that with a limiting expres-

sion, which you can evaluate as ∆x goes to zero. In this case, the limiting

expression is:

~~^~~

~~h~~

~~^ h~~

dy

dx

f x + ∆x - f x

= lim

∆x

∆x " 0

In other words, the derivative of f(x) is the amount f(x) changes in ∆x, divided

by ∆x, as ∆x goes to zero.

I take a look at some common derivatives in the following sections; you’ll see

these derivatives throughout this book.

Derivatives that are constants

The first type of derivative you’ll encounter is when f(x) equals a constant, c.

If f(x) = c, then f(x + ∆x) = c also, and f(x + ∆x) – f(x) = 0 (because all these

amounts are actually the same), so df(x)/dx = 0. Therefore:

^ h

^ h

df x

dx

f x = c

= 0





12

**Part I: Focusing on First Order Differential Equations**

How about when f(x) = cx, where c is a constant? In this case, f(x) = cx, and

f(x + ∆x) = cx + c ∆x.

So f(x + ∆x) – f(x) = c ∆x and (f(x + ∆x) – f(x))/∆x = c. Therefore:

^ h

^ h

df x

dx

f x = cx

= c

Derivatives that are powers

Another type of derivative that pops up is one that includes raising x to the

power n. Derivatives with powers work like this:

^ h

^ h

df x

dx

f x = x

n

= n xn - 1

Raising e to a certain power is always popular when working with differential

equations (e is the natural logarithm base, e = 2.7128 . . ., and a is a constant):

^ h

^ h

df x

dx

f x = eax

= a eax

And there’s also the inverse of e , which is the natural log, which works like

a

this:

^ h

^ h

^ h

df x

dx

1

f x = ln x

\=

x

Derivatives involving trigonometry

Now for some trigonometry, starting with the derivative of sin(x):

^ h

^ h

^ h

df x

dx

^ h

f x = sin x

= cos x

And here’s the derivative of cos(x):

^ h

^ h

^ h

df x

dx

^ h

f x = cos x

= -sin x

Derivatives involving multiple functions

The derivative of the sum (or difference) of two functions is equal to the sum

(or difference) of the derivatives of the functions (that’s easy enough to

remember!):

^ h

^ h

^ h

^ h

^ h

^ h

df x

dx

d a x

dx

d b x

dx

f x = a x ! b x

\=

!





13

**Chapter 1: Welcome to the World of Differential Equations**

The derivative of the product of two functions is equal to the first function

times the derivative of the second, plus the second function times the deriva-

tive of the first. For example:

^ h

^ h

^ h

^ h

^ h ^ h

df x

dx

^ h d b x

^ h d a x

f x = a x b x

= a x

\+ b x

dx

dx

How about the derivative of the quotient of two functions? That derivative is

equal to the function in the denominator times the derivative of the function

in the numerator, minus the function in the numerator times the derivative

of the function in the denominator, all divided by the square of the function

in the denominator:

^ h

^ h

~~^ h~~ d a x

~~^ h~~ d b x

~~^ h~~

^ h

b x

\- a x

^ h a x

df x

dx

dx

dx

f x =  ~~^ h~~

\=

~~^ h~~

b x

2

b x

Seeing the Big Picture

with Direction Fields

It’s all too easy to get caught in the math details of a differential equation,

thereby losing any idea of the bigger picture. One useful tool for getting an

overview of differential equations is a direction field, which I discuss in more

detail in Chapter 2. Direction fields are great for getting a handle on differen-

tial equations of the following form:

dy

dx

\_

i

= f x,y

The previous equation gives the slope of the equation y = f(x) at any point x. A

direction field can help you visualize such an equation without actually having

to solve for the solution. That field is a two-dimensional graph consisting of

many, sometimes hundreds, of short line segments, showing the slope — that

is, the value of the derivative — at multiple points. In the following sections,

I walk you through the process of plotting and understanding direction fields.

Plotting a direction field

Here’s an example to give you an idea of what a direction field looks like.

A body falling through air experiences this force:

F = mg – γ v





14

**Part I: Focusing on First Order Differential Equations**

In this equation, F is the net force on the object, m is the object’s mass, g is

the acceleration due to gravity (g = 9.8 meters/sec near the Earth’s surface),

2

γ is the drag coefficient (which adds the effect of air friction and is measured

in newtons sec/meter), and v is the speed of the object as it plummets

through the air.

If you’re familiar with physics, consider Newton’s second law. It says that

F = ma, where F is the net force acting on an object, m is its mass, and a is its

acceleration. But the object’s acceleration is also dv/dt, the derivative of the

object’s speed with respect to time (that is, the rate of change of the object’s

speed). Putting all this together gives you:

dv

dt

F = ma = m

= mg - c v

Now you’re back in differential equation territory, with this differential equa-

tion for speed as a function of time:

dv

dt

c

~~m~~

= g -

v

Now you can get specific by plugging in some numbers. The acceleration due

to gravity, g, is 9.8 meters/sec near the Earth’s surface, and let’s say that the

2

drag coefficient is 1.0 newtons sec/meter and the object has a mass of 4.0 kilo-

grams. Here’s what you’d get:

dv

dt

v

4

= 9.8 -

To get a handle on this equation without attempting to solve it, you can plot

it as a direction field. To do so you create a two-dimensional plot and add

dozens of short line segments that give the slope at those locations (you can

do this by hand or with software). The direction field for this equation

appears in Figure 1-2. As you can see in the figure, there are dozens of short

lines in the graph, each of which give the slope of the solution at that point.

The vertical axis is v, and the horizontal axis is t.

Because the slope of the solution function at any one point doesn’t depend

on t, the slopes along any horizontal line are the same.

Connecting slopes into an integral curve

You can get a visual handle on what’s happening with the solutions to a dif-

ferential equation by looking at its direction field. How? All those slanted line

segments give you the solutions of the differential equations — all you have

to do is draw lines connecting the slopes. One such solution appears in

Figure 1-3. A solution like the one in the figure is called an integral curve of

the differential equation.





15

**Chapter 1: Welcome to the World of Differential Equations**

50

45

**v**

40

35

30

25

**Figure 1-2:**

A direction

field. 20

1

2

3

4

5

6

7

**t**

8

9

10

50

45

**v**

40

35

30

**Figure 1-3:** 25

A solution in

a direction

field. 20

1

2

3

4

5

6

7

**t**

8

9

10





16

**Part I: Focusing on First Order Differential Equations**

Recognizing the equilibrium value

As you can see from Figure 1-3, there are many solutions to the equation that

you’re trying to solve. As it happens, the actual solution to that differential

equation is:

v = 39.2 + ce–t/4

In the previous solution, c is an arbitrary constant that can take any value.

That means there are an infinite number of solutions to the differential

equation.

But you don’t have to know that solution to determine what the solutions

behave like. You can tell just by looking at the direction field that all solutions

tend toward a particular value, called the equilibrium value. For instance, you

can see from the direction field graph in Figure 1-3 that the equilibrium value

is 39.2. You also can see that equilibrium value in Figure 1-4.

50

45

**v**

40

35

30

**Figure 1-4:**

An

equilibrium 25

value in a

direction

field. 20

1

2

3

4

5

6

7

**t**

8

9

10





17

**Chapter 1: Welcome to the World of Differential Equations**

Classifying Differential Equations

Tons of differential equations exist in Math and Science Land, and the way

you tackle them differs by type. As a result, there are several classifications

that you can put differential equations into. I explain them in the following

sections.

Classifying equations by order

The most common classification of differential equations is based on order.

The order of a differential equation simply is the order of its highest deriva-

tive. For example, check out the following, which is a first order differential

equation:

dy

dx

= 5x

Here’s an example of a second order differential equation:

d

2

y

2

dy

dx

\+

= 19x + 4

dx

And so on, up to order n:

d

n

y

n

d

n - 1

y

1

d

2

y

2

dy

dx

9

\- 16

\+ . . . + 14

\+ 12

\- 19x + 4 = 0

dx

dx

n

dx

\-

As you might imagine, first order differential equations are usually the most

easily managed, followed by second order equations, and so on. I discuss

first order, second order, and higher order differential equations in a bit more

detail later in this chapter.

Classifying ordinary versus

partial equations

You can also classify differential equations as ordinary or partial. This classifi-

cation depends on whether you have only ordinary derivatives involved or

only partial derivatives.





18

**Part I: Focusing on First Order Differential Equations**

An ordinary (non-partial) derivative is a full derivative, such as dQ/dt, where

you take the derivative of all terms in Q with respect to t. Here’s an example

of an ordinary differential equation, relating the charge Q(t) in a circuit to the

electromotive force E(t) (that is, the voltage source connected to the circuit):

d

2

Q

2

dQ

dt

1

C

^ h

L

\+ R

\+

Q = E t

dt

Here, Q is the charge, L is the inductance of the circuit, C is the capacitance

of the circuit, and E(t) is the electromotive force (voltage) applied to the cir-

cuit. This is an ordinary differential equation because only ordinary deriva-

tives appear.

On the other hand, partial derivatives are taken with respect to only one vari-

able, although the function depends on two or more. Here’s an example of a

partial differential equation (note the squiggly d’s):

\_

i

\_

i

2

2

u x,t

2u x,t

2t

α

2

\=

2x

2

In this heat conduction equation, α is a physical constant of the system that

you’re trying to track the heat flow of, and u(x, t) is the actual heat.

Note that u(x, t) depends on both x and t and that both derivatives are partial

derivatives — that is, the derivatives are taken with respect to one or the

other of x or t, but not both.

In this book, I focus on ordinary differential equations, because partial differ-

ential equations are usually the subject of more advanced texts. Never fear

though: I promise to get you your fair share of partial differential equations.

Classifying linear versus

nonlinear equations

Another way that you can classify differential equations is as linear or non-

linear. You call a differential equation linear if it exclusively involves linear

terms (that is, terms to the power 1) of y, y', y", and beyond to y(n). For exam-

ple, this equation is a linear differential equation:

d

2

Q

2

dQ

dt

1

C

^ h

L

\+ R

\+

Q = E t

dt





19

**Chapter 1: Welcome to the World of Differential Equations**

Note that this kind of differential equation usually will be written this way

throughout this book. And this form makes the linear nature of this equation

clear:

^ h

1

LQ"+ R Ql+ Q = E t

C

On the other hand, nonlinear differential equations involve nonlinear terms in

any of y, y', y", up to y(n). The following equation, which describes the angle of

a pendulum, is a nonlinear differential equation that involves the term sin θ

(not just θ):

θ

2

g

L

d

2

\+

sinθ = 0

dt

Handling nonlinear differential equations is generally more difficult than han-

dling linear equations. After all, it’s often tough enough to solve linear differ-

ential equations without messing things up by adding higher powers and

other nonlinear terms. For that reason, you’ll often see scientists cheat when

it comes to nonlinear equations. Usually they make an approximation that

reduces the nonlinear equation to a linear one.

For example, when it comes to pendulums, you can say that for small angles,

sin θ ≈ θ. This means that the following equation is the standard form of the

pendulum equation that you’ll find in physics textbooks:

θ

2

g

L

d

2

\+

θ = 0

dt

As you can see, this equation is a linear differential equation, and as such,

it’s much more manageable. Yes, it’s a cheat to use only small angles so that

sin θ ≈ θ, but unless you cheat like that, you’ll sometimes be reduced to using

numerical calculations on a computer to solve nonlinear differential equa-

tions; obviously these calculations work, but it’s much less satisfying than

cracking the equation yourself (if you’re a math geek like me).

Solving First Order Differential Equations

Chapters 2, 3, and 4 take a look at differential equations of the form f'(x) =

f(x, y); these equations are known as first order differential equations

because the derivative involved is of first order (for more on these types

of equations, see the earlier section “Classifying equations by order.”





20

**Part I: Focusing on First Order Differential Equations**

First order differential equations are great because they’re usually the most

solvable. I show you all kinds of ways to handle first order differential equa-

tions in Chapters 2, 3, and 4. The following are some examples of what you

can look forward to:

` `As you know, first order differential equations look like this: f'(x) = f(x, y).

In the upcoming chapters, I show you how to deal with the case where

f(x, y) is linear in x — for example, f'(x) = 5x — and then nonlinear in x,

as in f'(x) = 5x .

2

` `You find out how to work with separable equations, where you can

factor out all the terms having to do with y on one side of the equation

and all the terms having to do with x on the other.

` `I also help you solve first order differential equations in cool ways, such

as by finding integrating factors to make more difficult problems simple.

Direction fields, which I discuss earlier in this chapter, work only for equa-

tions of the type f'(x) = f(x, y) — that is, where only the first derivative is

involved — because the first derivative of f(x) gives you the slope of f(x) at

any point (and, of course, connecting the slope line segments is what direc-

tion fields are all about).

Tackling Second Order and Higher Order

Differential Equations

As noted in the earlier section “Classifying equations by order,” second order

differential equations involve only the second derivative, d

2

y/dx , also known

2

as y". In many physics situations, second order differential equations are

where the action is.

For example, you can handle physics situations such as masses on springs or

the electrical oscillations of inductor-capacitor circuits with a differential

equation like this:

y" – ay = 0

In Part II, I show you how to tackle second order differential equations with a

large arsenal of tools, such as the Wronskian matrix determinant, which will tell

you if there are solutions to a second (or higher) order differential equation.

Other tools I introduce you to include the method of undetermined coefficients

and the method of variation of parameters.





21

**Chapter 1: Welcome to the World of Differential Equations**

After first and second order differential equations, it’s natural to want to keep

the fun going, and that means you’ll be dealing with higher order differential

equations, which I also cover in Part II. With these high-end equations, you

find terms like d

n

y/dxn

, where n > 2.

The derivative d

atives are written as y', y", y''', yiv, y

of y is written as y(n)

n

y/dx

n

is also written as y(n). Using the standard syntax, deriv-

, and so on. In general, the nth derivative

v

.

Higher order differential equations can be tough; many of them don’t have

solutions at all. But don’t worry, because to help you solve them I bring to

bear the wisdom of more than 300 years of mathematicians.

Having Fun with Advanced Techniques

You discover dozens of tools in Part III of this book; all of these tools have been

developed and proved powerful over the years. Laplace Transforms, Euler’s

method, integrating factors, numerical methods — they’re all in this book.

These tools are what this book is all about — applying the knowledge of hun-

dreds of years of solving differential equations. As you may know, differential

equations can be broken down by type, and there’s always a set of tools devel-

oped that allows you to work with whatever type of equation you come up

with. In this book, you’ll find a great many powerful tools that are just waiting

to solve all of your differential equations — from the simplest to the seemingly

impossible!





22

**Part I: Focusing on First Order Differential Equations**





**Chapter 2**

**Looking at Linear First Order**

**Differential Equations**

In This Chapter

` `Beginning with the basics of solving linear first order differential equations

` `Using integrating factors

` `Determining whether solutions exist for linear and nonlinear equations

A

s you find out in Chapter 1, a first order differential equation simply has

a derivative of the first order. Here’s what a typical first order differen-

tial equation looks like, where f(t, y) is a function of the variables t and y (of

course, you can use any variables here, such as x and y or u and v, not just t

and y):

dy

dt

\_

i

= f t,y

In this chapter, you work with linear first order differential equations — that

is, differential equations where the highest power of y is 1 (you can find out

the difference between linear and nonlinear equations in Chapter 1). For

example:

dy

dt

= 5

dt

dt

= y + 1

= 3y + 1

dt

dt

I provide some general information on nonlinear differential equations at the

end of the chapter for comparison.





24

**Part I: Focusing on First Order Differential Equations**

First Things First: The Basics of Solving

Linear First Order Differential Equations

In the following sections, I take a look at how to handle linear first order dif-

ferential equations in general. Get ready to find out about initial conditions,

solving equations that involve functions, and constants.

Applying initial conditions from the start

When you’re given a differential equation of the form dy/dt = f(t, y), your goal

is to find a function, y(t), that solves it. You may start by integrating the equa-

tion to come up with a solution that includes a constant, and then you apply

an initial condition to customize the solution. Applying the initial condition

allows you to select one solution among the infinite number that result from

the integration. Sounds cool, doesn’t it?

Take a look at this simple linear first order differential equation:

dy

dt

= a

As you can see, a is just a regular old number, meaning that this is a simple

example to start with and to introduce the idea of initial conditions. How can

you solve it? First of all, you may have noticed that another way of writing

this equation is:

dy = a dt

This equation looks promising. Why? Well, because now you can integrate

like this:

y

t

\#

\#

dy =

a dt

y

x

0

0

Performing the integration gives you the following equation:

y – y0 = at – at0

You can combine y – at into a new constant, c, by adding y to the right side

0

0

0

of the equation, which gives you:

y = at + c





25

**Chapter 2: Looking at Linear First Order Differential Equations**

That was simple enough, right? And guess what? You’re done! The solution to

this differential equation is y = at + c.

So, for example, if a = 3 in the differential equation, here’s the equation you

would have:

dy

dt

= 3

The solution for this equation is y = 3t + c.

Note that c, the result of integrating, can be any value, which leads to an infi-

nite set of solutions: y = 3t + 5, y = 3t + 6, y = 3t + 589,303,202. How do you track

down the value of c that works for you? Well, it all depends on your initial con-

ditions; for example, you may specify that the value of y at t = 0 be 15. Setting

this initial condition allows you to state the whole problem — differential

equation and initial condition — as follows:

dy

dt

= 3

y(0) = 15

Substituting the initial condition, y(0) = 15, into the solution y = 3t + c gives

you the following equation:

y(t) = 3t + 15

Stepping up to solving differential

equations involving functions

Of course, dy/dt = 3 (the example from the previous section) isn’t the most

exciting differential equation. However, it does show you how to solve a dif-

ferential equation using integration and how to apply an initial condition. The

next step is to solve linear differential equations that involve functions of t

rather than just a simple number.

This type of differential equation still contains only dy/dt and terms of t,

making it easy to integrate. Here’s the basic form:

dy

dt

^ h

= g t

where g(t) is some function of t.

Here’s an example of this type of differential equation:

dy

dt

= t

3

\- 3t + t

2





26

**Part I: Focusing on First Order Differential Equations**

Well, heck, that’s easy too; you simply rearrange to get this:

dy = t

3

dt – 3t

2

dt + t dt

Then you can integrate to get this equation:

t

4

t

2

y = - t

3

\+

\+ c

4

2

Adding a couple of constants to the mix

The next step up from equations such as dy/dx = a or dy/dt = g(t) are equa-

tions of the following form, which involve y, dy/dt, and the constants a and b:

dy

dt

= ay - b

How do you handle this equation and find a solution? Using some handy alge-

bra, you can rewrite the equation like this:

dy/dt

y - b/a

~~\_~~

~~i~~ = a

Integrating both sides gives you the following equation:

ln | y – (b/a) | = at + c

where c is an arbitrary constant. Now get y out of the natural logarithm,

which gives you:

y = (b/a) + deat

where d = e . And that’s it! You’re done. Good job!

c

Solving Linear First Order Differential

Equations with Integrating Factors

Sometimes integrating linear first order differential equations isn’t as easy as

it is in the examples earlier in this chapter. But it turns out that you can often

convert general equations into something that’s easy to integrate if you find

an integrating factor, which is a function, µ(t). The idea here is to multiply the

differential equation by an integrating factor so that the resulting equation

can easily be integrated and solved.

In the following sections, I provide tips and tricks for solving for an integrating

factor and plugging it back into different types of linear first order equations.





27

**Chapter 2: Looking at Linear First Order Differential Equations**

Solving for an integrating factor

In general, first order differential equations don’t lend themselves to easy

integration, which is where integrating factors come in. How does the method

of integrating factors work? To understand, say, for example, that you have

this linear differential equation:

dy

dt

\+ 2y = 4

First, you multiply the previous equation by µ(t), which is a stand-in for the

undetermined integrating factor, giving you:

^ h dy

^ h

^ h

µ t

\+ 2µ t y = 4 µ t

dt

Now you have to choose µ(t) so that you can recognize the left side of this

equation as the derivative of some expression. This way it can easily be

integrated.

Here’s the key: The left side of the previous equation looks very much like

differentiating the product µ(t)y. So try to choose µ(t) so that the left side of

the equation is indeed the derivative of µ(t)y. Doing so makes the integration

easy.

The derivative of µ(t)y by t is:

8 ^ h

B

^ h

d µ t y

^ h dy

d

µ

dt

t y

= µ t

\+

dt

dt

Comparing the previous two equations term by term gives you:

^ h

dµ t

dt

^ h

= 2µ t

Hey, not bad. Now you’re making progress! This is a differential equation you

can solve. Rearranging the equation so that all occurrences of µ(t) are on the

same side gives you:

^ h

dµ t /dt

µ t

^ h

= 2

Now the equation can be rearranged to look like this:

^ h

dµ t

µ t

^ h

= 2 dt

Fine work. Integration gives you:

ln |µ(t)| = 2t + b

where b is an arbitrary constant of integration.





28

**Part I: Focusing on First Order Differential Equations**

Now it’s time for some exponentiating. Exponentiating both sides of the

equation gives you:

µ(t) = ce2t

where c is an arbitrary constant.

So that’s it — you’ve solved for the integrating factor! It’s µ(t) = ce2t

.

Using an integrating factor to solve

a differential equation

After you solve for an integrating factor, you can plug that factor into the

original linear differential equation as multiplied by µ(t). For instance, take

your original equation from the previous section:

^ h dy

^ h

^ h

µ t

\+ 2µ t y = 4 µ t

dt

and plug in the integrating factor to get this equation:

dy

dt

ce2t

\+ 2ce2t y = 4 ce2t

Note that c drops out of this equation when you divide by c, so you get the

following equation (because you’re just looking for an arbitrary integrating

factor, you could also set c = 1):

dy

dt

e

2t

\+ 2e2t y = 4 e2t

When you use an integrating factor, you attempt to find a function µ(t) that,

when multiplied on both sides of a differential equation, makes the left side

into the derivative of a product. Figuring out the product allows you to solve

the differential equation.

In the previous example, you can now recognize the left side as the derivative

of e2t y. (If you can’t recognize the left side as a derivative of some product, in

general, it’s time to go on to other methods of solving the differential equation).

In other words, the differential equation has been conquered, because now

you have it in this form:

\_

i

d e2t

dt

y

= 4e2t

You can integrate both sides of the equation to get this:

e2ty = 2e2t + c





29

**Chapter 2: Looking at Linear First Order Differential Equations**

And, finally, you can solve for y with your handy algebra skills:

y = 2 + ce–2t

You’ve got yourself a solution. Beautiful.

The use of an integrating factor isn’t always going to help you; sometimes,

when you use an integrating factor in a linear differential equation, the left

side isn’t going to be recognizable as the derivative of a product of functions.

In that case, where integrating factors don’t seem to help, you have to turn to

other methods. One of those methods is to determine whether the differen-

tial equation is separable, which I discuss in Chapter 3.

Moving on up: Using integrating factors in

differential equations with functions

Now you’re going to take integrating factors to a new level. Check out this

linear equation, where g(t) is a function of t:

dy

dt

^ h

\+ ay = g t

This one’s a little more tricky. However, using the same integrating factor

from the previous two sections, eat (remember that the c dropped out), works

here as well. After you multiply both sides by eat, you get this equation:

dy

dt

^ h

e

at

\+ a eat y = eat g t

Now you can recast this equation in the following form:

\_

i

d eat

dt

y

^ h

= eat g t

To integrate the function g, I use s as the variable of integration. Integration

gives you this equation:

^ h

\#

e

at y =

e

as g s ds + c

You can solve for y here, which gives you the following equation:

^ h

\#

y = e- at

e

as g s ds + ce- at

And that’s it! You’ve got your answer!

Of course, solving this equation depends on whether you can calculate the

integral in the previous equation. If you can do it, you’ve solved the differential

equation. Otherwise, you may have to leave the solution in the integral form.





30

**Part I: Focusing on First Order Differential Equations**

Trying a special shortcut

In this section, I give you a shortcut for solving some particular differential

equations. Ready? Here’s the tip: In general, the integrating factor for an

equation in this form:

dy

dt

^ h

\+ ay = g t

is this:

^ h

\#

µ t = exp a dt

In this equation, exp(x) means e .

x

As an example, try solving the following differential equation with the shortcut:

dy

dt

1

2

\+

y = 4 + t

Assume that the initial condition is

y = 8, when t = 0

This equation is an example of the general equation solved in the previous

section. In this case, g(t) = 4 + t, and a = ⁄ .

2

1

Using a, you find that the integrating factor is et/2, so multiply both sides of

equation by that factor:

dy

dt

e

t/2

e

t/2

\+

y = 4et/2 + tet/2

2

Now you can combine the two terms on the left to give you this equation:

\_

i

d et/2

dt

y

= 4et/2 + tet/2

All you have to do now is integrate this result. The term on the left and the

first term on the right are no problem. The last term on the right is another

story.

You can use integration by parts to integrate this term. Integration by parts

works like this:

b

^ h ^ h

^ h ^ h

\#

f x gl x dx = f b g b

a

^ h ^ h

b

^ h ^ h

\#

-f a g a - f l x g x dx

a





31

**Chapter 2: Looking at Linear First Order Differential Equations**

Applying integration by parts to the last term on the right, and integrating

the others, gives you:

et/2 y = 8et/2 + 2 t et/2 – 4et/2 + c

where c is an arbitrary constant, set by the initial conditions. Dividing by eat

gives you this equation:

y = 4 + 2t + ce–at

By applying the initial condition, y(0) = 8, you get

y(0) = 8

8 = 4 + c

Or c = 4. So the general solution of the differential equation is:

y = 4 + 2t + 4e–t/2

In Chapter 1, I explain that direction fields are great tools for visualizing dif-

ferential equations. You can see a direction field for the previously noted

general solution in Figure 2-1.

**Figure 2-1:**

The

direction

field of the

general

solution.





32

**Part I: Focusing on First Order Differential Equations**

Connecting the slanting lines in a direction field gives you a graph of the solu-

tion. You can see a graph of this solution in Figure 2-2.

**Figure 2-2:**

The graph of

the general

solution.

Solving an advanced example

I think you’re ready for another, somewhat more advanced, example. Try

solving this differential equation to show that you can have different integrat-

ing factors:

dy

t

\+ 2y = 4t

2

dt

where y(1) = 4.

To solve, first you have to find an integrating factor for the equation. To get it

into the form:

dy

dt

^ h

\+ ay = g t

you have to divide both sides by t, which gives you this equation:

dy

dt

2

\+

y = 4t

t





33

**Chapter 2: Looking at Linear First Order Differential Equations**

To find the integrating factor, use the shortcut equation from the previous

section, like this:

^ h

2

\#

\#

µ t = exp a dt= exp

dt

t

Performing the integral gives you this equation:

^ h

2

\#

µ t = exp

dt= e2 ln

t

= t

2

t

So the integrating factor here is t , which is a new one. Multiplying both sides

2

of the equation by the integrating factor, µ(t) = t , gives you:

2

dy

dt

t

2

\+ 2ty = 4t

3

Because the left side is a readily apparent derivative, you can also write it in

this form:

\_

i

d yt

dt

2

= 4t

3

Now simply integrate both sides to get:

yt = t + c

2

4

Finally you get:

c

y = t

\+

2

t

2

where c is an arbitrary constant of integration.

Now you can plug in the initial condition y(1) = 4, which allows you to see

that c = 3. And that helps you come to this solution:

3

y = t

\+

2

t

2

And there you have it. You can see a direction field for the many general solu-

tions to this differential equation in Figure 2-3.





34

**Part I: Focusing on First Order Differential Equations**

**Figure 2-3:**

The

direction

field of a

more

advanced

solution.

You can see this function graphed in Figure 2-4.

**Figure 2-4:**

The graph of

a more

advanced

solution.





35

**Chapter 2: Looking at Linear First Order Differential Equations**

Determining Whether a Solution for a

Linear First Order Equation Exists

I show you how to deal with different kinds of linear first order differential

equations earlier in this chapter, but the fact remains that not all linear differ-

ential equations actually do have a solution.

Luckily, a theorem exists that tells you when a given linear differential equa-

tion with an initial condition has a solution. That theorem is called the exis-

tence and uniqueness theorem.

This theorem is worth knowing. After all, if a differential equation doesn’t have

a solution, what use is it to search for a solution? In other words, this theorem

represents another way to tackle linear first order differential equations.

Spelling out the existence and uniqueness

theorem for linear differential equations

In this section, I explain what the existence and uniqueness theorem for linear

differential equations says. Before I continue, however, note that a continuous

function is a function for which small changes in the input result in small

changes in the output (for example, f(x) = 1/x is not continuous at x = 0).

Without further ado, here’s the existence and uniqueness theorem:

**If there is an interval I that contains the point to, and if the functions p(x)**

**and g(x) are continuous on that interval, and if you have this differential**

**equation:**

**dy**

**dx**

^ h

^ h

\+ **p x y** = **g x**

**then there exists a unique function, y(x), that is the solution to that differen-**

**tial equation for each x in interval I that also satisfies this initial condition:**

**y(to) = yo**

**where yo is an arbitrary initial value.**

In other words, this theorem says that a solution exists and that the solution

is unique.





36

**Part I: Focusing on First Order Differential Equations**

Finding the general solution

Thinking about the theorem in the previous section begs the question: What

is the general solution to the following linear differential equation?

dy

dx

^ h

^ h

\+ p x y = g x

Note that this differential equation has a function p(x) and g(x), which pro-

vides a more complex situation. So you can’t use the simple form I explain in

the earlier section “Adding a couple of constants to the mix,” where a and b

are constants like this:

dy

dx

= ay - b

The solution here is:

y = (b/a) + ceat

Now you face a more complex situation, with functions p(x) and g(x). A gen-

eral solution to the general equation does exist, and here it is:

^ h ^ h

\#

µ s g s ds + c

y =

^ h

µ t

where the integrating factor is the following:

^ h

^ h

\#

µ t = exp p t dt

The integrals in these equations may not be possible to perform, of course.

But together, the equations represent the general solution.

Note that for linear differential equations, the solution, if there is one, is com-

pletely specified, up to a constant of integration, as in the solution you get in

the earlier section “Solving an advanced example”:

c

y = t

\+

2

t

2

where c is a constant of integration.

You can’t necessarily say the same thing about nonlinear differential

equations — they may have solutions of completely different forms, not just

differing in the value of a constant. Because the solution to a linear differen-

tial equation has one form, differing only by the value of a constant, those

solutions are referred to as general solutions. This term isn’t used when dis-

cussing nonlinear differential equations, which may have multiple solutions

of completely different forms. I discuss nonlinear first order differential equa-

tions later in this chapter.





37

**Chapter 2: Looking at Linear First Order Differential Equations**

Checking out some existence

and uniqueness examples

In this section, I include a few examples to help you understand the existence

and uniqueness theorem for linear differential equations.

Example 1

Apply the existence and uniqueness theorem to the following equation to

show that there exists a unique solution:

dy

dx

4x

y - 5

= ~~\_~~

~~i~~

Just kidding! This equation isn’t linear because the term (y – 5) is in the denom-

inator of the right side. And, of course, because the equation isn’t linear, the

existence and uniqueness theorem doesn’t apply. Did you catch that?

Example 2

Try this differential equation (which I promise is linear!). Does a unique solu-

tion exist?

dy

dx

\+ 2y = 4x

2

where y(1) = 2.

The equation is already in the correct form:

dy

dx

^ h

^ h

\+ p x y = g x

where p(x) = 2 and g(x) = 4x .

2

Note that p(x) and g(x) are continuous everywhere, so there’s a general solu-

tion that’s valid on the interval, –∞

∞

.

< x <

In particular, the initial condition is y(1) = 2, which is definitely inside the

interval that p(x) and g(x) are continuous (everything is inside that interval).

So, yes, there exists a solution to the initial value problem.

Example 3

Now take a look at this equation, which is similar to the example in the previ-

ous section, and determine whether a unique solution exists:

dy

dx

x

\+ 2y = 4x

2

where y(1) = 2.





38

**Part I: Focusing on First Order Differential Equations**

The next step is to put the equation into this form:

dy

dx

^ h

^ h

\+ p x y = g x

Here’s what the equation should look like:

dy 2y

dx

\+

x

= 4x

In other words:

^ h

2

p x =

x

and

g(x) = 4x

Note that p(x) and g(x) aren’t continuous everywhere. In particular, p(x) is

discontinuous at x = 0, which makes the interval in which p(x) and g(x) are

continuous on the interval 0 > x and 0 < x.

Because the initial condition here is y(1) = 2, the point of interest is x = 1,

which is inside the interval where p(x) and g(x) are continuous. Therefore, by

the existence and uniqueness theorem, the initial value problem indeed has a

unique solution. Cool, huh?

Figuring Out Whether a Solution for a

Nonlinear Differential Equation Exists

In the previous sections of this chapter, I cover linear first order differential

equations in detail. But you may be wondering: Is there such a thing as a non-

linear differential equation? You bet there is! A nonlinear differential equation

simply includes nonlinear terms in y, y', y", and so on. Nonlinear equations

are pretty tough, so I don’t delve into them a lot in this book. But I do want to

discuss one important theorem related to solving these equations.

You see, the existence and uniqueness theorem (which you use for linear

equations, and which I cover earlier in this chapter) is analogous to another

theorem that’s used for nonlinear equations. I explain this theorem and show

some examples in the following sections.





39

**Chapter 2: Looking at Linear First Order Differential Equations**

The existence and uniqueness theorem for

nonlinear differential equations

Here’s the existence and uniqueness of solutions for nonlinear equations:

**Say that you have a rectangle R that contains the point (t , y ) and that the**

**o**

**o**

**functions f and df/dy are continuous in that rectangle. Then, in an interval**

**t – h < t < t + h contained in R, there’s a unique solution to the initial**

**o**

**o**

**value problem:**

**dy**

**dt**

\_

i

\_

i

= **f t,y , y t** = **y**

**0**

**0**

Note that this theorem discusses the continuity of both f and df/dy instead of

the continuity of both p(x) and g(x). Like the first theorem in this chapter,

this theorem guarantees the existence of a unique solution if its conditions

are met.

Here’s another note: If the differential equation in question actually is linear,

the theorem reduces to the first theorem in this chapter. In that case, f(t, y) =

–p(t)y + g(t) and df/dy = –p(t). So demanding that f and df/dy be continuous is

the same as saying that p(t) and g(t) be continuous.

Here’s a side note that many differential equations books won’t tell you: The

first theorem in this chapter guarantees a unique solution, but it’s actually a

little tighter than it needs to be in order to guarantee just a solution (which

isn’t necessarily unique). In fact, you can show that there’s a solution — but

not that it’s unique — to the nonlinear differential equation merely by proving

that f is continuous.

A couple of nonlinear existence and

uniqueness examples

In the following sections, I provide two examples that put the nonlinear exis-

tence and uniqueness theorem into action.

Example 1

Determine what the two theorems in this chapter have to say about the fol-

lowing differential equation as far as its solutions go:

dy

dx

5x

2

\+ 9x + 6

\=

~~\_~~

~~i~~

2 y - 4

where y(0) = –1.





40

**Part I: Focusing on First Order Differential Equations**

Well, as you can see, this is a nonlinear equation in y. So the first theorem,

which deals only with linear differential equations, has nothing to say about it.

That means you need the nonlinear theorem. Note that for this theorem:

\_

i

5x

2

\+ 9x + 6

f x,y =

~~\_~~

~~i~~

2 y - 4

and

df

dy

5x

2

\+ 9x + 6

= -

~~\_~~

~~i~~

2

2 y - 4

These two functions, f and df/dy, are continuous, except at y = 4.

So you can draw a rectangle around the initial condition point, (0, –1) in which

both f and df/dy are continuous. And the existence and uniqueness theorem

for nonlinear equations guarantees that this differential equation has a solu-

tion in that rectangle.

Example 2

Now determine what the existence and uniqueness theorems say about this

differential equation:

dy

dx

= y1/5

where y(1) = 0.

Clearly, this equation isn’t linear, so the first theorem is no good. Instead you

have to try the second theorem. Here, f is:

f(x, y) = y1/5

and df/dy is:

y

\- 4/5

df

dy

\=

5

Now you know that f(x, y) is continuous at the initial condition point given by:

y(1) = 0

But df/dy isn’t continuous at this point. The upshot is that neither the first

theorem nor the second theorem have anything to say about this initial value

problem. On the other hand, a solution to this differential equation is still

guaranteed because f(x, y) is continuous. However, it doesn’t guarantee the

uniqueness of that solution.





**Chapter 3**

**Sorting Out Separable First Order**

**Differential Equations**

In This Chapter

` `Figuring out the fundamentals of separable differential equations

` `Applying separable differential equations to real life

` `Advancing with partial fractions

S

ome rocket scientists call you, the Consulting Differential Equation

Expert, into their headquarters.

“We’ve got a problem,” they explain. “Our rockets are wobbling because we

can’t solve their differential equation. All the rockets we launch wobble and

then crash!”

They show you to a blackboard with the following differential equation:

dy

dx

x

\-

2

\=

2

y

2

“It’s not linear,” the scientists cry. “There’s a y in there!”

2

“I can see that,” you say. “Fortunately, it is separable.”

“Separable? What does that mean?” they ask.

“Separable means that you can recast the equation like this, where x is on

one side and y is on the other,” you say while showing them the following

equation on your clipboard:

(2 – y

2

) dy = x dx

2

“You can integrate the equation with respect to y on one side, and x on the

other,” you say.

“We never thought of that. That was too easy.”





42

**Part I: Focusing on First Order Differential Equations**

That’s what this chapter covers: separable first order differential equations.

(First order equations, as I note in Chapter 1, have derivatives that go up only

to the first order.) I explain the basics of separable equations here, such as

determining the difference between linear and nonlinear separable equations

and figuring out different types of solutions, such as implicit and explicit. I also

introduce you to a fancy method for solving separable equations involving

partial fractions. Finally, I show you a couple of real world applications for

separable equations. When you’re an expert at these equations, you too can

solve problems for rocket scientists.

Beginning with the Basics of Separable

Differential Equations

Separable differential equations, unlike general linear equations in Chapter 2,

let you separate variables so only variables of one kind appear on one side,

and only variables of another kind appear on the other. Say, for example, that

you have a differential equation of the following form, in which M and N are

functions:

\_

i

\_

i dy

M x,y + N x,y

= 0

dx

And furthermore, imagine that you could reduce this equation to the follow-

ing form, where the function M depends only on x and the function N depends

only on y:

^ h

\_ i dy

M x + N y

= 0

x

This equation is a separable equation; in other words, you can separate the

parts so that only x appears on one side, and only y appears on the other.

You write the previous equation like this:

M(x) dx + N(y) dy = 0

Or in other words:

M(x) dx = –N(y) dy

If you can separate a differential equation, all that’s left to do at that point is

to integrate each side (assuming that’s possible). Note that the general form

of a separable differential equation looks like this:

^ h

\_ i dy

M x + N y

= 0

dx





43

**Chapter 3: Sorting Out Separable First Order Differential Equations**

However, nothing here says that N(y) has to be linear in y. For example, con-

sider this separable differential equation that isn’t linear:

dy

dx

x + y

2

= 0

And if you’re still not convinced, check out this one, which is also separable

but not linear:

\_

i dy

x

9

\+ 1 - y

3

= 0

dx

In the following sections, I ease you into linear separable equations before

tackling nonlinear separable equations. I also show you a trick for turning

nonlinear equations into linear equations. (It’s so cool that it’ll impress all

your friends!)

Starting easy: Linear separable equations

To get yourself started with linear separable equations, say that you have

this differential equation:

dy

dx

\- x = 0

2

This equation qualifies as linear. This also is an easily separated differential

equation. All you have to do is put it into this form:

dy = x dx

2

And now you should be able to see the idea behind solving separable differ-

ential equations immediately. You just have to integrate, which gives you this

equation:

x

3

y =

\+ c

3

where c is an arbitrary constant. There’s your solution! How easy was that?

Introducing implicit solutions

Not all separable equation solutions are going to be as easy as the one in the

previous section. Sometimes finding a solution in the y = f(x) format isn’t ter-

ribly easy to get. Mathematicians refer to a solution that isn’t in the form

y = f(x) as an implicit solution. Coming up with such a solution is often the

best you can do, because solving a separable differential equation involves





44

**Part I: Focusing on First Order Differential Equations**

integrating both sides of the equation, and there’s no guarantee that the inte-

gration will come out cleanly. (The form y = f(x) is known as an explicit solu-

tion; I show you how to find an explicit solution from an implicit solution in

the next section.)

Try this differential equation to see what I mean:

dy

dx

x

\-

2

\=

2

y

2

How about it? One of the first things that should occur to you is that this isn’t

a linear differential equation, so the techniques in the first part of this chap-

ter won’t help. However, you’ll probably notice that you can write this equa-

tion as:

(2 – y

2

) dy = x dx

2

As you can see, this is a separable differential equation because you can put y

on one side and x on the other. You can also write the differential equation

like this:

\_

i dy

-x

2

\+ 2 - y

2

= 0

dx

You can cast this particular equation in terms of a derivative of x, and then

you integrate with respect to x to solve it. After integration, you wind up with

the following:

\_

i

d -x

3

/3

-x

\=

2

dx

Note that:

~~\_~~

~~i~~

d 2y - y

3

/3

\_

i dy

2 - y

2

\=

dx

dx

because of the chain rule, which says that:

dy

df

df

\=

dx dy dx

So now you can write the original equation like this:

\_

i dy

e

y

3

o

d

-x

3

3

-x

2

\+ 2 - y

2

\=

\+ 2y -

= 0

dx dx

3

If the derivative of the term on the right is 0, it must be a constant this way:

e

y

3

o

-x

3

3

\+ 2y -

= c

3





45

**Chapter 3: Sorting Out Separable First Order Differential Equations**

Finally, multiplying by 3 gives you the following implicit solution to your origi-

nal separable equation:

–x

3

\+ 6y – y = c

3

To see how the solutions look graphically, check out the direction field for this

differential equation in Figure 3-1. (I introduce direction fields in Chapter 1.)

**Figure 3-1:**

The

direction

field of a

nonlinear

separable

equation.

Finding explicit solutions from

implicit solutions

The implicit solution in the previous section, with terms in y and y , isn’t ter-

3

ribly easy to cram into the y = f(x) format. In this section, you discover that

you can find an explicit solution to a separable equation by using a quadratic

equation, which is the general solution to polynomials of order two.

Try another, somewhat more tractable problem. Solve this differential

equation:

dy

dx

9x

2

\+ 6x + 4

\=

~~\_~~

~~i~~

2 y - 1

where y(0) = –1.





46

**Part I: Focusing on First Order Differential Equations**

If this differential equation were of the following form:

dy

dx

= 9x + 6x + 4

2

there would be no problem. After all, you would just integrate. But you’ve

probably noticed that pesky 2(y – 1) term in the denominator on the right

side. Fortunately, you may also realize that this is a separable differential

equation because you can put y on one side and x on the other. Simply write

the equation like this:

2(y – 1) dy = (9x

Now you integrate to get this equation:

– 2y = 3x + 3x +4x + c

2

\+ 6x + 4) dx

y

2

3

2

Using the initial condition, y(0) = –1, substitute x = 0 and y = –1 to get the

following:

1 + 2 = c

Now you can see that c = 3 and that the implicit solution to the separable

equation is:

y

2

– 2y = 3x

3

\+ 3x +4x + 3

2

If you want to find the explicit solution to this and similar separable equa-

tions, simply solve for y with the quadratic equation because the highest

power of y is 2. Solving for y using the quadratic formula gives you:

y = 1 ! 3x

3

\+ 3x + 4x + 4

2

You have two solutions here: one where the addition sign is used and one

where the subtraction sign is used. To match the initial condition that y(0) =

–1, however, only one solution will work. Which one? The one using the sub-

traction sign:

y = 1 - 3x

3

\+ 3x + 4x + 4

2

In this case, the solution with the subtraction is valid as long as the expres-

sion under the square root is positive — in other words, as long as x > –1.

You can see the direction field for the general solutions to this differential

equation in Figure 3-2.





47

**Chapter 3: Sorting Out Separable First Order Differential Equations**

**Figure 3-2:**

The

direction

field of a

separable

equation

with initial

conditions.

As I note in Chapter 1, connecting the slanting lines in a direction field gives

you a graph of the solution. You can see a graph of this particular function in

Figure 3-3.

**Figure 3-3:**

A graph of

the solution

of a

separable

equation

with initial

conditions.





48

**Part I: Focusing on First Order Differential Equations**

Tough to crack: When you can’t find an

explicit solution

Most of the time, you can find an explicit solution from an implicit solution.

But every once in a while, getting an explicit solution is pretty tough to do.

Here’s an example:

dy

dx

ysinx

= ~~\_~~

~~i~~

1 + 2y

2

where y(0) = 1.

As you get down to work (bringing to bear all your differential equation skills!),

the first thing that may strike you is that this equation isn’t linear. But, you’ll

also likely note that it’s separable. So simply separate the equation into y on

the left and x on the right, which gives you this equation:

\_

i

1 + 2 y

2

dy

= sinx dx

y

This equation subsequently becomes

dy

y

\+ 2y dy = sinx dx

Now you can integrate to get this:

ln|y| + y = –cos x + c

2

Next, take a look at the initial condition: y(0) = 1. Plugging that condition into

your solution gives you this equation:

0 + 1 = –1 + c

or

c = 2

So your solution to the initial separable equation is:

ln|y| + y = –cos x + 2

2

This is an implicit solution, not an explicit solution, which would be in terms

of y = f(x). In fact, as you can see from the form of this implicit solution, get-

ting an explicit solution would be no easy task.





49

**Chapter 3: Sorting Out Separable First Order Differential Equations**

However, never fear the implicit solution! You still can use numerical or graphi-

cal methods to deal with such solutions. For instance, take a look at the direc-

tion field for this differential equation, which indicates what the integral curves

look like, in Figure 3-4.

3

2

**y**

1

0

**Figure 3-4:**

The

direction

field of a

separable

equation

–1

with a hard- –2

to-find

explicit

solution. –3

–4

–3

–2

–1

0

1

**x**

2

3

4

A neat trick: Turning nonlinear separable

equations into linear separable equations

In this section, I introduce you to a neat trick that helps with some differen-

tial equations. With it, you can make a linear equation out of a seemingly non-

linear one. All you have to do to use this trick is to substitute the following

equation, in which v is a variable:

y = xv

In some cases, the result is a separable equation.

As an example, try solving this differential equation:

dy 2y

dx

4

\+ x

3

4

\=

xy





50

**Part I: Focusing on First Order Differential Equations**

At first glance, this equation doesn’t look separable. In fact, even if you break

it out into two fractions, it still doesn’t look separable:

dy 2y

= x +

dx

x

y

3

3

What do you do now? Keep reading to find out.

Knowing when to substitute

You can use the trick of setting y = xv when you have a differential equation

that’s of the following form:

dy

dx

\_

i

= f x,y

when f(x, y) = f(tx, ty), where t is a constant.

You can see that substitution is possible, because substituting tx and ty into

this differential equation gives you the following result:

dy 2t

dx

4

y

4

\+ t

4

x

4

\=

txt

3

y

3

which breaks down to:

dy 2y + x

xy

Substituting y = xv into this differential equation gives you:

4

4

\=

dx

3

^

h

4

2 xv + x

4

dv

dx

v + x

\=

^

h

3

x xv

This equation now can be simplified to look like this:

dv

dx

v + 1

4

x

\=

v

3

You now have a separable equation!

Separating and integrating

Continuing with the example from the previous section, you can now sepa-

rate the terms, which gives you:

dx

~~x~~  =

v

3

dv

v

4

\+ 1





51

**Chapter 3: Sorting Out Separable First Order Differential Equations**

After you integrate both sides, you get the following equation:

^ h ln\_v

\+ 1i

4

ln x =

\+ c

4

where c is a constant of integration. Bearing in mind that, where k is a constant:

ln(x) + ln(k) = ln(kx)

and that:

n ln(x) = ln(x

you get:

\+ 1 = (kx)

n

)

v

4

4

where:

c = –ln(k)

Where does all this get you? You’re ready to substitute with the following:

y

x

v =

This substitution gives you:

4

d y n

^

h

4

\+ 1 = kx

x

So:

y

4

\+ x

where m = k

y = (mx

And there’s your solution. Nice work!

4

= mx

. And solving for y gives you the following:

– x

8

4

8

4 1/4

)





52

**Part I: Focusing on First Order Differential Equations**

Trying Out Some Real World

Separable Equations

In the following sections, I take a look at some real world examples featuring

separable equations.

Getting in control with a sample

flow problem

To understand the relevance of differential equations in the real world, here’s

a sample problem to ponder: Say that you have a 10-liter pitcher of water, and

that you’re mixing juice concentrate into the pitcher at the same time that

you’re pouring juice out. If the concentrate going into the pitcher has

sugar per liter, the rate at which the concentrate is going into the pitcher,

which I’ll call rin, is 100 liter per second, and the juice in the pitcher starts off

1

⁄ kg of

4

1⁄

with 4 kg of sugar, find the amount of sugar in the juice, Q, as a function of

time, t.

Because this problem involves a rate — dQ/dt, which is the change in the

amount of sugar in the pitcher — it’s a differential equation, not just a simple

algebraic equation. I walk you through the steps of solving the equation in

the following sections.

Determining the basic numbers

When you start trying to work out this problem, remember that the change in

the amount of sugar in the pitcher, dQ/dt, has to be the rate of sugar flow in

minus the rate of sugar flow out, or something like this:

dQ

dt

\_

i

\_

i

= rate of sugar flow in - rate of sugar flow out

Now you ask: What’s the rate of sugar flow in? That’s easy; it’s just the con-

centration of sugar in the juice concentrate multiplied by the rate at which

the juice concentrate is flowing into the pitcher, which I’ll call rin. So, your

equation looks something like this:

\_

i

r

4

rate of sugar flow in = in kg/sec

Now what about the flow of sugar out? The rate of sugar flow out is related to

the rate at which juice leaves the pitcher. So if you assume that the amount of

juice in the pitcher is constant, then rin = rout = r. That, in turn, means the rate





53

**Chapter 3: Sorting Out Separable First Order Differential Equations**

of sugar flow out is the rate at which the juice leaves the pitcher, r, multiplied

by the concentration of sugar in the juice, which is Q divided by the capacity

of the pitcher (10 liters), or Q/10. Here’s what your equation would look like:

\_

i

Q

10

rate of sugar flow out =

r kg/sec

So that means:

dQ

dt

\_

i

\_

i

r

4

Qr

10

= rate of sugar flow in - rate of sugar flow out =

\-

where the initial condition is:

Q0 = 4 kg

Solving the equation

The equation at the end of the previous section is separable, and separating

the variables, each on their own side, gives you this equation:

dQ Qr

r

4

\+

\=

dt

10

Now that, you might say, is a linear differential in Q. And you’d be right. So you

know that the equation is both linear and separable.

You can handle this differential equation using the methods in Chapter 2. For

instance, to solve, you find an integrating factor, multiply both sides by the

integrating factor, and then see if you can figure out what product the left

side is the derivative of and integrate it. Whew! It sounds rough, but note that

the equation is of the following form:

dy

dt

\+ ay = b

The solution to this kind of differential equation is already found in Chapter 2;

you use an integrating factor of eat. The solution to this kind of equation is:

y = (b/a) + ce–at

So you can see that the solution to the juice flow problem is:

Q(t) = 2.5 + ce–rt/10

Because r = ⁄100 liter per second, the equation becomes:

1

Q(t) = 2.5 + ce–t/1000





54

**Part I: Focusing on First Order Differential Equations**

And because the initial condition is:

Q0 = 4 kg

you know that:

Q = 2.5 + 1.5 e–t/1000

Note the solution as t → is 2.5 kg of sugar, and that’s what you’d expect.

Why? Because the concentrate has kg of sugar per liter, and 10 liters of

∞

1⁄

4

water are in the pitcher. So 10/4 = 2.5 kg.

The direction field for different values of Q0 appears in Figure 3-5. Notice that

all the solutions tend toward the final Q of 2.5 kg of sugar, as you’d expect.

**Figure 3-5:**

The

direction

field of a

flow

problem

solution.

You can see a graph of this solution in Figure 3-6.





55

**Chapter 3: Sorting Out Separable First Order Differential Equations**

**Figure 3-6:**

The graph of

the solution

of a flow

problem.

Striking it rich with a sample

monetary problem

You may not have realized that differential equations can be used to solve

money problems. Well they can! And here’s a problem to prove it: Say that

you’re deciding whether to deposit your money in the bank. You can calcu-

late how your money grows, dQ/dt, given the interest rate of the bank and the

amount of money, Q, that you have in the bank. As you can see, this is a job

for differential equations.

Figuring out the general solution

Suppose your bank compounds interest continuously. The rate at which your

savings, Q, grows, is:

dQ

dt

= rQ

where r is the interest rate that your bank pays.





56

**Part I: Focusing on First Order Differential Equations**

This equation says that the rate at which your money grows is equal to the

interest rate multiplied by the current amount of money you have. That’s an

equation for the rate at which your money grows, not the actual amount of

money.

Say that you have Q0 money at t = 0:

Q(0) = Q0

How much money would you have at a certain time in the future? That’s easy

enough to figure out. Separate the variables, each on their own side, like this:

dQ

Q

= r dt

Then integrate:

ln|Q| = rt

Finally, exponentiate both sides, which gives you the following equation:

Q = cert

To match the initial condition:

Q(0) = Q0

the solution becomes:

Q = Q0ert

So, in other words, your money would grow exponentially. Not bad.

Compounding interest at set intervals

Now I want you to examine the result from the previous section a little, deriv-

ing it another way so that it makes more sense. If your bank compounded

interest once a year, not continuously, after t years, you’d have this much

money:

Q = Q0(1 + r)

t

That’s because if your interest was 5 percent, after the first year, you would

have 1.05Q0; at the end of the second year, 1.05 Q0, and so on.

2





57

**Chapter 3: Sorting Out Separable First Order Differential Equations**

What if your bank compounded interest twice a year? Would you have this

much at the end of t years:

Q = Q0(1 + r)2t

No, you wouldn’t. Why? Because that would pay you r percent interest twice

a year. For example, if r = 8 percent, the previous equation would pay you 8

percent of your total savings twice a year. Instead, banks divide the interest

rate they pay you by the number of times they compound per year, like this:

c

r

2

m

2t

Q = Q 1 +

0

In other words, if the bank compounds twice a year, and the annual interest

rate is 8 percent, six months into the year it pays you 4 percent, and at the

end of the year it pays another 4 percent.

In general, if your bank compounds interest m times a year, after t years,

you’d have:

c

r

m

mt

Q = Q 1 +

~~m~~

0

If you take the limit as m → — that is, as your bank starts to compound

∞

continuously — you get this equation:

c

r

m

mt

Q = lim Q 1 +

~~m~~

0

m " 3

But that’s just the expansion for ert. So, as the bank compounds continuously,

you get:

c

r

m

mt

Q = lim Q 1 +

= Q0 ert

~~m~~

0

m " 3

And this result confirms the answer you got from solving the differential

equation in the previous section.

So if you had $25 invested, and you left it alone at 6 percent for 60 years,

you’d have:

Q = Q0ert = 25e0.06(60)

or:

Q = Q0ert = 25e0.06(60) = $914.96

Hmm, not such a magnificent fortune.





58

**Part I: Focusing on First Order Differential Equations**

Adding a set amount of money

How about if you add a set amount every year to the equation in the previous

section? That would be better, wouldn’t it? Say that you add $5,000 a year. In

that case, remember that the set amount would change the differential equa-

tion for your savings, which was this:

dQ

dt

= rQ

The equation would change to this, where k is the amount you contribute

regularly:

dQ

dt

= rQ + k

If you deposit regularly, k > 0; if you withdraw regularly, k < 0. Ideally, you

should add or subtract k from your account continuously over the year to

make your solution exact, but here you can just assume that you add or sub-

tract k once a year.

Putting this new equation into standard separable form gives you this:

dQ

dt

\- rQ = k

This equation is of the following form:

dy

dt

\+ ay = b

The solution to this kind of equation is:

y = (b/a) + ce–at

In this case, that solution means:

Q = cert – k/r

What’s going on here? It looks like you have the solution for leaving money in

the bank without adding anything minus the amount you’ve added. Can that

be right? The answer is in c, the constant of integration. Here, the initial con-

dition is:

Q(0) = Q0

which means that:

Q(0) = cer0 – k/r = c – k/r = Q0





59

**Chapter 3: Sorting Out Separable First Order Differential Equations**

or to simplify things:

c = Q0 + k/r

So your solution turns out to be:

Q = cert – k/r = (Q0 + k/r)ert – k/r

Working this out gives you:

\_

i

\_

e

rt - 1i

k

Q = Q + k/r ert - k/r = Q0 ert

\+

r

0

That looks a little better! Now the first term is the amount that you’d earn if

you just left Q0 in the account, and the second term is the amount resulting

from depositing or withdrawing k dollars regularly.

For example, say you started off with $25, but then you added $5,000 every

year for 60 years. At the end of 60 years at 6 percent, you’d have:

k\_

rt - 1i = 25e0.06 (60)

5,000\_

0.06

e

0.06 (60) - 1i

Q = Q0 ert

\+

e

\+

r

After calculating this out, you’d get:

5,000\_

0.06

e

0.06 (60) - 1i = $914.96 + $2,966,519 = $2,967,434

Q = 25e0.06 (60)

\+

Quite a tidy sum.

Break It Up! Using Partial Fractions

in Separable Equations

When a term in a separable differential equation looks a little difficult to inte-

grate, you can use the method of partial fractions to separate it. This method

is used to reduce the degree of the denominator of a rational expression.

For example, using the method of partial fractions, you can express:

6

x

2

\+ 2x - 8

as the following equation:

6

1

1

\=

\-

x + 2x - 8 x - 2 x + 4

2





60

**Part I: Focusing on First Order Differential Equations**

Note that the power of the denominator has been reduced by one. You’ll

often see the method of partial fractions used when solving differential equa-

tions involving fractions, because using this method makes integrating the

resulting two terms a lot easier.

Here’s an example:

dy

dx

2xy

\=

x

2

\-

y

2

You’re probably screaming at your book right now. That’s not separable, you

say. However, perhaps you’ve also noticed that this equation is of the follow-

ing form:

dy

dx

\_

i

= f x,y

And f(x, y) = f(tx, ty), where t is a constant. So you now have this equation:

dy

dx

2txty

2xy

\=

\=

t

2

x

2

\-

t

2

y

2

x

2

\-

y

2

Yep, you guessed it: This equation calls for the old trick of substituting y = vx.

(See the earlier section “A neat trick: Turning nonlinear separable equations

into linear separable equations” for details.) Substituting y = vx into this dif-

ferential equation gives you the following equation:

^

h

2x xv

dv

dx

v + x

\=

^

h

2

x

2

\- xv

or to simplify matters:

dv

dx

2v

\-

v + x

\=

1

v

2

By subtracting the term on the right and adding to the left, you get the

following:

~~\_~~

~~i~~

v v

2

\+ 1

dv

dx

x

\+  ~~\_~~

~~i~~  = 0

v

2

\-

1

Flipping the fractions gives you:

dx

v

2

\- 1

2

~~\_~~

\+ 1~~i~~ dv = 0

~~x~~

\+

v v





61

**Chapter 3: Sorting Out Separable First Order Differential Equations**

Time to use the method of partial fractions. In this case, you get the following

equation:

dx

v

2

\- 1

2

dx d  2v

v + 1

1 n

~~\_~~

\+ 1~~i~~ dv =

\+

\-

dv = 0

~~x~~

\+

~~x~~

~~v~~

v v

2

or to simplify:

dx 2v dv dv

~~x~~

\+

\-

~~v~~

= 0

v

2

\+ 1

Ah, much better. Now you can integrate! Integrating all these terms gives you:

ln|x| + ln|v

2

\+ 1| – ln|v| = c

or:

ln|x| + ln|v

2

\+ 1| = ln|v| + c

Exponentiating both sides gives you this equation:

x(v + 1) = kv

where k = e

Substituting v = y/x gives you the following:

2

c.

\_

i

x y

2

\+ x

2

ky

= x

x

2

The previous equation can then be simplified to the implicit solution of the

following:

y

2

\+ x

or to simplify even further:

– ky + x = 0

2

= ky

y

2

2

Finally, you can solve using the quadratic equation to get the following

explicit solution:

k !

k

2

\- 4x

2

y =

2





62

**Part I: Focusing on First Order Differential Equations**





**Chapter 4**

**Exploring Exact**

**First Order Differential**

**Equations and Euler’s Method**

In This Chapter

` `Understanding the fundamentals of exact differential equations

` `Figuring out whether differential equations are exact

` `Turning nonexact equations into exact equations with integrating factors

` `Crunching numbers with Euler’s method

` `Digging into difference equations

N

ot all first order differential equations are linear (see Chapter 2) or

separable (see Chapter 3). So sometimes you have to use other tools to

solve first order differential equations. One of those tools is knowing how

to solve exact differential equations. That’s what I introduce you to in this

chapter. And for those really intractable (a.k.a. difficult) differential equa-

tions, you also get an introduction to working with mathematical methods. In

particular, you find out how to use Euler’s method to approximate solutions

to just about any differential equation (assuming it has a solution!). And you

find out that Euler’s method is a type of difference equation (don’t worry;

I explain everything).

Exploring the Basics of Exact

Differential Equations

One of the most powerful methods for working with differential equations is

seeing whether they’re exact, and if they are, you can tackle them. I explain

the basics in the following sections.





64

**Part I: Focusing on First Order Differential Equations**

Defining exact differential equations

To solve an exact differential equation, you have to find a function whose

partial derivatives correspond to the terms in the differential equation. For

example, assume that you have a differential equation of this form:

\_

i

\_

i dy

M x,y + N x,y

= 0

dx

where M and N are functions.

Now suppose that you can find a function f(x, y) such that the following equa-

tions are true:

\_

i

i

2f x,y

2x

\_

i

= M x,y

\_

2f x,y

2y

\_

i

= N x,y

Note that the previous two equations are partial derivatives with respect

to x, so I include the symbol ∂. (Check out Chapter 1 for more about partial

derivatives.)

The differential equation that you’re trying to solve becomes:

\_

i

\_

i

2f x,y

2x

2f x,y

2y

dy

dx

\+

= 0

which is equal to (**note:** ordinary derivatives now):

\_

i

df x,y

= 0

dx

So the solution, after integration, is:

f(x, y) = c

The previous solution is at least the implicit solution; you may have to move

things around a bit to get the actual explicit solution. (As I explain in Chapter 3,

implicit solutions aren’t in the form y = f(x), but explicit solutions are.)

Here’s the point: If you can find a function f such that a differential equation

can be reduced to the following form:

\_

i

df x,y

= 0

dx

then the differential equation is said to be exact.





65

**Chapter 4: Exploring Exact First Order Differential Equations and Euler’s Method**

Working out a typical exact

differential equation

Exact differential equations can be tough to solve, so in this section, I provide

a typical example so you can get the hang of it. Check out this differential

equation:

dy

dx

4x + 2y

2

\+ 4xy

= 0

This equation isn’t linear, and it also isn’t separable. However, you may sus-

pect that the equation is exact. So, if that’s the case, how do you solve it?

You might note that this function has some interesting properties:

f(x, y) = 2x

2

\+ 2xy

2

In particular, note that ∂f/∂x (**note:** this is the partial derivative with respect

to x) is:

2f

2x

= 4x + 2y

2

Those are the first two terms of the equation you’re looking to solve. Also,

note that

2f

2y

= 4xy

which looks a lot like the third term in the original equation. So you could

write the equation like this:

dy

2f

2f

\+

= 0

2x 2y dx

You’re making progress! Note that because y is a function of f, you can use the

chain rule (see Chapter 3) and switch to ordinary derivatives, meaning that

you can write the original equation like this:

df

dx

= 0

where

f(x, y) = 2x

2

\+ 2xy

2





66

**Part I: Focusing on First Order Differential Equations**

The ordinary derivative I just gave you is easy to integrate, so you get the fol-

lowing equation:

2x

2

\+ 2xy = c

2

where c is a constant of integration. That’s the implicit solution. Now you can

divide by 2, absorbing that 2 into c, which gives you:

x

2

\+ xy = c

2

So that’s your implicit solution. But it’s easy to solve for y, as you can see in

this equation:

c - x

2

y =

x

Determining Whether a Differential

Equation Is Exact

As you can see from the previous section, knowing when a differential equa-

tion is exact is helpful. But just when is it exact? Keep reading to find out.

Checking out a useful theorem

How can you tell, in a systematic way, whether a differential equation is

exact? You’re in luck: It turns out that there’s a handy theorem to determine

whether a differential equation is exact, and here it is:

**If the functions M, N,** o**M/**o**y, and** o**N/**o**x are continuous in a rectangle R,**

**then this differential equation:**

\_

i

\_

i **dy**

**M x,y** + **N x,y**

= **0**

**dx**

**is an exact differential equation in the rectangle R if and only if:**

\_

i

\_

i

o**M x,y**

o**y**

o**N x,y**

o**x**

\=

**at every point in R.**





67

**Chapter 4: Exploring Exact First Order Differential Equations and Euler’s Method**

In other words, if you have the differential equation

\_

i

\_

i dy

M x,y + N x,y

= 0

dx

there exists a function f(x, y) in a rectangle R such that:

\_

i

2f x,y

2x

\_

i

= M x,y

and

\_

i

2f x,y

2y

\_

i

= N x,y

if and only if:

\_

i

\_

i

2M x,y

2y

2N x,y

2x

\=

in the rectangle R.

So how do you solve exact differential equations? You have to solve the par-

tial differential equation:

\_

i

2f x,y

2x

\_

i

= M x,y

and

\_

i

2f x,y

2y

\_

i

= N x,y

And if you can find it, the implicit solution is f(x, y) = c.

Applying the theorem

So how about an example that shows how to apply the theorem in the previ-

ous section? Take a look at this differential equation:

2xy + \_1 + x

i dy

= 0

2

dx





68

**Part I: Focusing on First Order Differential Equations**

In other words:

M(x, y) = 2xy

and

N(x, y) = (1 + x

2

)

Note that

\_

i

\_

i

2M x,y

2N x,y

2x

\=

= 2x

2y

So now you know that the differential equation is exact. And now you need to

find M(x, y) and N(x, y) such that:

\_

i

2f x,y

2x

\_

i

= M x,y

and

\_

i

2f x,y

2y

\_

i

= N x,y

When you find f(x, y), the solution to the original equation is

f(x, y) = c

Start by finding f(x, y). Because

M(x, y) = 2xy

that means

\_

i

2f x,y

2x

= 2xy

Integrating both sides of the previous equation gives you:

f(x, y) = x y + g(y)

2

where g(y) is a function that depends only on y, not on x. So what’s g(y)? You

know that:

\_

i

2f x,y

2y

\_

i

= N x,y





69

**Chapter 4: Exploring Exact First Order Differential Equations and Euler’s Method**

and

N(x, y) = (1 + x )

2

or

\_

i

2f x,y

2y

= \_1 + x

i

2

Because you know that

f(x, y) = x y + g(y)

you get this equation:

2

\_

i

2f x,y

2y

2g

2y

\_ i

= x

2

\+

y = 1 + x

2

By canceling out the x2

, you get

2g

2y

\_ i

y = 1

Fortunately, this equation is easy enough to integrate. Integrating it gives

you this:

g(y) = y + d

where d is a constant of integration. And because

f(x, y) = x

you get:

f(x, y) = x

2

y + g(y)

2

y + y + d

Whew. You now know that the solution to f(x, y) = x y + g(y) is:

2

f(x, y) = c

So

2

x y + y = c

where the constant of integration d has been absorbed into the constant of

integration c.





70

**Part I: Focusing on First Order Differential Equations**

As you recall from the earlier section “Defining exact differential equations,”

finding f(x, y) gives you the implicit solution to the exact differential solution

you’re trying to solve. Happily, x y + y = c is easy to solve for y in terms of x,

2

giving you:

c

y = ~~\_~~

~~i~~

1 + x

2

And that, my friends, is the explicit solution to your original equation. Cool!

Conquering Nonexact Differential

Equations with Integrating Factors

The earlier sections in this chapter cover exact differential equations. But

what about those equations that don’t look exact but can be converted into

exact equations? Yes, you read that right! Sometimes, differential equations

are intractable and not exact. For example, that’s the case with this differen-

tial equation:

dy

dx

y - x

= 0

You start off by checking this differential equation for exactness, meaning

that you have to cast it in this form:

\_

i

\_

i dy

M x,y + N x,y

= 0

dx

So, in the case of the example:

M(x, y) = y

and

N(x, y) = –x

The differential equation is exact if:

\_

i

\_

i

2M x,y

2y

2N x,y

2x

\=

But these two aren’t equal; rather:

\_

i

2M x,y

2y

= 1





71

**Chapter 4: Exploring Exact First Order Differential Equations and Euler’s Method**

and

\_

i

2N x,y

2x

= -1

As you can see, the original equation isn’t exact. However, the two partial

derivatives, ∂M/∂x and ∂N/∂y, differ only by a minus sign. Isn’t there some

way of making this differential equation exact?

Yup, you’re right. There is a way! You just have to use an integrating factor.

As I discuss in Chapter 2, integrating factors are used to multiply differential

equations to make them easier to solve. In the following sections, I explain

how to use an integrating factor to magically turn a nonexact equation into

an exact one.

Finding an integrating factor

How can you find an integrating factor that makes differential equations

exact? Just follow the steps in the following sections.

Multiplying by the factor you want to find

Using the example from earlier, here I show you how to find an integrating

factor that makes differential equations exact. Say you have this differential

equation:

\_

i

\_

i dy

M x,y + N x,y

= 0

dx

Multiplying this equation by the integrating factor µ(x, y) (which you want to

find) gives you this:

\_

i

\_

i

\_

i

\_

i dy

µ x,y M x,y + µ x,y N x,y

= 0

dx

This equation is exact if:

a \_

i

\_

ik

a \_

i

\_

ik

2 µ x,y M x,y

2 µ x,y N x,y

\=

2y

2x

which means that µ(x, y) must satisfy this differential equation:

R

V

a

\_

ik

\_

i

\_

i

\_

i

\_

i 2µ

\_

i 2µ

x,y

2x

S 2

M x,y

N x,y

2x

W

\_

i

x,y

2y

2

M x,y

\- N x,y

\+ S

\-

Wµ x,y = 0

2y

S

W

S

W

X

T





72

**Part I: Focusing on First Order Differential Equations**

Well, yipes. That doesn’t seem to have bought you much simplicity. In fact,

this equation looks more complex than before. What you have to do now is to

assume that µ(x, y) is a function of x only — that is, µ(x, y) = µ(x) — which

also means that:

^ h

2µ x

2y

= 0

This turns the lengthy and complex equation into the following:

^ h

\_

i

\_

i

J

N

i 2µ x

2M x,y

2y

2N x,y

2x

^ h

\_

K

O

-N x,y

\+

\-

µ x = 0

2x

K

O

P

L

Or in other words:

^ h

\_

i

\_

i

J

N

i 2µ x

2M x,y

2y

2N x,y

^ h

\_

K

O

N x,y

\=

\-

µ x

2x

K

2x

O

L

P

Dividing both sides by N(x, y) to simplify means that:

^ h

\_

i

\_

i

J

N

2µ x

2x

2M x,y

2y

2N x,y

2x

^ h

1

K

O

\=

\_

i

\-

µ x

K

O

P

N x,y

L

Well, that looks somewhat better. You can see how to finish the example in

the next section.

Completing the process

Remember the differential equation that you’re trying to solve? If not, here it is:

dy

dx

y - x

= 0

In this case,

M(x, y) = y

and

N(x, y) = –x

Plug these into your simplified equation from the previous section, which

becomes:

^ h

2µ x

2x

`

^

hj ^ h

-1

\=

~~x~~

1 - -1 µ x





73

**Chapter 4: Exploring Exact First Order Differential Equations and Euler’s Method**

or:

^ h

2µ x

2x

^ h

-2

\=

~~x~~

µ x

Now this equation can be rearranged to get this one:

~~^ h~~

2µ x

µ x

2x

~~^ h~~

= -2

~~x~~

Integrating both sides gives you:

ln|>(x)| = –2 ln|x|

And finally, exponentiating both sides results in this equation:

^ h

1

!µ x =

x

2

For this differential equation:

\_

i

2M x,y

2y

= 1

and

\_

i

2N x,y

2x

= -1

Because these equations differ by a sign, you may suspect that you need the

negative version of µ(x), meaning that:

^ h

1

µ x = -

x

2

So that, at last, is your integrating factor. Whew!

Using an integrating factor

to get an exact equation

To carry on from the example in the previous section: Multiplying your original

equation by your integrating factor gives you this new differential equation:

-y

x

dy

dx

1

\+

2

x

= 0





74

**Part I: Focusing on First Order Differential Equations**

Is this exact? To find out, consider that

\_

i

-y

M x,y =

x

2

and

\_

i

1

N x,y =

x

The differential equation is exact if:

\_

i

\_

i

2M x,y

2y

2N x,y

2x

\=

You can now see that these two terms are equal, because:

\_

i

2M x,y

2y

-1

2

\=

x

and

\_

i

2N x,y

2x

-1

2

\=

x

So the integrating factor, –1/x , did the trick, and the equation is now exact.

2

The finishing touch: Solving the

exact equation

The last step is to solve the exact equation as I explain earlier in this chapter.

In other words, you have to solve it by finding a function f(x, y) = c such that:

\_

i

i

2f x,y

2x

\_

i

= M x,y

and

\_

2f x,y

2y

\_

i

= N x,y

As noted in the previous section,

\_

i

y

M x,y = -

x

2

which means that

\_

i

2f x,y

2x

y

= -

x

2





75

**Chapter 4: Exploring Exact First Order Differential Equations and Euler’s Method**

Integrating both sides of the equation gives you:

\_

i

y

\_ i

f x,y = + g y

x

And because, using the info from the previous section:

\_

i

2f x,y

2y

\_

i

1

= N x,y =

x

you can see that

g(y) = d

where d is a constant of integration. So f(x, y) must be:

\_

i

y

f x,y = + d

x

As you recall from the earlier section “Defining exact differential equations,”

the implicit solution of an exact differential equation is:

f(x, y) = c

So:

y

x

= c

where the constant d has been absorbed into the constant c. Now you know

that the explicit solution to the exact equation is:

y = cx

Cool. The solution turned out to be simple.

Getting Numerical with Euler’s Method

Face it: Sometimes, you just can’t find a solution to some differential equa-

tions. Or, at best, you may only be able to find an implicit one. So what do

you do? In that case, it could be time to turn to numerical methods — that is,

using a computer.

I know, using a computer feels a lot like a cop-out, but sometimes you have

no other choice. Chapters 1, 2, and 3 all contain examples where I used a

computer to calculate direction fields and plot some actual solutions. Now, in

the following sections, I introduce one simple numerical method of solving

differential equations. This method is called Euler’s method.





76

**Part I: Focusing on First Order Differential Equations**

**So who was this Euler guy?**

Leonhard Paul Euler (1707–1783) was a Swiss and graph theory. He’s also responsible for

mathematician who lived, for the most part, in much of the mathematical terminology that

Russia and Germany. He was an important people take for granted, such as the notation

genius who contributed to physics, calculus, used for mathematical functions.

Understanding the method

Euler’s method basically says “Hey, you may not have the actual curve that

represents the solution to your differential equation, but you have the slope

of that curve everywhere (because the slope — the rate of change of the

curve — is the derivative).”

To better understand what I mean, say that you have the following general

differential equation:

dy

dx

\_

i

= f x,y

And suppose that you have a point, (x , y ), that’s on the solution curve.

0

0

Because of your differential equation, you know that the slope of the solution

curve at that point is f(x , y ).

0

0

Now imagine that you want to find the solution at a point, (x, y), a short dis-

tance away. Here’s how you might find y:

y = y0 + ∆y

Anything with the symbol ∆ signifies change. So, ∆y means a change in y.

Because the slope, m, is defined as ∆y/∆x, this equals (for small ∆x):

y = y0 + m ∆x

And because ∆x = x – x0, you have:

y = y + m (x – x )

0

0

Because the slope, m, is equal to the derivative at (x , y ), and because of

0

0

your original equation, m = f(x , y ), you get:

0

0

y = y + f(x , y ) (x – x )

0

0

0

0





77

**Chapter 4: Exploring Exact First Order Differential Equations and Euler’s Method**

So if you keep (x – x0) small, this approximation should be close. All it’s doing

is using the slope to extrapolate (x , y ) to a new point nearby, (x, y). This

0

0

process is illustrated in Figure 4-1.

**Figure 4-1:**

Euler’s

method at

work.

If you call ∆x by the term h, as it’s often referred to when using Euler’s

method, you get this:

y = y + f(x , y ) h

1

0

0

0

And in general, you can find any point along the solution curve like this,

when using Euler’s method:

yn+1 = y + f(x , y ) h

n

n

n

Checking the method’s accuracy

on a computer

In this section, I put Euler’s method to work, finding a solution to the follow-

ing differential equation:

dy

dx

= x

where

y(0) = 0





78

**Part I: Focusing on First Order Differential Equations**

In fact, you already know the solution by simply integrating:

x

2

y =

2

Because you know the solution, you can now check the accuracy of Euler’s

method. And you’re in luck, because here I show you how to develop a short

program that uses Euler’s method to solve differential equations. I developed

this program using the Java programming language (which you can get for

free at java.sun.com; just click the Java SE link under the Downloads tab).

You don’t have to know Java to use this book — the programming in this sec-

tion is only a demonstration. But because numerical methods of solving dif-

ferential equations require a computer, I use a programming language to get

things working. You can skip this part if you aren’t interested.

Defining initial conditions and functions

The Java program starts by defining the initial condition point — which is a

solution point for the differential equation, by definition — (x , y ). Then it

0

0

defines the step size, h, and the number of steps you want to take, n. So, for

example, if you have the initial point at (0, 0), and you want the solution at

(10, y), your step size is 0.1, and you need n = 100 steps:

double x0 = 0.0;

double y0 = 0.0;

double h = 0.1;

double n = 100;

At this point, the program also defines a Java function, f(x, y), that returns the

value of the derivative at any point (x, y):

public double f(double x, double y)

{

return x;

}

Because you know the exact solution, you’ll also set up a Java function to

return the exact solution at any point so you can compare it to the Euler’s

method value:

public double exact(double x, double y)

{

return x \* x / 2;

}





79

**Chapter 4: Exploring Exact First Order Differential Equations and Euler’s Method**

The actual work is done in a Java function named “calculate.” In this function,

each step using Euler’s method is calculated and displayed, like this:

public void calculate()

{

double x = x0;

double y = y0;

double k;

System.out.println(“x\t\tEuler\t\tExact”);

for (int i = 1; i < n; i++){

k = f(x, y);

y = y + h \* k;

x = x + h;

System.out.println(round(x) + “\t\t” + round(y) +

“\t\t” + round(exact(x, 0)));

}

}

The program also has a function named “round,” which rounds values to two

decimal places for the printout:

public double round(double val)

{

double divider = 100;

val = val \* divider;

double temp = Math.round(val);

return (double)temp / divider;

}

Examining the entire code

The following is the whole code, e.java, which is a short program for calculat-

ing differential equation solutions using Euler’s method. The parts you have to

change when you want to solve your own differential equations are in **bold:**

public class e

{

**double x0 = 0.0;**

**double y0 = 0.0;**

**double h = 0.1;**

**double n = 100;**

public e()

{





80

**Part I: Focusing on First Order Differential Equations**

}

public double f(double x, double y)

{

**return x;**

}

public double exact(double x, double y)

{

**return x \* x / 2;**

}

public static void main(String [] argv)

{

e de = new e();

de.calculate();

}

public void calculate()

{

double x = x0;

double y = y0;

double k;

System.out.println(“x\t\tEuler\t\tExact”);

for (int i = 1; i < n; i++){

k = f(x, y);

y = y + h \* k;

x = x + h;

System.out.println(round(x) + “\t\t” + round(y) +

“\t\t” + round(exact(x, 0)));

}

}

public double round(double val)

{

double divider = 100;

val = val \* divider;

double temp = Math.round(val);

return (double)temp / divider;

}

}

An example at work

In this section, I put the program to work. As it stands, e.java is set up with

the following differential equation:

dy

dx

= x





81

**Chapter 4: Exploring Exact First Order Differential Equations and Euler’s Method**

where

y(0) = 0

The program starts at (x , y ) = (0, 0), which you know is a point on the solu-

0

0

tion curve, and then it calculates 100 steps, each of ∆x = 0.1.

You start by using the Java compiler, javac.exe, to compile the code:

C:\>javac e.java

Then, you run the compiled code, e.class, using java.exe like this: java e. The

program then prints out the current x value, the Euler approximation of the

solution at that x value, and the exact solution, as you see here:

C:\>java e

x

Euler

0.0

0.01

0.03

0.06

0.1

0.15

0.21

0.28

0.36

0.45

0.55

0.66

0.78

0.91

1.05

1.2

Exact

0.01

0.02

0.05

0.08

0.13

0.18

0.24

0.32

0.4

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1.0

1.1

1.2

1.3

1.4

1.5

1.6

1.7

1.8

1.9

2.0

2.1

2.2

2.3

2.4

2.5

2.6

2.7

2.8

2.9

3.0

3.1

3.2

3.3

0.5

0.6

0.72

0.85

0.98

1.13

1.28

1.45

1.62

1.81

2.0

2.21

2.42

2.65

2.88

3.13

3.38

3.65

3.92

4.21

4.5

1.36

1.53

1.71

1.9

2.1

2.31

2.53

2.76

3.0

3.25

3.51

3.78

4.06

4.35

4.65

4.96

5.28

4.81

5.12

5.45





82

**Part I: Focusing on First Order Differential Equations**

3.4

3.5

3.6

3.7

3.8

3.9

4.0

4.1

4.2

4.3

4.4

4.5

4.6

4.7

4.8

4.9

5.0

5.1

5.2

5.3

5.4

5.5

5.6

5.7

5.8

5.9

6.0

6.1

6.2

6.3

6.4

6.5

6.6

6.7

6.8

6.9

7.0

7.1

7.2

7.3

7.4

7.5

7.6

7.7

7.8

7.9

8.0

8.1

8.2

8.3

8.4

5.61

5.95

6.3

6.66

7.03

7.41

7.8

8.2

8.61

9.03

9.46

9.9

10.35

10.81

11.28

11.76

12.25

12.75

13.26

13.78

14.31

14.85

15.4

5.78

6.13

6.48

6.85

7.22

7.61

8.0

8.41

8.82

9.25

9.68

10.13

10.58

11.04

11.52

12.0

12.5

13.0

13.52

14.04

14.58

15.12

15.68

16.24

16.82

17.4

15.96

16.53

17.11

17.7

18.0

18.6

18.3

18.91

19.53

20.16

20.8

19.22

19.84

20.48

21.12

21.78

22.44

23.12

23.8

21.45

22.11

22.78

23.46

24.15

24.85

25.56

26.28

27.01

27.75

28.5

24.5

25.2

25.92

26.64

27.38

28.12

28.88

29.64

30.42

31.2

32.0

32.8

33.62

34.44

35.28

29.26

30.03

30.81

31.6

32.4

33.21

34.03

34.86





83

**Chapter 4: Exploring Exact First Order Differential Equations and Euler’s Method**

8.5

8.6

8.7

8.8

8.9

9.0

9.1

9.2

9.3

9.4

9.5

9.6

9.7

9.8

9.9

35.7

36.12

36.98

37.84

38.72

39.6

40.5

41.4

42.32

43.24

44.18

45.12

46.08

47.04

48.02

49.0

36.55

37.41

38.28

39.16

40.05

40.95

41.86

42.78

43.71

44.65

45.6

46.56

47.53

48.51

So there you have it — Euler’s method looks pretty accurate for your differen-

tial equation’s solution. At x = 9.9, it’s off only by 1% (49.00 – 48.51). Not bad.

**Tip:** You can get even better accuracy by using smaller step sizes.

You have to be careful when it comes to step size. If you have a really steep

slope, you have to use a truly tiny step size to get the most accurate results.

Delving into Difference Equations

Euler’s method, which is discussed in the previous section, brings up an

interesting topic: difference equations. That’s correct, you read right —

“difference” equations. I know what you’re thinking: An explanation is in

order! Allow me to start at the beginning. Derivatives are built to work like

this, where ∆x → 0 and y = f(x):

~~^~~

~~h~~

~~^ h~~

dy

dx

f x + ∆x - f x

= lim

∆x

∆x " 0

However, sometimes, you don’t want ∆x to go to zero. In other words, some-

times it just makes sense to keep the step size, ∆x, discrete and nonzero. For

example, you can set up a differential equation to calculate the interest you

pay on a loan, but because ∆x → 0, the differential equation calculates the

interest as if it were compounded continuously. But what if the interest is

actually compounded monthly or annually? In that case, you should use ∆x =

1 month or 1 year, not ∆x → 0.

When ∆x doesn’t go to zero, you have a difference equation, not a differential

equation. I take some time to look at difference equations in the following

sections.





84

**Part I: Focusing on First Order Differential Equations**

Some handy terminology

Euler’s method is a good example of a difference equation, because every y

value depends on the previous y value:

yn+1 = y + f(x , y ) h

n

n

n

Here’s how it looks written as a difference equation, where the value yn+1 is

some function of yn:

yn+1 = f(n, yn)

**Note:** This is the kind of equation you’d use if interest was compounded

annually in a savings account instead of continuously. In that case, the future

value of the savings account, yn+1, depends on the current value, yn.

Just as with differential equations, you can apply some terminology to differ-

ence equations. In particular, the previous equation is a first order difference

equation. Why? Because it depends on y , not on earlier terms (y , y , and

n

n-1

n-2

so on). The equation is linear if f(n, y ) is linear in y . If f(n, y ) isn’t linear in y ,

n

n

n

n

the equation is nonlinear.

You can also have initial conditions for difference equations, such as the first

value being set to a constant:

y0 = c

Iterative solutions

Because a difference equation is defined using successive terms:

yn+1 = f(n, yn)

the solution is all the terms y , y , y . . . yn+1.

0

1

2

To make solving these kinds of equations a little more manageable, assume

that the function f in the original equation only depends on yn, not on n itself,

so you get:

yn+1 = f(yn)

So:

y = f(y )

1

0





85

**Chapter 4: Exploring Exact First Order Differential Equations and Euler’s Method**

and:

y = f(y )

2

1

which means that:

y = f(y ) = f(f(y ))

2

1

0

This equation is sometimes written as:

y = f(y ) = f(f(y )) = f (y0)

2

2

1

0

which is often called the second iterate of the difference equation’s solution,

written as f (y0).

2

Here’s the third iterate:

y = f(y ) = f(f(y )) = f(f(f(y )))

3

2

1

o

The third iterate can also be written using the f

y = f(y ) = f(f(y )) = f(f(f(y ))) = f (y0)

As long as yn+1 = f(yn), you can write the nth iterate as:

yn = f (y0)

n

( ) notation, like this:

3

3

2

1

0

n

Equilibrium solutions

It’s often important to know what happens as n →

∞. Does the series converge?

Does it diverge? The answer tells you whether you have a viable solution.

Sometimes, all the yn have the same value. In this case, the solution is said to

be an equilibrium solution. The series converges to that equilibrium solution.

So, every term is the same:

yn = f (y0)

n

and:

y = f(y )

n

n

I introduce some examples in the following sections.





86

**Part I: Focusing on First Order Differential Equations**

Working without a constant

To better understand equilibrium solutions, say, for example, that you have

savings in a bank that pays an interest rate, i, annually. The amount of money

you have in year, n + 1, is written like so:

yn+1 = (1 + i) yn

The solution of this difference equation is easy, because i is constant. Each

year’s savings is simply (1 + i) multiplied by the previous year’s savings. So

your equation looks like this:

yn = (1 + i) y0

n

∞

This means that the limiting value as n → depends on i.

For instance, if i is less than 0, you get:

lim y = 0

n

n " 3

If i is equal to 0, you get:

lim y = y

n

0

n " 3

Otherwise, you get:

lim y = nonexistent

n

n " 3

That is to say, the equilibrium solution is i = 0.

Working with a constant

Just for kicks, change the circumstances from the previous section. Say that

you increase your savings each year by adding a constant value, c. Your equa-

tion would now look like this:

yn+1 = (1 + i) yn + c

The solution to this difference equation is:

yn = (1 + i)

n

y0 + (1 + (1 + i) + (1 + i) + (1 + i)n-1)c

2

If i isn’t equal to 0, you can write the equation as:

^

h

n

^

h

1 + i - 1

n

y = 1 + i y0 +

c

n

i





87

**Chapter 4: Exploring Exact First Order Differential Equations and Euler’s Method**

For example, if you started with y0 = $1,000 and i = 5%, and you add $1,000 a

year for 10 years, you’d end up with an equation that looks like this:

^

h

n

^

h

1 + i - 1

\_

i

\_

i

1.62 - 1

n

y = 1 + i y0 +

c = 1.62 1,000 +

1,000

n

i

.05

or:

\_

i

1.62 - 1 \_

i

y = 1.62 1,000 +

1,000 = 1,620 + 12,400 = $14,020

n

.05

Not a bad return!





88

**Part I: Focusing on First Order Differential Equations**





**Par t II**

**Surveying Second**

**and Higher Order**

**Dif ferential**

**Equations**





In this part . . .

I

t’s time to up the ante with second order — and

higher — differential equations. A second order differ-

ential equation is one that involves a second derivative;

higher order equations involve three or more.

In this part, you discover that there are dazzling new tech-

niques to bring to bear with second and higher order

equations, such as the popular method of undetermined

coefficients and variation of parameters. Get set to exer-

cise your brain!





**Chapter 5**

**Examining Second Order**

**Linear Homogeneous**

**Differential Equations**

In This Chapter

` `Focusing on the fundamentals of second order linear differential equations

` `Getting a grip on constant coefficients

` `Exploring characteristic equations

` `Taking a crack at reduction of order

` `Understanding the Wronskian and other cool theorems

I

n Part I, I tell you what you need to know about a variety of first order dif-

ferential equations. Now you’re striking out into uncharted territory —

second order differential equations. These kinds of equations are based heav-

ily in physics — in wave motion, electromagnetic circuits, heat conduction,

and so on. They’re also fun and interesting. In this chapter, I walk you through

the fundamentals of second order linear homogeneous differential equations,

with a few useful tips and theorems thrown in along the way.

The Basics of Second Order

Differential Equations

To better understand second order differential equations, first take a look at

the following equation:

d

2

y

2

\_

i

= f x,y

dx





92

**Part II: Surveying Second and Higher Order Differential Equations**

As you can see, this equation has a second derivative, which makes it a

second order differential equation. But you know what? That’s not quite good

enough. The f(x, y) is okay for first order differential equations, but it isn’t

good enough for second order ones because the function f may also depend

on dy/dx. So the following is the general form of a second order differential

equation:

d

2

y

2

d

dy n

= f x,y,

dx

dx

In the following sections, I introduce several important types of second order

differential equations, including linear equations and homogeneous equations.

In this chapter, I focus on the second order linear homogeneous differential

equation (try saying that ten times fast!); if you can solve the homogeneous

form of a differential equation, you can always solve the same differential

equation as a nonhomogeneous differential equation (or at least give the solu-

tion in integral form). In other words, finding the solution to the homogeneous

differential equation is the fundamental part of solving second order differen-

tial equations. (I show you how to solve second order linear nonhomogeneous

differential equations in Chapter 6. As I note there, solving nonhomogeneous

equations usually involves solving the corresponding homogeneous equation

as well.)

Linear equations

I restrict this chapter to second order linear differential equations that have

the following form:

y" + p(x)y' + q(x)y = g(x)

where:

d y

2

y''=

dx

2

and:

dy

dx

yl=

However, a typical second order linear equation is sometimes written as the

following (who says that mathematicians don’t like to mix things up a bit?):

P(x)y" + Q(x)y' + R(x)y = G(x)





93

**Chapter 5: Examining Second Order Linear Homogeneous Differential Equations**

where P(x), Q(x), R(x), and G(x) are functions. The transition between the

original equation and the alternate is easy. Check it out:

~~^ h~~

~~^ h~~

~~^ h~~

^ h Q x

^ h R x

^ h G x

p x =  ~~^ h~~

q x =  ~~^ h~~

g x =  ~~^ h~~

P x

P x

P x

In this chapter, I show you only how to solve the typical second order linear

equation for regions where p(x), q(x), and g(x) are continuous functions, mean-

ing that their values don’t make discontinuous jumps. I also usually provide

initial conditions as well, such as:

y(x0) = y0

But that condition isn’t enough to specify the solution of a second order

linear differential equation. You also need to specify the value of y'(x0). That

value is usually something like this:

y'(x0) = y'0

Second order differential equations that aren’t in the form of y" + p(x)y' +

q(x)y = g(x) are called nonlinear.

Homogeneous equations

The equation y" + p(x)y' + q(x)y = g(x) is referred to as homogeneous if g(x) =

0; that is, the equation is of the following form:

y" + p(x)y' + q(x)y = 0

Alternately, using the P(x), Q(x), R(x), G(x) terminology from the previous

section, a homogeneous equation can be written as:

P(x) y" + Q(x)y' + R(x)y = 0

If second order linear differential equations can’t be put into either of these

forms, the equation is said to be nonhomogeneous. To find out how to solve

linear nonhomogeneous differential equations, check out Chapter 6.





94

**Part II: Surveying Second and Higher Order Differential Equations**

Second Order Linear Homogeneous

Equations with Constant Coefficients

You may think that second order linear homogeneous differential equations

are intimidating. But they really aren’t, if you know some fundamentals.

The best place to start solving second order differential equations is with

equations where P(x), Q(x), and R(x) are constants, a, b, and c. So, for exam-

ple, you get this equation when you include the constants:

ay" + by' + cy = 0

Okay, so you’ve narrowed things down. Now you’re talking about second

order linear homogeneous differential equations with constant coefficients.

Despite the hairy name, these equations are pretty easy to solve. In fact, you

can always solve an equation of this type using some elementary solutions

and initial conditions. Take a look at the examples in the following sections.

Elementary solutions

To get you up to speed, I begin with this typical equation:

y" – y = 0

Yes, this qualifies as a second order linear homogeneous differential equation.

Why? Just figure that a = 1, b = 0, and c = –1. There you have it.

To solve this differential equation, you need a solution y = f(x) whose second

derivative is the same as f(x) itself, because subtracting the f(x) from f"(x)

gives you 0.

You can probably think of one such solution: y = e

x

. Substituting y = e into the

x

equation gives you this:

e

x

– e

As you can see, y = e

In fact, y = c e (where c is a constant) is also a solution, because y" still

x

= 0

x

is indeed a solution.

x

1

1

equals c1e

x

, which means that substituting y = c e into the original equation

x

1

gives you:

c1e

x

– c1e = 0

x





95

**Chapter 5: Examining Second Order Linear Homogeneous Differential Equations**

So y = c e

x

is also a solution. In fact, that solution is more general than just

1

y = e , because y = c e represents an infinite number of solutions, depending

on the value of c1.

x

x

1

You can go further still by noting that y = e–x is also a solution, because:

y" – y = e–x – e–x = 0

Again, note that if y = e–x is a solution, then y = c2e–x (where c2 is a constant) is

also a solution because:

y" – y = c2e–x – c2e–x = 0

And here’s the fun part: If y = c1e

sum of these two must also be a solution:

x

and y = c2e–x are both solutions, then the

y = c1e

x

\+ c2e–x

In other words, if y = f (x) and y = f (x) are solutions to a second order linear

1

2

homogeneous differential equation, then:

y = f (x) + f (x)

1

2

is also a solution.

Initial conditions

In this section, I give you a look at some initial conditions to fit with the

solutions from the previous section. For instance, say that you have these

conditions:

y(0) = 9

and

y'(0) = –1

To meet these initial conditions, you can use the form of the solution y = c e

x

\+

1

c2e–x, which means that y' = c1e

x

– c2e–x. Using the initial conditions, you get:

y(0) = c1e

x

\+ c2e–x = c + c = 9

1 2

y'(0) = c1e

x

– c2e–x = c – c = –1

1 2





96

**Part II: Surveying Second and Higher Order Differential Equations**

So you get these two equations:

c + c = 9

1

2

c – c = –1

1

2

These are two equations in two unknowns. To solve them, write c + c = 9 in

1

2

this form:

c2 = 9 – c1

Now substitute this expression for c into c – c = –1, which gives you this

2

1

2

equation:

c – 9 + c = –1

1

1

or:

So

2c1 = 8

c1 = 4

Substituting the preceding value of c into c + c = 9 gives you:

1

1

2

c + c = 4 + c = 9

1

2

2

or:

c2 = 5

These values of c and c give you the following solution:

1

2

y = 4e + 5e–x

x

That was simple enough, and you can generalize it as the solution to any linear

homogeneous second order differential equation with constant coefficients.

Checking Out Characteristic Equations

Here’s the general second order linear homogeneous equation, where a, b,

and c are constants:

ay" + by' + cy = 0





97

**Chapter 5: Examining Second Order Linear Homogeneous Differential Equations**

The solution of this equation is of the form y = erx, where r isn’t yet determined.

Plugging y = erx into the equation gives you:

ar

Dividing by erx (which is always nonzero) gives you:

ar + br + c = 0

2

erx + brerx + cerx = 0

2

This equation is called the characteristic equation for ay" + by' + cy = 0, and it’s

a quadratic equation. If the roots of the characteristic equation are r and r ,

1

2

the general solution of ay" + by' + cy = 0 is:

y = c1 er1 + c2 er2

x

x

Earlier in this chapter, I treat this equation as one solution of ay" + by' + cy =

\0. But the truth is that it’s the unique solution, as is indicated by a theorem

later in this chapter (see the later section “Putting Everything Together with

Some Handy Theorems”). Because ar

2

\+ br + c = 0 is a quadratic equation, the

following are three possibilities for r and r :

1

2

` `r and r are real and distinct

1

2

` `r and r are complex numbers (complex conjugates of each other)

1

2

` `r = r , where r and r are real

1

2

1

2

You can take a look at these cases in the following sections.

Real and distinct roots

When it comes to characteristic equations, one possibility is that r and r are

1

2

real, and not equal to each other. I explain the basics of understanding this

concept and provide a clarifying example in the following sections.

The basics

When solving a general problem, where:

y(x0) = y0

and:

y'(x0) = y'0





98

**Part II: Surveying Second and Higher Order Differential Equations**

you get the following:

y = c er1

x

\+ c2 er2

x

0

0

0

1

and

yl = c r er1

x

\+ c r er2

x

0

0

0

1

1

2

1

Then you can solve for c and c in these equations, which gives you:

1

2

yl - y r

c1 =

0

0

2

e

\- r1

x

0

r - r

1

2

and:

y r - yl

c2 =

0

1

0

e

\- r2

x

0

r - r

1

2

An example

How about an example to bring the concept of real and distinct roots into

focus? Try this second order linear homogeneous differential equation:

y" + 5y' + 6y = 0

with the initial condition that:

y(0) = 16

and:

y'(0) = –38

To solve, make the assumption that the solution is of the form y = cerx

Substituting that equation into y" + 5y' + 6y = 0 gives you:

.

cr

Next you divide by cerx to get:

\+ 5r + 6 = 0

2

erx + 5crerx + 6cerx = 0

r

2

which is the characteristic equation for y" + 5y' + 6y = 0. You can also write

this equation as:

(r + 2) (r + 3) = 0





99

**Chapter 5: Examining Second Order Linear Homogeneous Differential Equations**

So the roots of the characteristic equation are:

r1 = –2

and

r2 = –3

which means that the solution to y" + 5y' + 6y = 0 is:

y = c1e–2x + c2e–3x

where c and c are determined by the initial conditions:

1

2

y(0) = 16

and:

y'(0) = –38

Substituting the initial conditions into your solution gives you these equations:

y(0) = c + c = 16

1

2

and:

y'(0) = –2c – 3c = –38

1

2

From the first equation, you can see that c = 16 – c , and substituting that

2

1

into the second equation gives you:

–2c – 3c = –2c – 48 + 3c = c – 48 = –38

1

2

1

1

1

or:

c1 = 10

Substituting this value of c into y(0) = c + c = 16 gives you:

1

1

2

c + c = 10 + c = 16

1

2

2

So that means:

c2 = 6





100

**Part II: Surveying Second and Higher Order Differential Equations**

Now you’ve found c and c , which means that the general solution to y" + 5y' +

1

2

6y = 0 is:

y = 10e–2x + 6e–3x

You can see this solution graphed in Figure 5-1.

**Figure 5-1:**

The solution

to an

equation

with real

and distinct

roots.

Complex roots

Besides real and distinct roots (see the previous section), another possibility,

when it comes to characteristic equations, is having complex roots. In this

case, the quadratic formula yields two complex numbers. I explain the basics

of this concept and walk you through an example in the following sections.

The basics

Check out the following quadratic equation:

-b !

b - 4ac

2

r =

2a

The discriminant, b

2

– 4ac, is negative, which means that you’re taking the

square root of a negative number, so you get complex numbers. In particular,

the imaginary part of the two roots varies by their sign (+ or –), as shown

by the example equation.





101

**Chapter 5: Examining Second Order Linear Homogeneous Differential Equations**

In other words, the roots are of the following forms:

r1 = λ + iµ

and

r2 = λ – iµ

where λ and µ are both real numbers, and i is the square root of –1.

As you can see, the characteristic equation has complex roots. What does

that mean for the solution to the differential equation? As you find out earlier

in this chapter, the solutions to the differential equation are:

y1 = er1

x

and

So:

y2 = er2

x

y1 = e(λ + iµ)x

and:

y2 = e(λ – iµ)x

Now you have to deal with complex numbers as exponents of e. You may be

familiar with the following handy equations:

eiax = cos ax + i sin ax

and:

e–iax = cos ax – i sin ax

You’re making progress! You have now removed i from the exponent. Putting

these two equations to work gives you these forms for the solutions, y and y :

1

2

y1 = e(λ + iµ)x = eλx(cos µx + i sin µx)

and:

y2 = e(λ – iµ)x = eλx(cos µx – i sin µx)





102

**Part II: Surveying Second and Higher Order Differential Equations**

However, you still have that pesky factor of i; and you want to get rid of it.

Why? The general differential equation that y and y are solutions of only has

1

2

real coefficients:

ay" + by' + cy = 0

Here’s the key: You could get rid of those factors of i if you could just divide

them out. After all, i is just a constant. For instance, if you had the solution in

a form like this:

yn = i eλxcos µx

you could replace i with an arbitrary constant of integration, c, which would

look like this:

yn = c eλxcos µx

Now try adding and subtracting y and y . As you recall from the earlier sec-

1

2

tion “Elementary solutions,” if two functions are a solution to a linear differen-

tial equation, the sum and difference of those functions are also solutions. So

you can introduce the new solutions m(x) and n(x), the sum and difference of

y and y :

1

2

m(x) = y (x) + y (x)

1

2

and:

n(x) = y (x) – y (x)

1

2

First, calculating m(x) gives you the following equation:

m(x) = y (x) + y (x) = eλx(cos µx + i sin µx) + eλx(cos µx – i sin µx)

1

2

which you can convert to:

m(x) = y (x) + y (x) = 2 eλxcos µx

1

2

Your solution now looks fine — there’s no pesky i lurking around. Now how

about calculating n(x)? Here’s what that looks like:

n(x) = y (x) – y (x) = eλx(cos µx + i sin µx) – eλx(cos µx – i sin µx)

1

2

which works out to:

n(x) = y (x) – y (x) = 2i eλx sin µx

1

2





103

**Chapter 5: Examining Second Order Linear Homogeneous Differential Equations**

Your solution is looking even better, because now m(x) and n(x) have the fol-

lowing forms:

m(x) = c1 eλxcos µx

and:

n(x) = c2 eλx sin µx

Yes, it’s true that n(x) as written is multiplied by i: 2i eλx sin µx. But that’s the

beauty of the whole thing: 2i is just a constant, so it can be replaced by c2.

And that substitution gets rid of the pesky i.

So, finally, you can write the solution as:

y(x) = m(x) + n(x)

or:

y(x) = c1 eλx cos µx + c2 eλx sin µx

where you get λ and µ from the roots of the differential equation’s character-

istic equation:

2

ar + br + c = 0

where the roots are:

r1 = λ + iµ

and

r2 = λ – iµ

An example

If you feel like you’ve grasped the basics of complex roots, take a look at an

example. Try solving this differential equation:

2y" + 2y' + y = 0

where:

y(0) = 1

and

y'(0) = 1





104

**Part II: Surveying Second and Higher Order Differential Equations**

You probably already have a good idea what to do here. You simply need to

find the characteristic equation and then the roots of that equation. Here’s

the characteristic equation:

2

2r + 2r + 1 = 0

You can find the roots of this characteristic equation by using the quadratic

equation from the previous section. Your work should give you these roots:

-2 ! 4 - 8

4

This equation works out to be:

r = –1

⁄

2

± (1⁄ )i

2

So the two roots are:

r1 = –1

⁄

2

\+ (

1

⁄

2

)i

and:

r2 = –1

⁄

2

– ( ⁄

2

1

)i

Because the two roots are of the form:

r1 = λ + iµ

and

r2 = λ – iµ

then:

λ = –1⁄

2

and:

µ = 1⁄

2

So the solution is:

y(x) = c1 e–x/2 cos

x

⁄

2

\+ c2 e–x/2 sin ⁄

2

x





105

**Chapter 5: Examining Second Order Linear Homogeneous Differential Equations**

To find c and c , you simply have to apply the initial conditions (substituting

1

2

in for y(0) and y'(0)), which means that:

y(0) = c1 = 1

and:

y'(0) =

Substituting c1 = 1 gives you:

y'(0) =

So c2 = 1. That makes the general solution to 2y" + 2y' + y = 0:

y(x) = e–x/2 cos + e–x/2 sin

1⁄

2c1

\+

1

⁄2c2 = 1

1⁄

2

1

\+ ⁄2c2 = 1

x⁄

2

x⁄

2

And that’s it — no imaginary terms involved. Cool. You can see a graph of

this solution in Figure 5-2.

**Figure 5-2:**

The solution

to an

equation

with

complex

roots.





106

**Part II: Surveying Second and Higher Order Differential Equations**

Identical real roots

In the previous sections, I cover the cases where the characteristic equation

has real and distinct roots as well as complex roots. All that’s left is the case

where the characteristic equation has two real roots that are identical to each

other. You get the fundamentals and an example in the following sections.

The basics

When the roots of a characteristic equation are identical, the discriminant of

the quadratic equation, b – 4ac, equals zero, which means that:

2

r1 = –b/2a

and

r2 = –b/2a

However, now you have a problem. Why? Because second order differential

equations are supposed to have two expressions in their solution. Because

r = r , you get this:

1

2

y = c e–bx/2a

y = c e–bx/2a

2 2

1

1

These solutions differ only by a constant, so they aren’t really different at all;

you could write either y + y or y – y as:

1

2

1

2

y = ce–bx/2a

So, as you can see, you really only have one solution in this case. How can you

find another? Here’s the traditional way of solving this issue: So far, you’ve

been finding solutions to second order linear differential equations by assum-

ing the solution is of the following form:

y(x) = cerx

However, consider this: What if you replaced the constant with a function of x,

m(x), instead? Doing so would let you handle more general second order linear

differential equations. By doing this, you get:

y(x) = m(x)erx

In this case, r = –b/2a, so you get this form of the solution:

y(x) = m(x)e–bx/2a





107

**Chapter 5: Examining Second Order Linear Homogeneous Differential Equations**

Differentiating the equation gives you:

^ h

^ h

^ h

b

2a

yl x = ml x e- bx/2a

\-

m x e- bx/2a

You also need y"(x) to substitute into the differential equation. Doing so

gives you:

^ h

^ h

^ h

^ h

b

2a

b

2

y'' x = m'' x e- bx/2a

\-

ml x e- bx/2a

\+

m x e- bx/2a

4a

2

Substituting y(x), y'(x), and y"(x) into the following differential equation:

ay" + by' + cy = 0

gives you (after rearranging the terms):

^ h

^

h

^ h

c

m

^ h

b

2

b

2

a m'' x + b - b ml x +

\-

\+ c m x = 0

4a 2a

So b – b = 0 in the second term, along with combining the fractions in the

third term, gives you:

^ h

c

m

^ h

b

2

a m'' x + c -

m x = 0

4a

Here’s the trick: Note that c – b /4a is the discriminant of the characteristic

2

equation, and in this case (the case of real identical roots), the discriminant

equals zero. So you have:

a m"(x) = 0

or simply, dividing by a:

m"(x) = 0

Wow, that looks pretty easy after all. After integrating, you get this final form

for m(x):

m(x) = d1x + d2

where d and d are constants.

1

2

Because the second solution you’ve been looking for is y2(x) = m(x)erx

\=

d1xerx + d2erx, here’s the general solution of the differential equation in the

case where the characteristic equation’s roots are real and identical:

y(x) = c1xe–bx/2a + c2e–bx/2a

where c and c are constants.

1

2





108

**Part II: Surveying Second and Higher Order Differential Equations**

This trick, it turns out, can often be used to find a second solution to a

second order linear homogeneous differential equation if you already know

one solution. In fact, trying a solution of the form y(x) = m(x)f(x) is so useful

that it has been given a name: the method of reduction of order. I discuss this

method in more detail later in this chapter.

An example

Want to see an example so that the identical real root concept can really take

hold? Take a look at this differential equation:

y" + 2y' + y = 0

where:

y(0) = 1

and:

y'(0) = 1

The characteristic equation is:

2

r + 2r + 1 = 0

You can factor this equation into:

(r + 1) (r + 1) = 0

So the roots of the characteristic equation are identical, –1 and –1.

Now the solution is of the following form:

y(x) = c1xe–bx/2a + c2e–bx/2a

To figure out c and c , use the initial conditions. Substituting into the equa-

1

2

tion gives you:

y(0) = c2 = 1

Differentiating the y(x) equation gives you y'(x); you also can substitute c2 = 1

to get:

^ h

bc1

2a

b

2a

yl x = c e- bx/2a

\-

xe- bx/2a

\-

e

\- bx/2a

1





109

**Chapter 5: Examining Second Order Linear Homogeneous Differential Equations**

From the initial conditions, y'(0) equals:

y'(0) = c1 – 1 = 1

So c1 = 2, giving you the following general solution:

y(x) = 2xe–x + e–x

And that’s that. You can find a graph of this solution in Figure 5-3.

**Figure 5-3:**

The solution

to an

equation

with

identical

real roots.

Getting a Second Solution

by Reduction of Order

If you know one solution to a second order differential equation, you can get

a first order differential equation for the second solution — or rather, for the

derivative of the second solution, which you can then integrate to get the

actual second solution. That’s where the term reduction of order comes from.

The method is very cool, as you find out in the following sections.





110

**Part II: Surveying Second and Higher Order Differential Equations**

Seeing how reduction of order works

What is the reduction of order method? Basically it says that if you already

know a solution, y1(x), to a differential equation of this form:

y" + p(x)y' + q(x) = 0

you can substitute the following expression into the equation to search for a

second solution:

y(x) = m(x)y1(x)

Note that the original equation isn’t restricted to differential equations with

constant coefficients. However, it is homogeneous (in other words, it equals

zero).

Differentiating y(x) = m(x)y1(x) with respect to x gives you:

y'(x) = m'(x)y (x) + m(x)y '(x)

1

1

You also need the second derivative of y(x) = m(x)y1(x), which looks like this:

y"(x) = m"(x)y (x) + m'(x)y '(x) + m'(x)y '(x) + m(x)y "(x)

1

1

1

1

The middle two terms are the same, so the equation becomes:

y"(x) = m"(x)y (x) + 2m'(x)y '(x) + m(x)y "(x)

1

1

1

Putting y'(x) and y"(x) into y" + p(x)y' + q(x) = 0 gives you the following

equation:

y m" + (2y ' + py )m' + (y " + py ' + qy ) = 0

1

1

1

1

1

1

I bet you recognize the expression in the second set of parentheses here. And

guess what? That’s the point! That expression is y " + py ' + qy , which is just

1

1

1

y substituted into the original differential equation. But y is a solution of

1

1

that homogeneous differential equation, so the expression in parentheses

equals 0!

So you end up with this equation:

y m" + (2y ' + py )m' = 0

1

1

1





111

**Chapter 5: Examining Second Order Linear Homogeneous Differential Equations**

It doesn’t look pretty, but examine what you have here: This is actually a first

order differential equation in m'(x). If you substitute n(x) = m'(x) into the

equation, you get this:

y n'(x) + (2y ' + py )n(x) = 0

1

1

1

This final equation is a first order differential equation in n(x), and it can

often be solved as a first order linear differential equation or as a separable

differential equation (see Chapters 2 and 3 for more about these types of

equations).

Trying out an example

In this section, you can see reduction of order at work in an example. Take a

look at this second order differential equation:

2x y" + xy' – y = 0

2

How do you tackle this one? I walk you through the process in the following

sections.

The first solution

In the equation 2x y" + xy' – y = 0, note how each successive derivative y' and

2

y" is multiplied by a new power of x. This suggests that differentiating a solu-

tion of this differential equation generates a new power of x in the denomina-

tor (and that the x and x

y1 = 1/x

Substituting this solution into the equation gives you:

2x n(n+1)/xn+2 – xn/xn+1 – 1/x = 0

By cancelling 1/x , you get:

2n(n+1) – n – 1 = 0

2

cancel out). So try a first solution of the form:

n

2

n

n

or:

2n – n – 1 = 0

2





112

**Part II: Surveying Second and Higher Order Differential Equations**

The quadratic equation gives you these roots:

1 ! 3

4

Taking the root r = 1, you see that:

y1 = 1/x

is a solution of 2x

2

y" + xy' – y = 0. (You can take a look at the other root, r = – ⁄ ,

2

1

in the later section “A little shortcut.”)

The second solution

In the previous section, you find the first solution, y1 = 1/x. Now you use the

reduction of order method to find a second solution. This means that you’re

now looking for a solution of the following form:

y2 = m(x)/x

The first derivative of this solution is:

y2' = m'(x)/x – m(x)/x

2

The second derivative is:

y " = m"(x)/x – 2m'(x)/x + 2m(x)/x

3

2

2

Substituting y' and y" into 2x

2xm" – m' = 0

2

y" + xy' – y = 0 gives you (after the algebra settles):

To make this equation a little easier to work with, set m'(x) = n(x), which

gives you this:

dn

dx

2x

= n

Separating the variables results in the following equation:

dn dx

n  =

2x

or:

ln(n) = ln(x)/2

Exponentiating both sides of the equation gives you:

n(x) = kx1/2





113

**Chapter 5: Examining Second Order Linear Homogeneous Differential Equations**

where k is a constant. Because n(x) = m'(x), you know that:

m(x) = cx3/2 + d

where c and d are constants.

This solves for m(x). Now because, by y2 = m(x)/x:

y = m(x) y = m(x)/x

2

1

you know that:

y = c x1/2 + c2/x

2

1

Note that the second term here can be absorbed together with y1 (which is

1/x). So the complete solution is (I’ve absorbed the constants together as

needed):

y = y + y = c x1/2 + c2/x

1

2

1

A little shortcut

You may have noticed that in the previous example, you didn’t actually need

to use reduction of order. I’ll show you what I mean. The differential equation

you were solving looked like this:

2x

You guessed that the solution was of the following form:

y = 1/x

Substituting this into the differential equation gave you:

2n – n – 1 = 0

2

y" + xy' – y = 0

n

2

which has these roots:

1 ! 3

4

So the roots are 1 and –

tions already:

1

⁄ , which means that you did in fact have two solu-

2

y = c /x

1

1

and:

y = c x1/2

2

2





114

**Part II: Surveying Second and Higher Order Differential Equations**

Putting Everything Together with

Some Handy Theorems

A couple of formal theorems, which I explain in the following sections, lock

down exactly how to find the general solutions to second order linear homo-

geneous differential equations and formalize the information from earlier

sections.

Superposition

I’ll start off with the theorem on superposition of solutions, which formally

says this:

**If you have the second order linear homogeneous differential equation:**

**y" + p(x)y' + q(x) = 0**

**and have two solutions, y (x) and y (x), then any linear combinations of**

**1**

**2**

**these solutions:**

**y = c y + c y**

**2**

**1**

**1**

**2**

**where c and c are constants, is also a solution of the differential equation.**

**1**

**2**

In plain English, this theorem simply says that if you have two solutions to a

second order linear differential equation, a linear combination of those two

solutions is also a solution. You actually use this theorem throughout the first

part of this chapter as you solve second order linear homogeneous differen-

tial equations for two solutions, y and y , and give the general solution as a

1

2

linear combination of the two.

Here’s another example; say that you have the following second order linear

differential equation:

y" – y = 0

You can guess that the solution is of the form y = enx and that substituting it in

gives you:

2

n enx – enx = 0

or:

n

2

– 1 = 0





115

**Chapter 5: Examining Second Order Linear Homogeneous Differential Equations**

Therefore:

n = ±1

So the two solutions you’ve worked out are:

y = c e

x

1

1

and

y = c e–x

2

2

According to this theorem, the following linear superposition of these solu-

tions is also a solution:

y = c1e

You can verify your solution by substituting it into the original equation:

y" – y = c1e + c2e–x – (c1e + c2e–x) = 0

x

\+ c2e–x

x

x

Linear independence

Earlier in this chapter, you work problems to find the solutions y and y to

1

2

second order linear homogeneous differential equations, but it turns out that

there’s a restriction on them — they have to be linearly independent. What,

exactly, does that mean?

If you have two functions, f(x) and g(x), they’re linearly dependent in an inter-

val I if for all x in I you can find two constants, c and c , such that this equa-

1

2

tion is true:

c f(x) + c g(x) = 0

1

2

In other words, f(x) just differs from g(x) by a constant.

If the functions f and g aren’t linearly dependent in the interval I, they’re lin-

early independent in the interval I. In other words, if it’s impossible to find

two constants such that the previous equation is true for f(x) and g(x) in the

interval I, then f(x) and g(x) are linearly independent in the interval I.

Practically speaking, if one function isn’t just a multiple of another function,

the two are linearly independent.





116

**Part II: Surveying Second and Higher Order Differential Equations**

Here’s the formal theorem:

**If you have the second order linear homogeneous differential equation:**

**y" + p(x)y' + q(x) = 0**

**and have two linearly independent solutions, y (x) and y (x), then any**

**1**

**2**

**linear combinations of these solutions:**

**y = c y + c y**

**2**

**1**

**1**

**2**

**where c and c are constants, is the general solution of the differential**

**1**

**2**

**equation. Every solution of the differential equation can be expressed in**

**the form of y = c y + c y .**

**1**

**1**

**2**

**2**

In other words, you can’t just use any two solutions, y and y , to a second

1

2

order linear homogeneous differential equation. Instead, those two solutions

have to be linearly independent so that a linear combination of them is a gen-

eral solution of the differential equation.

Clear as mud, right? Well, here’s an example to wrap your brain around. Say

that you have the following differential equation:

y" + 6y' + 8y = 0

What’s the general solution of this equation? Well, guessing that the solutions

are of the form y = erx, you get the following equation by substituting the solu-

tion into the differential equation:

r

2e

rx + 6rerx + 8erx = 0

The characteristic equation is:

\+ 6r + 8 = 0

r

2

which can be factored into:

(r + 4) (r + 2)

So the roots of the characteristic equation are –4 and –2, and your solutions

are of the form:

y = c e–4x

1

1

and

y = c e–2x

2

2





117

**Chapter 5: Examining Second Order Linear Homogeneous Differential Equations**

These solutions are linearly independent — they don’t just differ by a multi-

plicative constant — so by the theorem of linear independence, the general

solution to the differential equation has the following form:

y = c1e–4x + c2e–2x

The Wronskian

You may have heard of the Wronskian, especially if you aspire to be a

Differential Equations Wizard (and doesn’t everyone?). But if you haven’t

heard of it, you’re probably wondering what it is. Briefly put, the Wronskian

is the determinant of an array of coefficients that lets you determine the

linear independence of solutions to a differential equation.

Okay, that was a mouthful. What does it mean in layman’s terms? I explain

what you need to know and provide some examples in the following sections.

Arrays and determinants

Say that you have a second order linear homogeneous differential equation

with the following general solution:

y = c y + c y

2 2

1

1

And assume that you have these initial conditions

y(x0) = y0

and

y'(xo) = y'o

The initial conditions mean that the constants c and c have to satisfy these

1

2

equations:

y = c y (x ) + c y (x )

o

1

1

0

2

2

0

and:

y' = c y' (x ) + c y' (x )

0

1

1

0

2

2

0





118

**Part II: Surveying Second and Higher Order Differential Equations**

Solving this system of two equations for c and c gives you:

1

2

~~\_~~

~~i~~

~~\_~~

~~i~~

y yl

x

x

\- yl y

x

c1 =

~~\_~~

~~i~~

0

2

2

~~\_~~

0

0

~~i~~

0

~~\_~~

2

~~i~~

0

~~\_~~

~~i~~

y

x

y

l

\- l

y

x

y

x

1

0

1

0

2

0

and:

~~\_~~

~~i~~

~~\_~~

~~i~~

-y yl x + yl y

x

c2 =

~~\_~~

~~i~~

0

~~\_~~

1

0

~~i~~

~~\_~~

0

1

0

~~i~~

0

~~\_~~

~~i~~

y

x

y

l

x

\- yl

x

y

2

x

1

0

2

0

1

0

At some point in time, someone got the bright idea that this system looks like

the division of two array determinants. As a refresher on determinants, say

you have this array:

a

c

b

d

In the example, the determinant is:

a

c

b

d

= ad - cb

Using this notation, you can write the expressions for c and c in determinant

1

2

form:

\_

i

y

y

x

0

2

0

\_

i

yl0 yl

x

2

0

c1 =

\_

i

\_

i

y

x

y

x

1

0

2

0

\_

i

\_

i

yl x

yl

x

1

0

2

0

and:

\_

i

y

x

y

1

0

0

\_

i

yl x

yl

1

0

0

c2 =

\_

i

\_

i

y

x

y

x

0

1

0

2

\_

i

\_

i

yl x

yl

x

0

1

0

2

In order for c and c to make sense in these expressions, the denominator

1

2

must be nonzero, so:

\_

i

\_

i

y

x

y

x

0

\_

i

\_

i

\_

i

\_

i

1

0

2

W =

\_

i

\_

i = y

x

yl

x

\- yl x

y

x

! 0

yl x

yl

x

0

1

0

2

0

1

0

2

0

1

0

2

Here’s the Wronskian (W) of the solutions y and y :

1

2

W = y (x )y' (x ) – y '(x )y (x )

1

0

2

0

1

0

2

0





119

**Chapter 5: Examining Second Order Linear Homogeneous Differential Equations**

**Who was Wronski?**

Jósef Maria Hoëné-Wronski (1778–1853) was a pursuing ultimately unsuccessful topics, such as

Polish philosopher. He studied and published in perpetual motion machines. Unfortunately, during

many fields, such as philosophy, math, and his lifetime, his work was largely ridiculed and

physics, and he also was an inventor and a ignored. However, since his death, people have

lawyer.

come to unearth significant nuggets of thought

from his writings.

Despite deep flashes of insight into math and

some other fields, Wronski spent much of his life

You may also see the Wronskian referred to as the Wronskian determinant. It’s

named for a Polish mathematician, Jósef Maria Hoëné-Wronski (and you

thought mathematicians had bland names). Check out the nearby sidebar

“Who was Wronski?” for more info.

The formal theorem

The Wronskian is a measure of linear independence. Consider this, for exam-

ple: If you have two solutions, y and y , and their Wronskian is nonzero, then

1

2

those solutions are linearly independent. And that, my friend, means that

every solution to the differential equation is a linear combination of those

two solutions.

And that brings me to a formal theorem:

**If you have the second order linear homogeneous differential equation:**

**y" + p(x)y' + q(x) = 0**

**and have two solutions, y (x) and y (x), where their Wronskian is nonzero**

**1**

**2**

**at a point x , then any linear combinations of these solutions:**

**0**

**y = c y + c y**

**2**

**1**

**1**

**2**

**where c and c are constants, is the general solution of the differential**

**1**

**2**

**equation. Every solution of the differential equation can be expressed in**

**the form of y = c y + c y .**

**1**

**1**

**2**

**2**

Here’s the gist of this formal theorem: If the Wronskian of your two solutions

is nonzero at a point x0, then a linear combination of those solutions contains

every solution of the differential equation. In other words, if you have two





120

**Part II: Surveying Second and Higher Order Differential Equations**

solutions, y and y , and their Wronskian is nonzero, then this is the general

1

2

solution of the corresponding differential equation:

y = c y + c y

1

1

2 2

**Note:** The y and y form is what’s called a fundamental solution to the differ-

1

2

ential equation.

Example 1

How about some examples to get a hang of the Wronskian? Earlier in this

chapter, you tackled this differential equation:

y" + 2y' + y = 0

The characteristic equation is:

2

r + 2r + 1 = 0

and you can factor that equation this way:

(r + 1) (r + 1) = 0

which means that the roots of the differential equation are identical, –1 and

–1. So the solution is of the following form:

y(x) = c1xe–x + c2e–x

Now take a look at the Wronskian, which looks like this:

\_

i

\_

i

y

x

y

x

0

\_

i

\_

i

\_

i

\_

i

1

0

2

W =

\_

i

\_

i = y

x

yl

x

\- yl x

y

x

0

yl x

yl

x

0

1

0

2

0

1

0

2

1

0

2

Because:

y = c xe–x

1

1

and

y = c e–x

2

2

the Wronskian equals:

W = y (x )y' (x ) – y '(x )y (x ) = –c xe–x c2e–x – (c1e–x – c1xe–x)c2e–x

1

0

2

0

1

0

2

0

1

or:

W = –c c e–2x

1

2





121

**Chapter 5: Examining Second Order Linear Homogeneous Differential Equations**

And because the Wronskian is always nonzero, you don’t even have to substi-

tute x in; y and y form a fundamental solution of the differential equation, as

0

1

2

long as c and c are both nonzero.

1

2

Example 2

Here’s another example. Say that you have two solutions, y and y , to a

1

2

second order linear homogeneous differential equation such that:

y1 = er1

x

and

y2 = er2

x

Your task now is to show that y and y form a fundamental solution to the dif-

1

2

ferential equation if r ≠ r .

1

2

Time to check the Wronskian:

\_

i

\_

i

y

x

y

x

0

\_

i

\_

i

\_

i

\_

i

1

0

2

W =

\_

i

\_

i = y

x

yl

x

\- yl x

y

x

0

yl x

yl

x

0

1

0

2

0

1

0

2

1

0

2

Because y1 = e

r

x

and y2 = e , the Wronskian equals:

2

r

x

1

\_

i

\_

i

\_

i

\_

i

W = y

x

yl

x

\- yl x

y

x

= er1

x

r2 er2

x

\- r1 er1

x

e

r2

x

1

0

2

0

1

0

2

0

or:

\_

i

W = r - r

e

(r1 + r2 ) x

2

1

Don’t forget: You don’t have to substitute x into the Wronksian, because it’s

0

clearly nonzero everywhere as long as r ≠ r . So y and y form a fundamental

1

2

1

2

solution set of the differential equation.

Because:

y1 = er1

x

and

y2 = er2

x

you can see that what the Wronskian is trying to say is that y and y are lin-

1

2

early independent. In other words, you can’t multiply y by a constant so that

1

it equals y for all x in an interval, such as –2 < x < 2, as long as r ≠ r .

2

1

2





122

**Part II: Surveying Second and Higher Order Differential Equations**

Example 3

Here’s one final Wronskian example. Earlier in this chapter, you solve this dif-

ferential equation:

2x

By guessing that the solution was of the following form:

y1 = 1/x

you came up with this characteristic equation:

2n – n – 1 = 0

2

y" + xy' – y = 0

n

2

and found this solution:

y = c1x1/2 + c2/x

Is this the general solution? You can find out by bringing the Wronskian to the

rescue:

\_

i

\_

i

\_

i

\_

i

c

1

2

W = y

x

yl

x

\- yl x

y

x

= -c1 x1/2 c2 /x

2

\-

x- 1/2 c2 /x

1

0

2

0

1

0

2

0

or:

So:

c1 c

2

2

W = -c c x- 3/2

\-

x

\- 3/2

1

2

-3

2

W =

c c x- 3/2

1 2

If c and c ≠ 0, then because W ≠ 0 for x > 0, you can conclude that:

1

2

y = c1x1/2 + c2/x

is indeed the general solution.





**Chapter 6**

**Studying Second Order**

**Linear Nonhomogeneous**

**Differential Equations**

In This Chapter

` `Focusing on the facts of linear nonhomogeneous second order equations

` `Mapping out the method of undetermined coefficients

` `Perusing variation of parameters

` `Applying nonhomogeneous equations to physics

C

hapter 5 is about second order linear homogeneous differential equa-

tions of this form:

y" + p(x)y' + q(x)y = 0

This equation is homogeneous because it equals zero (and there’s no term

that only relies on x). In this chapter, however, you tackle differential equa-

tions of the nonhomogeneous form:

y" + p(x)y' + q(x)y = g(x)

where g(x) ≠ 0.

Exciting, isn’t it? To start, I provide you with a theorem that gives you the

power you need to solve these kinds of equations. After that, I describe some

great techniques for working with these equations. I even throw in a few

physics examples to show you how these equations apply to real life.





124

**Part II: Surveying Second and Higher Order Differential Equations**

The General Solution of Second Order

Linear Nonhomogeneous Equations

Luckily for mathematicians everywhere, a quick and easy theorem giving the

general solution of a second order linear nonhomogeneous differential equa-

tion exists. And this theorem is the one that you’ll refer to over and over

again in this chapter. In the following sections, I explain the theorem and how

you can put it to work.

Understanding an important theorem

Without further ado, here’s the theorem of the general solution of a second

order linear nonhomogeneous differential equation:

**The general solution of the nonhomogeneous differential equation:**

**y" + p(x)y' + q(x)y = g(x)**

**is:**

**y = c y (x) + c y (x) + y (x)**

**1**

**1**

**2**

**2**

**p**

**where c y (x) + c y (x) is the general solution of the corresponding homo-**

**1**

**1**

**2**

**2**

**geneous differential equation:**

**y" + p(x)y' + q(x)y = 0**

**(for example, y and y are a fundamental set of solutions to the homoge-**

**1**

**2**

**neous equation) and where y (x) is a specific solution to the nonhomoge-**

**p**

**neous equation.**

This very important theorem basically says that to find the general solution

to a nonhomogeneous differential equation, you need the sum of the general

solution of the corresponding homogeneous differential equation added to a

particular solution of the nonhomogeneous differential equation. A particular

solution is any solution of the nonhomogeneous differential equation. Quite a

mouthful isn’t it? Not to worry; I explain how to use this theorem in the next

section.





125

**Chapter 6: Studying Second Order Linear Nonhomogeneous Differential Equations**

Putting the theorem to work

You need to follow these steps to find the general solution of a second order

linear nonhomogeneous equation:

**1. Find the corresponding homogeneous differential equation by setting**

**g(x) to 0.**

**2. Find the general solution, y = c y (x) + c y (x), of the corresponding**

**1**

**1**

**2**

**2**

**homogeneous differential equation.**

This solution is referred to as yh.

**3. Find a single solution to the nonhomogeneous equation.**

This solution is sometimes referred to as the particular (or specific)

solution, yp.

**4. The general solution of the nonhomogeneous differential equation is**

**the sum of y + y .**

**h**

**p**

To see these steps in action, take a look at this nonhomogeneous differential

equation:

y" – y' – 2y = e3x

To solve this equation, start by getting the homogenous version of it, like this:

y" – y' – 2y = 0

You can assume that the solution is of the form y = ert. So, when you substi-

tute that into the differential equation, you get the following characteristic

equation (see Chapter 5 for more details):

2

r – r – 2 = 0

You can then factor the characteristic equation this way:

(r + 1)(r – 2) = 0

Now you can see that the roots, r and r , of the characteristic equation are –1

1

2

and 2, giving you:

y1 = e–x

and:

y2 = e2x





126

**Part II: Surveying Second and Higher Order Differential Equations**

So, the general solution to the homogeneous differential equation is given by:

y = c1e–x + c2e2x

You’re halfway there! Now you need a particular solution to the original non-

homogeneous differential equation:

y" – y' – 2y = e3x

Note that g(x) has the form e3x here, so you can assume that the particular

solution has this form:

yp(x) = Ae3x

In this case, A is an arbitrary coefficient.

Substituting this form into the nonhomogeneous equation gives you:

9Ae3x – 3Ae3x – 2Ae3x = e3x

or:

9A – 3A – 2A = 1

So

4A = 1

and

A = ⁄

4

1

The particular solution is:

^ h

e

3x

y

x =

p

4

Because the general solution to the nonhomogeneous equation is equal to

the sum of the general solution of the corresponding homogeneous differen-

tial equation and a particular solution of the nonhomogeneous differential

equation, you get this equation as the general solution:

y = yh + yp

or:

e

3x

y = c1 e- x + c2 e2x

\+

4





127

**Chapter 6: Studying Second Order Linear Nonhomogeneous Differential Equations**

Finding Particular Solutions with the

Method of Undetermined Coefficients

Are there any techniques that allow you to find particular solutions to non-

homogeneous differential equations? Yes, there are! I’ll start with the method

of undetermined coefficients, which is actually a method you use earlier in

this chapter (you just didn’t know the fancy name there).

You start by finding a particular solution to the nonhomogeneous differential

equation:

y" + p(x)y' + q(x)y = g(x)

The method of undetermined coefficients notes that when you find a candidate

solution, y, and plug it into the left-hand side of the equation, you end up with

g(x). Because g(x) is only a function of x, you can often guess the form of

yp(x), up to arbitrary coefficients, and then solve for those coefficients by

plugging yp(x) into the differential equation.

This method works because you’re grappling only with g(x) here, and the

form of g(x) can often tell you what a particular solution looks like. For

instance, if g(x) is in the form of

` `**erx,** try a particular solution of the form Aerx, where A is a constant.

Because derivatives of erx reproduce erx, you have a good chance of find-

ing a particular solution this way.

` `**a polynomial of order n,** try a polynomial of order n. For example, if

g(x) = x

2

\+ 1, try a polynomial of the form Ax + B.

2

` `**a combination of sines and cosines,** sin αx + cos βx, try a combination

of sines and cosines with undetermined coefficients, A sin αx + B cos βx.

Then plug into the differential equation and solve for A and B.

In the following sections, you take a look at some examples that put to work

the method of undetermined coefficients, and then you solve actual differential

equations using the theorem I explain earlier in this chapter.

When g(x) is in the form of erx

You see the following equation in its entirety in the earlier section “Putting

the theorem to work,” but here’s how to figure out the particular solution:

y" – y' – 2y = e3x





128

**Part II: Surveying Second and Higher Order Differential Equations**

From the form of the term on the right, g(x), you can guess that a particular

solution, yp(x), has the form:

yp(x) = Ae3x

Substituting this into the differential equation gives you:

9Ae3x – 3Ae3x – 2Ae3x = e3x

Dropping e3x out of each term gives you:

9A – 3A – 2A = 1

So:

4A = 1

and

A = ⁄

4

1

The particular solution for the differential equation is:

^ h

e

3x

y

x =

p

4

When g(x) is a polynomial of order n

The example in this section points out how to deal with a particular solution

in the form of a polynomial. Your mission, should you choose to accept it, is

to find the general solution of the following nonhomogeneous equation:

y" = 9x

2

\+ 2x – 1

where:

y(0) = 1

y'(0) = 3

and

The general solution to the homogeneous equation

The homogeneous equation is simply:

y" = 0





129

**Chapter 6: Studying Second Order Linear Nonhomogeneous Differential Equations**

And you can integrate to get this equation:

y' = c1

Integrating again gives you the general solution to the homogeneous differen-

tial equation, yh:

y = c x + c

2

h

1

The particular and general solutions to the nonhomogeneous equation

To find the general solution to the nonhomogeneous equation, you need a

particular solution, yp. The g(x) term in the original equation is 9x

2

\+ 2x – 1,

so you can assume that the particular solution has a similar form:

yp = Ax + Bx + C

2

where A, B, and C are constant coefficients that you have to determine. But

here’s the issue: The supposed form of y has terms in common with y , the

p

h

general solution of the homogenous equation:

y = c x + c

h

1

2

yp = Ax

2

\+ Bx + C

Both of these have an x term and a constant term. When y and y have terms

h

p

in common — differing only by a multiplicative constant — that isn’t good,

because those are really part of the same solution. When you add yh and yp

together, you get this:

y = y + y = Ax + (c + B)x + (c + C)

1 2

2

h

p

which can be rewritten:

y = y + y = Ax + cx + d

2

h

p

where c and d are constants. As you can see, the terms Bx + C in yp really

don’t add anything.

The way to handle this issue is to multiply yp by successive powers of x until

you don’t have any terms of the same power as in yh. For example, multiply yp

by x to get:

yp = Ax

3

\+ Bx + Cx

2





130

**Part II: Surveying Second and Higher Order Differential Equations**

This equation still isn’t good enough, however. After all, the Cx term overlaps

with the c x term in y . So, you have to multiply by x again to get:

1

h

yp = Ax

4

\+ Bx

3

\+ Cx

2

This solution has no terms in common with the homogeneous general solu-

tion, yh, so you’re in business.

Substituting yp = Ax

4

\+ Bx

3

\+ Cx

2

into y" = 9x + 2x – 1 gives you:

2

12Ax + 6Bx + 2C = 9x

2

2

\+ 2x – 1

Comparing coefficients of like terms gives you:

12A = 9

6B = 2

2C = –1

which means that:

A =

B =

3

⁄

4

1⁄

3

C = –1

⁄

2

So the particular solution is:

3

4

1

3

1

2

y p =

x

4

\+

x

3

\-

x

2

Therefore, the general solution is:

3

4

1

3

1

2

y = y + y = c x + c +

x

4

\+

x

3

\-

x

2

h

p

1

2

Or, after rearranging to make things look pretty, you get:

3

4

1

3

1

2

y = y + y =

x

4

\+

x

3

\-

2

x + c1 x + c

2

h

p

where you can get c and c by using the initial conditions. Substituting y(0) =

1

2

1 gives:

y(0) = 1 = c2

So c2 = 1. Taking the derivative of your general solution gives you:

y' = 3x + x – x + c1

3

2





131

**Chapter 6: Studying Second Order Linear Nonhomogeneous Differential Equations**

And substituting the initial condition y'(0) = 3 gives you:

y'(0) = 3 = c1

Here’s the general solution with all the numbers filled in:

3

4

1

3

1

2

y =

x

4

\+

x

3

\-

2

x + 3x + 1

When g(x) is a combination

of sines and cosines

Combinations of sines and cosines can be a bit tricky, but with the help of

the following sections, you can solve equations featuring these combinations

in a snap.

Example 1

Find a particular solution to the following non-homogeneous equation:

y" – y' – 2y = sin 2x

This example looks as though a particular solution may be of the form yp =

Asin2x + Bcos2x. There’s one way to find out if you’re correct; you can substi-

tute this solution into your equation to get:

(–6A + 2B) sin 2x + (–6B – 2A) cos 2x = sin 2x

You can now equate the coefficients of sin 2x and cos 2x to get these

equations:

–6A + 2B = 1

and

–6B – 2A = 0

Multiplying –6B – 2A = 0 by –3 and adding the result to 6A + 2B = 1 gives you

20B = 1. So B = ⁄20. Substituting that number into –6B – 2A = 0 gives you the fol-

1

lowing equation:

-6

20

\- 2A = 0





132

**Part II: Surveying Second and Higher Order Differential Equations**

So A = –3

⁄20. Therefore, a particular solution of the original nonhomogeneous

equation is:

-3

20

cos2x

20

y p =

sin2x +

Example 2

Here’s another example using sines and cosines. Try finding a particular solu-

tion of the following equation:

y" + 16y = 4 cos 4x

Assume that the solution looks like this:

yp = A cos 4x + B sin 4x

So far, so good. Now, however, when you plug this solution into the differen-

tial equation, you get the following result:

(16A – 16A) cos 4x + (16B – 16B) sin 4x = 4 cos 4x

Hang on a minute here! The coefficients of cos 4x and sin 4x on the left are

both zero! So, there are no solutions that are a combination of a sine and a

cosine that solve the differential equation. You can see why if you take a look

at the corresponding homogeneous differential equation:

y" + 16y = 0

The general solution to this homogeneous equation is:

y = c cos 4x + c sin 4x

1

2

This general solution has the same form as your attempted particular solution:

A cos 4x + B sin 4x. But because that’s the homogeneous solution, it isn’t going

to be a particular solution to the nonhomogeneous equation. Instead, you have

to find another version of yp — one that will result in sin 4x and cos 4x terms

when differentiated. The simplest form (besides yp = A cos 4x + B sin 4x) that

can do that is:

yp = Ax cos 4x + Bx sin 4x

Give it a try. Here’s what y'p looks like:

y'p = A cos 4x – 4Ax sin 4x + B sin 4x + 4Bx cos 4x





133

**Chapter 6: Studying Second Order Linear Nonhomogeneous Differential Equations**

And y"p looks like this:

y"p = –4A sin 4x – 4A sin 4x – 16Ax cos 4x + 4B cos 4x + 4B cos 4x – 16Bx

sin 4x

Substituting y"p into the original nonhomogeneous differential equation gives

you this result:

–4A sin 4x – 4A sin 4x – 16Ax cos 4x + 4B cos 4x + 4B cos 4x – 16Bx sin 4x +

16Ax cos 4x + 16Bx sin 4x = 4 cos 4x

Wow! Thankfully, this collapses to:

–8A sin 4x + 8B cos 4x = 4 cos 4x

So, A = 0 and B = ⁄ , giving you the following particular solution:

2

1

x

y p = sin4x

2

And that’s that. The general solution to this differential equation is therefore:

x

2

y = c cos4x + c sin4x + sin4x

1

2

When g(x) is a product

of two different forms

Here’s a neat trick: If your g(x) term is a product of erx with sin x and cos x or a

polynomial, you should attempt a particular solution that’s a similar product,

using coefficients whose values have yet to be determined.

Ready to see this handy trick at work? Take a look at this differential equation:

4y" + y = 5e

Assume that a particular solution is the product of e

yp = Ae cos 2x + Be sin 2x

Here’s the derivative y'p:

y'p = Ae cos 2x – 2Ae sin 2x + 2Be cos 2x

x

cos 2x

x

and cos 2x and sin 2x:

x

x

x

x

sin 2x + Be

x

x





134

**Part II: Surveying Second and Higher Order Differential Equations**

And here’s the second derivative y"p:

y"p = Ae

x

cos 2x – 2Ae

x

sin 2x – 2Ae

sin 2x

x

sin 2x – 4Ae

x

cos 2x + Be

x

sin 2x + 2Be

x

cos 2x + 2Be

x

cos 2x – 4Be

x

or:

y" = –3A e

4B) + e

x

cos 2x – 4Ae

x

sin 2x – 3Be

x

sin 2x + 4Be

x

cos 2x = e cos 2x (–3A +

x

p

x

sin 2x (–4A – 3B)

Substituting this into your original differential equation gives you the following:

4(–3Ae

x

cos 2x – 4Ae

cos 2x

x

sin 2x – 3Be

x

sin 2x + 4Be

x

cos 2x) + (Ae

x

cos 2x + Be

x

sin 2x) = 5e

x

or:

–12Ae

x

cos 2x – 16Ae

cos 2x

x

sin 2x – 12Be

x

sin 2x + 16Be

x

cos 2x + Ae

x

cos 2x + Be

x

sin 2x = 5e

x

Collecting terms gives you this equation:

(–11A+ 16B)e cos 2x + (–16A – 11B)e

x

x

sin 2x = 5e cos 2x

x

So, matching the coefficients of cos 2x and sin 2x gives you these equations:

–11A + 16B = 5

and

–16A – 11B = 0

From this equation, A = –11B/16, and by substituting it into the previous

equation you get this:

–121B + 256B = 80

So, 135B = 80, or B = 16

–16A – 176

And A = –11 27. Therefore the particular solution, yp, is:

⁄27. Figuring out A yields:

⁄27 = 0

⁄

-11

27

16

27

y p =

e

x

cos2x +

x

e sin2x





135

**Chapter 6: Studying Second Order Linear Nonhomogeneous Differential Equations**

Breaking Down Equations with the

Variation of Parameters Method

What if g(x) isn’t in one of the forms that I discuss in the previous sections?

What if you can’t get the method of undetermined coefficients to work? In

either case, you can always turn to the variation of parameters method.

So what’s this variation of parameters technique? It’s a clever one! Say that

you have the following differential equation:

y" + p(x)y' + q(x)y = g(x)

Now assume that you know the solution to the corresponding homogeneous

equation:

y" + p(x)y' + q(x)y = 0

The general homogenous solution is:

y = c y + c y

h

1

1

2 2

Here’s the first trick: You now replace the constants c and c with functions

1

2

u (x) and u (x) to find a particular solution. This is what the equation looks like:

1

2

y = u (x)y + u (x)y

2

p

1

1

2

Then you try to find the functions u (x) and u (x) such that this equation is a

1

2

particular solution of the nonhomogeneous differential equation (not the

homogeneous differential equation).

Here’s the second trick: Substituting this equation into your original nonho-

mogeneous equation is going to give you one equation in two unknowns,

u (x) and u (x), as well as their first two derivatives. You need a second con-

1

2

straint on the values of u (x) and u (x) as well. And because you’re looking

1

2

only for a single particular solution, you can choose that constraint on u (x)

1

and u2(x) to make the math easier.

In the following sections, I explain the basics of the variation of parameters

method and take you step by step through some interesting examples. I also

discuss the relationship of this method to one called the Wronskian (see

Chapter 5 for details).





136

**Part II: Surveying Second and Higher Order Differential Equations**

Nailing down the basics of the method

First up: You need y' and y" to substitute into your original nonhomogeneous

equation. Start with y', the first derivative of y = u (x)y + u (x)y :

p

1

1

2

2

y' = u' (x)y + u (x)y' + u' (x)y + u (x)y'

2

1

1

1

1

2

2

2

Here’s where the second trick comes in (the one designed to make the math

easier). Because you get to choose the second constraint on u (x) and u (x),

1

2

choose the constraint so that:

u' (x)y + u' (x)y = 0

1

1

2

2

The second trick makes the math easier because now the first derivative

becomes:

y' = u (x)y' + u (x)y'

2

1

1

2

Quite a bit simpler, right? Now for y":

y" = u' (x)y' + u (x)y" + u' (x)y' + u (x)y"

2

1

1

1

1

2

2

2

Now substitute y, y', and y" into the nonhomogeneous equation. The resulting

equation is going to look messy, but don’t fret because something good

happens:

u (x)[y " + p(x)y ' + q(x)y ] + u (x)[y " + p(x)y ' + q(x)y ] + u' (x)y ' +

1

1

1

1

2

2

2

2

1

1

u' (x)y ' = g(x)

2

2

Note that the first two terms are zero (that’s the good thing that happens),

because y and y are solutions of the homogeneous equation. This means

1

2

that you’re left with:

u' (x)y ' + u' (x)y ' = g(x)

1

1

2

2

You now have two equations in u' (x) and u' (x):

1

2

u' (x)y (x) + u' (x)y (x) = 0

1

1

2

2

u' (x)y '(x) + u' (x)y '(x) = g(x)

1

1

2

2

Using these equations, you can solve for u' (x) and u' (x). Then you can inte-

1

2

grate them, and you’ll have a particular solution to the original nonhomoge-

neous differential equation, because where y and y are linearly independent

1

2

solutions of the homogeneous equation:

y = u (x)y (x) + u (x)y (x)

p

1

1

2

2





137

**Chapter 6: Studying Second Order Linear Nonhomogeneous Differential Equations**

Solving a typical example

To help solidify the basics in your mind, put them to work with the following

differential equation:

y" + 4y = sin 2x

2

The homogenous equation is:

y" + 4y = 0

The general solution to the homogeneous equation is the following (I’ll skip the

details here; you can find out how to complete this step earlier in this chapter):

y = c cos 2x + c sin 2x

h

1

2

So:

y1 = cos 2x

y2 = sin 2x

and

This means that you’ll be searching for a particular solution of the following

form:

y = u (x) cos 2x + u (x) sin 2x

p

1

2

where you need to determine u (x) and u (x). The method of variation of

1

2

parameters tells you that:

u' (x)y (x) + u' (x)y (x) = 0

1

1

2

2

u' (x)y '(x) + u' (x)y '(x) = g(x)

1

1

2

2

Substituting in for y and y gives you these equations:

1

2

u' (x) cos 2x + u' (x) sin 2x = 0

1

2

–2u' (x) sin 2x + 2u' (x) cos 2x = sin

2

2x

1

2

Solving these equations for u' (x) and u' (x) gives you:

1

2

^ h

-sin

3

2x

ul x =

1

2





138

**Part II: Surveying Second and Higher Order Differential Equations**

and:

^ h

sin

2

2xcos2x

2

ul x =

2

You can integrate to find u (x) and u (x):

1

2

^ h

cos2x cos

3

2x

u x =

\-

1

4

12

and:

^ h

sin

3

2x

u

x =

2

12

Why aren’t you using any constants of integration here? Because you need

only one particular solution, so you can choose the constants of integration

to equal zero, which means that the particular solution is (after the algebra

and trig dust settles):

^ h

cos

2

2x sin

2

2x

y

x =

\+

p

6

12

So, the general solution of your original nonhomogeneous equation is:

y = yh + yp

which means it looks like this:

cos

2

2x sin

2

2x

y = c cos2x + c sin2x +

\+

1

2

6

12

Beautiful.

Applying the method to

any linear equation

As you can see from the previous sections, the method of variation of para-

meters can be useful. It’s broader in application than the method of undeter-

mined coefficients that I discuss earlier in this chapter. Why? The method of

undetermined coefficients works only for a few forms of g(x).

On the other hand, you can use the method of variation of parameters for all

linear differential equations (linear in y). For second order differential equa-

tions like the ones in this chapter, you get a system of two equations to solve;

for a system of three differential equations, you get three equations to solve;

and so on. The problem comes in the integration of u' (x), u' (x), and so on,

1

2

because the integration may not be possible.





139

**Chapter 6: Studying Second Order Linear Nonhomogeneous Differential Equations**

Take a look at an example that brings this issue to light. Here’s a whopper of

a differential equation:

d

2

y

2

dy 2y

^ h

2

1

\-

x

\+

\=

2

x

ln x

dx

dx

x

Why is this equation such a whopper? Well, for starters, it isn’t separable

(see Chapter 3 for an explanation of separable equations). And to top it off,

you can’t use the method of undetermined coefficients. But it’s linear, so you

can use the method of variation of parameters, as you find out in the follow-

ing sections.

The general solution of the homogeneous equation

First, take a look at the homogeneous equation:

d

2

y

2

dy 2y

2

\-

x

\+

= 0

2

dx

dx

x

You may notice that this equation looks a little more manageable than the

original one. After looking at the form of this differential equation and noting

that each successive term has another power of x in the denominator, you

would likely decide to try a solution of the form y = x . And by substituting

n

into the differential equation, you get:

n(n–1)xn–2 – 2nxn–2 + 2xn–2 = 0

After dividing by xn–2 and doing a little algebra, you get:

n

2

– n – 2n + 2 = 0

– 3n + 2 = 0

So:

n

2

You can solve this with the quadratic equation to get:

3 ! 1

2

n =

So n = 1 and n = 2, which means that you have two linearly independent

1

2

solutions of the homogeneous differential equation:

y1 = x

and

y2 = x

2





140

**Part II: Surveying Second and Higher Order Differential Equations**

You get the following as the general solution of the homogeneous differential

equation:

y = c x + c x

2

h

1

2

The particular and general solutions of the nonhomogeneous equation

Now you have to find the particular solution, yp, of the original nonhomoge-

neous differential equation. Why? Because its general solution is the sum of

the general solution of the homogeneous differential equation and the partic-

ular solution of the nonhomogeneous differential equation:

y = yh + yp

Say you have a linear differential equation of the following form:

y" + p(x)y' + q(x)y = g(x)

In this case, it’s a doozy of an equation, and:

^ h

2

p x =

x

^ h

2

q x =

x

2

^ h

^ h

1

g x = ln x

x

Okay, so you can’t use the method of undetermined coefficients. Never fear;

this is where the method of variation of parameters comes in. Accordingly,

you plan a solution of the following form:

y = u (x)x + u (x)x

2

p

1

2

The method of variation of parameters gives you:

u' (x)y (x) + u' (x)y (x) = 0

1

1

2

2

u' (x)y '(x) + u' (x)y '(x) = g(x)

1

1

2

2

So:

u' (x)x + u' (x)x = 0

2

1

2

and:

^ h

^ h

^ h

1

ul x + ul x 2x = ln x

x

1

2





141

**Chapter 6: Studying Second Order Linear Nonhomogeneous Differential Equations**

From:

u' (x)x + u' (x)x

2

= 0

1

2

you get:

u' (x) = –u' (x)x

1

2

And substituting that into the second equation gives you:

^ h

^ h

^ h

1

-ul x x + ul x 2x = ln x

x

2

2

So with a little combining, you get:

^ h

^ h

1

ul x =

ln x

2

x

2

Substituting that equation into u' (x)x + u' (x)x = 0 gives you the following:

2

1

2

^ h

^ h

1

ul x = - ln x

x

1

Now you have u' (x) and u' (x), and you have to integrate them. (**Tip:** You can

1

2

find the integrals in most standard calculus books.) Here are the answers (as

in the previous section, neglecting any constants of integration, because you

need only one particular solution):

^ h

^ h

1

u x = - ln

2

x

1

2

and:

^ h

^ h

1

1

u

x = - ln x -

x

x

2

Substituting that into the following equation:

y = u (x)x + u (x)x

2

p

1

2

gives you:

^ h

^ h

x

y p =- ln

2

x - xln x - x

2

Alright. You’re almost there! Because:

y = yh + yp





142

**Part II: Surveying Second and Higher Order Differential Equations**

you know that:

^ h

^ h

x

2

y = c x + c x

2

\-

ln

2

x - xln x - x

1

2

In fact, you can absorb the final –x term into c1x, giving you the general

solution:

^ h

^ h

x

2

y = c x + c x

2

\-

ln

2

x - xln x

1

2

What a pair! The variation of parameters

method meets the Wronskian

As noted in the previous sections, the method of variation of parameters

allows you to tackle linear differential equations, such as this second order

differential equation:

y" + p(x)y' + q(x)y = g(x)

The method of variation of parameters relies on the solution to the homoge-

neous equation:

y" + p(x)y' + q(x)y = 0

The solution to the homogeneous equation is:

y = c y (x) + c y (x)

h

1

1

2 2

The method of variation of parameters says that you then try to find a partic-

ular solution of the following form:

y = u (x)y (x) + u (x)y (x)

p

1

1

2

2

Substituting yp into the differential equation gives you these two equations:

u' (x)y (x) + u' (x)y (x) = 0

1

1

2

2

u' (x)y '(x) + u' (x)y '(x) = g(x)

1

1

2

2

You can formally solve these equations for u' (x) and u' (x) as follows:

1

2

~~^ h ^ h~~

^ h

-y x g x

ul x =  ~~^ h~~

~~^~~

2

~~h~~

~~^ h ^ h~~

1

y x yl x - yl x y

x

1

2

1

2

and:

~~^ h ^ h~~

^ h

y x g x

ul x =  ~~^ h~~

~~^~~

1

~~h~~

~~^ h ^ h~~

2

y x yl x - yl x y

x

1

2

1

2





143

**Chapter 6: Studying Second Order Linear Nonhomogeneous Differential Equations**

In fact, it turns out that the denominator is the Wronskian (introduced in

Chapter 5), W, for y , y , and x, W(y , y )(x):

1

2

1

2

W = y (x)y' (x) – y '(x)y (x)

1

2

1

2

So, you can write the equations for u' (x) and u' (x) like this instead:

1

2

^ h ^ h

^ h -y x g x

ul x =

\_

2

i^ h

1

W y ,y

x

1

2

and:

^ h ^ h

^ h

y x g x

ul x =

\_

1

i^ h

2

W y ,y

x

1

2

Note that dividing by the Wronskian is okay because y and y are a set of lin-

1

2

early independent solutions, so their Wronskian is nonzero. This means that

you can solve for u1(x) (at least theoretically) like this:

^ h ^ h

^ h

y

x g x

\#

u x =-

\_

2

i^ h dx + c

1

W y ,y

x

1

1

2

And you can solve for u2(x) like this:

^ h ^ h

^ h

y x g x

\#

u

x =

\_

1

i^ h dx + c

2

W y ,y

x

2

1

2

Of course, there’s no guarantee that you can perform the integrals in these

equations. But if you can, you can get u (x) and u (x), such that a particular

1

2

solution to the differential equation is:

y = u (x)y (x) + u (x)y (x)

p

1

1

2

2

The general solution is:

y = c y (x) + c y (x) + u (x)y (x) + u (x)y (x)

1

1

2

2

1

1

2

2

Bouncing Around with Springs ’n’ Things

Second order differential equations play a big part in elementary physics.

They’re used in describing the motion of springs and pendulums, electromag-

netic waves, heat conduction, electric circuits that contain capacitors and

inductors, and so on. I provide a couple of examples of second order differen-

tial equations in the following sections.





144

**Part II: Surveying Second and Higher Order Differential Equations**

A mass without friction

Here I show you the differential equation describing the motion of a mass on

the end of a spring. Say, for example, that you have the situation shown in

Figure 6-1, where a mass is moving around (without friction) on the end of a

spring. In the following sections, I show you how to solve this physics prob-

lem with the help of a nonhomogeneous equation.

**Figure 6-1:**

A spring

with a mass

moving

without

friction.

Turning the physics into a differential equation

The force that the spring in Figure 6-1 exerts on the mass is proportional to

the amount that the spring is stretched, and the constant of proportionality

is called the spring constant, k. Thus the force that the spring exerts on the

mass is:

F = –ky

where k is the spring constant (which you have to measure for every spring

you want to use) and y is the distance away from the equilibrium position

(where the spring is unstretched).

The minus sign is included to indicate that the force is a restorative force,

meaning that it always pulls toward the equilibrium position. So the force is

always in the opposite of the direction you’re pulling. If x, the distance from

the equilibrium position, is positive, the force exerted by the spring is nega-

tive, pulling back toward the equilibrium position.





145

**Chapter 6: Studying Second Order Linear Nonhomogeneous Differential Equations**

The force exerted by the spring is proportional to the length by which you’re

pulling the spring. As you may know from elementary physics, the force on

an object is equal to its mass multiplied by its acceleration:

F = ma

where m is the object’s mass, and a is its acceleration.

Here’s where the differential equation comes in, because acceleration is the

second order derivative of distance with respect to time (symbolized by t):

d

2

y

a =

dt

2

You can write the equation for force like this:

d

2

y

F = m

dt

2

In keeping with the notation I use throughout this book, I’ll write the previous

equation like this, where the second derivative of distance with respect to

time is given by y":

F = my"

Note that in physics, differentiating by time is often given by putting a dot

above the variable being differentiated, and differentiating twice with respect

to time is given by placing two dots above the variable being differentiated,

like this: ë.

The mass is accelerated by the spring, so F = ma is equal to F = –ky. So you

have this:

my" = –ky

You’re back in differential equation territory again, so now you’ll take over

from the physicists. Here’s what this equation looks like in a form you’re

more used to:

my" + ky = 0

This equation is okay, but it’s a homogeneous differential equation. And this

is, after all, a chapter on nonhomogeneous differential equations. To solve

this dilemma, you can add a periodic force, acting on the mass, say F cosω t.

0

0

Adding this force makes this a nonhomogeneous differential equation:

my" + ky = F cos ω t

0

0





146

**Part II: Surveying Second and Higher Order Differential Equations**

You’re driving the mass with this new force, F cos ω t. This is a periodic force,

0

0

with period (that is, the time it takes to complete a cycle):

2π

T =

ω

0

What’s going to happen now that the mass is subject to the spring force and

the new driving force? You can find out by solving my" + ky = F cos ω t.

0

0

The general solution to the homogeneous equation

To solve my" + ky = F cos ω t, you need to take a look at the corresponding

0

0

homogeneous equation:

my" + ky = 0

Put this equation into standard form, like so:

ky

m

y''+

= 0

In other words, the equation looks like this:

ky

m

y''= -

Now you need something that changes sign upon being differentiated twice,

which means that you need to use sines and cosines. So assume that:

y1 = cos ωx

and

y2 = sin ωx

Plugging y and y into the y" equation, you get:

1

2

k

ω

2

\=

m

or:

k

ω =

m

So the general homogeneous solution is:

y = c cos ωx + c sin ωx

h

1

2





147

**Chapter 6: Studying Second Order Linear Nonhomogeneous Differential Equations**

The particular and general solutions to the nonhomogeneous equation

Now you have to find a particular solution to the nonhomogeneous equation:

my" + ky = F cos ω t

0

0

which you can write as:

ky

m

F

0

y''+

\=

cosω0 t

m

Using the method of undetermined coefficients that I describe earlier in this

chapter, you can guess that the particular solution is of the following form:

y = A cos ω t

p

0

where A is yet to be determined.

You can dispense with the B sin ω t term because the differential equation

0

involves only y" and y, and g(x) is a cosine. So the B in B sin ω t would have to

0

be zero.

Plugging your attempted solution into the nonhomogeneous equation yields:

k

-A ω cosω t +

2

Acosω0 t =

F

0

cosω0 t

cosω0 t

m

m

0

0

or, since k/m = ω :

2

-A ω cosω t + A ω

2

2

cosω0 t =

F

m

0

0

0

Dividing by cos ω0t to simplify gives you:

-A ω + A ω

2

2

\=

F

0

m

0

Or:

So:

Aaω

\- ω

k

\=

F

2

2

0

m

0

F

A =

0

maω

\- w

k

2

2

0

And:

F cosω t

y p =

0

0

a

k

m ω

2

\- ω

2

0





148

**Part II: Surveying Second and Higher Order Differential Equations**

The general solution to the forced spring differential equation is:

F cosω t

y = c cosωx + c sinωx +

0

0

a

k

1

2

m ω

\- ω

2

2

0

You can see the graph of a representative solution, with c = c = 1, ω = 1, ω = ⁄ ,

2

1

1

2

0

and F /m(ω

2

– ω ) = 1, in Figure 6-2.

0

2

0

**Figure 6-2:**

Graphing

the math

behind a

mass

without

friction.

A mass with drag force

In this section is another example, but this time you include a drag force on

the mass. (You don’t have to read this example if you don’t want to. If you do,

be forewarned that the algebra gets a little involved.)

A drag force acting on a mass is referred to as damping. For example, the mass

may be moving through water or heavy fluid, and the damping force tends to

slow it down. The damping force is usually proportional to the speed of the

mass (the faster it goes, the more damping force there is), and the constant of

proportionality is γ, the damping coefficient. So here’s what the differential

equation of motion looks like with damping:

my" + γy' + ky = 0





149

**Chapter 6: Studying Second Order Linear Nonhomogeneous Differential Equations**

You now have a term in y', the speed of the mass on a spring. So how do you

solve this one? Well, you can try a solution of the form y = ert (which includes

sines and cosines if r is complex). Plugging this solution for y into the previ-

ous equation gives you:

mr

Canceling out ert gives you this characteristic equation:

mr + γr + k = 0

2

ert + γrert + kert = 0

2

The roots look like this:

\_

i

1/2

-γ ! γ

2

\- 4mk

r ,r =

1

2

2m

Look at the case where the discriminant, γ – 4mk, is less than zero. In that

2

case:

\_

i

1/2

γ ! i 4mk - γ

2m

2

r ,r =

1

2

So substituting r and r into ert, the solution can be written as:

1

2

y = e–γt/2m(A cos ωt + B sin ωt)

where:

~~\_~~

~~i~~

1/2

4km - γ

2m

2

ω =

The solution to the example is an interesting result. It indicates that the

motion of the mass is sinusoidal (like a sine wave), but it’s also multiplied by

an exponential that decays with time. So in this case, the mass oscillates with

a diminishing amplitude, tending toward zero motion. The usual way that the

solution is written is to let A = C cos δ and B = C sin δ, where δ is called the

phase angle. Now you can write the solution this way:

y = Ce–γt/2m cos (ωt – δ)

Writing the solution this way gives you the result in an even neater form. As

you can see, in this case, the solution has a decaying sinusoidal form — the

cos (ωt – δ) is multiplied by e–γt/2m, which goes to zero in time.

This reaction is just what you’d expect from a damped mass on a spring — it

would start oscillating, as you’d expect, and then slowly its motion would die

away. Think of a mass on a spring immersed in oil, for example.





150

**Part II: Surveying Second and Higher Order Differential Equations**

You can see a representative graph showing the mass’s motion in time in

Figure 6-3.

**Figure 6-3:**

Graphing

the math

behind a

mass with

drag force.





**Chapter 7**

**Handling Higher Order**

**Linear Homogeneous**

**Differential Equations**

In This Chapter

` `Discovering the notation of higher order differential equations

` `Introducing the fundamentals of higher order linear homogeneous equations

` `Working with real and distinct roots

` `Checking out complex roots

` `Dealing with duplicate roots

S

ome technicians from the local nuclear power plant storm into your

richly appointed office and say, “We need you to solve a differential equa-

tion, and quick.”

“Sure,” you say, “just let me finish lunch.”

“No,” they say, “we need the solution now.” You notice that they keep looking

over their shoulders nervously.

“And if you don’t get your solution now?” you ask, annoyed.

“Boom,” they say.

You put down your sandwich; this might be a rush job after all. “Okay,” you

say with a sigh, “let me see the differential equation.”

They put a piece of paper in front of you, and then you take a look:

y''' – 6y" + 11y' – 6y = 0





152

**Part II: Surveying Second and Higher Order Differential Equations**

“It’s a third order differential equation,” they say.

“I can see that,” you tell them.

“We only know how to solve up to second order,” they wail.

“Many first and second order methods are applicable to higher order differ-

ential equations,” you say, getting out your clipboard.

“Can you speed things up?” they ask, fidgeting.

“No problem,” you say. “The solution looks like this:”

y = c1e + c2e2x + c3e3x

x

“Wow,” they say. “That was quick work.” Then the techs start hurrying out

the door without paying you so much as a penny. Good thing you love work-

ing differential equations.

This chapter introduces higher order (also called nth order) differential equa-

tions, and by higher order, I mean any order higher than two. With the help of

this chapter, you can solve higher order differential equations in a snap, even

if they aren’t a matter of life and death! I focus on tips and tricks for solving

different kinds of higher order linear homogeneous equations (in other

words, those that equal zero).

The Write Stuff: The Notation of Higher

Order Differential Equations

Before I get into the nitty-gritty of higher order differential equations in the

following sections, you need a primer on their notation. Why? Well, they’re

slightly different from first and second order equations. For instance, here’s

an example of a higher order differential equation:

d

4

y

\- y = 0

dx

4

As you can see, this involves the fourth derivative of y with respect to x, so

it’s a fourth order differential equation. If you’ve read the first few chapters of

this book, you may expect that you can also write the equation like this:

y'''' – y = 0





153

**Chapter 7: Handling Higher Order Linear Homogeneous Differential Equations**

Surprise! Instead, this equation is usually written as:

y(4) – y = 0

Note the terminology: Instead of writing y'''', you write y(4). Derivatives up

to third order, y''', are commonly written using primes, but when it comes to

fourth order and up, go with the y(4) notation. After all, what would you

rather see:

y(9) – y = 0

or:

y''''''''' – y = 0

In some books, you may see higher order derivatives given with Roman

numerals, like this:

y

ix – y = 0

But because Roman numerals are on their way out in common usage today,

I stick with the y(9) version here.

Introducing the Basics of Higher Order

Linear Homogeneous Equations

Are you ready? It’s time to dig into higher order linear homogeneous differen-

tial equations. I start from the beginning in the following sections, with infor-

mation on their format, solutions, and initial conditions. I also provide some

handy theorems to help you on your way.

The format, solutions, and initial

conditions

A general higher order linear differential equation looks like this:

d

n

y

n

^ h dn - 1

y

^ h dn - 2

y

^ h dy

^ h

^ h

\+ p x

\+ p

x

+...+ p

n 1

\-

x

\+ p x y = g x

dx

1

dx

n

1

2

dx

n

2

dx

n

\-

\-





154

**Part II: Surveying Second and Higher Order Differential Equations**

This differential equation is linear in all derivatives of y with respect to x (it

involves only terms to the power 1), and it’s nonhomogeneous because it

equals the function g(x).

The homogeneous version of this differential equation looks like this:

d

n

y

n

^ h dn - 1

y

^ h dn - 2

y

^ h dy

^ h

\+ p x

\+ p

x

+...+ p

n 1

\-

x

\+ p x y = 0

dx

1

dx

n

1

2

dx

n

2

dx

n

\-

\-

where g(x) = 0.

Because homogeneous equations equal zero, working with them is a nice way

to ease into the world of higher order equations. You take a look at the higher

order homogeneous differential equation in this chapter, and then you delve

in to the nonhomogeneous version in Chapter 8.

Say, for example, that you have some solutions of the homogeneous

equation — y , y , and so on. If y , y , and so on are all solutions, then a linear

1

2

1

2

combination of them is also a solution. For instance:

y = c y + c y + . . . c y + cnyn

1

1

2

2

n-1 n–1

In this solution, c stands for various constants. (See the later section “The

general solution of a higher order linear homogeneous equation” for more

information.)

In addition, higher order differential equations can have initial conditions,

just as first order and second order differential equations can. For a higher

order differential equation, you can have this many initial conditions:

y(x ) = y , y'(x ) = y' . . . y(n–1)(x0) = y(n–1)

0

0

0

0

0

Solving differential equations of higher order where n = 3 or more is a lot like

solving differential equations of first or second order, except that you need

more integrations and have to solve larger systems of simultaneous equa-

tions to meet the initial conditions. To satisfy all these initial conditions, you

end up with a series of simultaneous equations, one for y(x ) = y , one for

0

0

y'(x ) = y' , and so on:

0

0

c y + c y + . . . cn–1yn-1 + c y = y

0

1

1

2

2

n

n

c y' + c y' + . . . cn–1y'n–1 + c y' = y'

0

1

1

2

2

n

n

c y" + c y' + . . . cn–1y"n–1 + c y" = y"

0

1

1

2

2

n

n

c1y(n–1) + c2y(n–1) + . . . cn–1y(n–1) + cny(n–1) = y(n–1)

n-1 n 0

1

2





155

**Chapter 7: Handling Higher Order Linear Homogeneous Differential Equations**

A couple of cool theorems

In the following sections, I give you a couple of helpful theorems about higher

order linear homogeneous differential equations. Put them to good use!

The general solution of a higher order linear homogeneous equation

You may wonder whether the solution you’ve found to a homogeneous equa-

tion, y = c y + c y + . . . cn–1yn–1 + c y , is a general solution. In other words, you

1

1

2

2

n n

want to figure out whether it encompasses every solution of the differential

equation. And that brings me to a theorem about the general solution of a

higher order linear homogeneous differential equation.

**If you have n solutions, y , y , . . . y , of a general linear homogeneous dif-**

**1**

**2**

**n**

**ferential equation of order n:**

**d**

**n**

**y**

**n**

^ h **dn** - **1**

**y**

^ h **dn** - **2**

**y**

^ h **dy**

^ h

\+ **p1**

**x**

\+ **p2**

**x**

+**...**+ **p**

**n 1**

\-

**x**

\+ **p x y** = **0**

**dx**

**dx**

**n**

**1**

**dx**

**n**

**2**

**dx**

**n**

\-

\-

**then a linear combination of those solutions:**

**y = c y + c y + . . . cn–1yn–1 + cn yn**

**1**

**1**

**2**

**2**

**encompasses all solutions if y , y , . . . y are linearly independent.**

**1**

**2**

**n**

What does it mean to be linearly independent? Well, the functions f , f , f . . . f

n

1

2

3

are linearly dependent if there exists a set of constants c , c , c ... c (not all of

1

2

3

n

which are zero) and an interval I such that:

c f + c f + . . . c + c f = 0

f

1 1

2 2

n–1 n–1

n n

for every x in I. The f , f , f . . . f are linearly independent if they aren’t linearly

1

2

3

n

dependent. It’s as simple as that.

If you have n linearly independent solutions for a linear homogeneous differ-

ential equation of order n, you have a fundamental set of solutions for the dif-

ferential equation. The general solution to the linear homogeneous differential

equation is a linear combination of the functions in the fundamental set of

solutions.

In other words, it’s the same story as I discuss in Chapter 5 for second order

linear homogeneous differential equations — only here it’s generalized for

higher orders.





156

**Part II: Surveying Second and Higher Order Differential Equations**

Solutions as related to the Wronskian

You can cast the theorem in the previous section in terms of the Wronskian,

which is the determinant of this matrix for a higher order differential equa-

tion (see Chapter 5 for full details about the Wronskian):

y

y

y

... y

n

1

2

3

yl1

ym

yl

ym

yl

ym

... yl

... ym

n

\_

i

2

3

n

W y ,y ,... y

\=

1

2

n

2

2

3

y

(n - 1)

y

(n - 1)

y

(n - 1)

...

y

(n - 1)

1

2

3

n

Here’s the theorem from the previous section written in terms of the

Wronskian:

**If you have n solutions, y , y , . . . y , of a general linear homogeneous dif-**

**1**

**2**

**n**

**ferential equation of order n:**

**d**

**n**

**y**

**n**

^ h

^ h

^ h **dy**

^ h

**d**

**n** - **1**

**d**

**n** - **2**

\+ **p1**

**x**

\+ **p2**

**x**

+**...**+ **p**

**n 1**

\-

**x**

\+ **p x y** = **0**

**dx**

**dx**

**n**

**1**

**dx**

**n**

**2**

**dx**

**n**

\-

\-

**and if their Wronskian, W(y , y . . . y )(x)** ≠ **0 in an interval I for at least**

**1**

**2**

**n**

**one point x in that interval, then all solutions of the homogeneous equa-**

**0**

**tion are encompassed by linear combinations of those solutions.**

Tackling Different Types of Higher Order

Linear Homogeneous Equations

In the following sections, you can check out several different cases of higher

order linear homogeneous equations: those with real and distinct roots, real

and imaginary roots, complex roots, and duplicate roots.

Real and distinct roots

The following sections walk you through one third order equation and one

fourth order equation, both of which have real and distinct roots.

A third order equation

Start by taking a look at the third order differential equation you solved at the

beginning of this chapter:

y''' – 6y" + 11y' – 6y = 0





157

**Chapter 7: Handling Higher Order Linear Homogeneous Differential Equations**

Assume these initial conditions:

y(0) = 9

y'(0) = 20

y"(0) = 50

This differential equation has constant coefficients (see Chapter 5 for more

information), so you can start by assuming a solution of the following form:

y = ert

Plugging this solution into your original equation gives you:

r

3

e

rt – 6r

Canceling out the ert yields:

– 6r + 11r – 6 = 0

2

ert + 11rert – 6ert = 0

r

3

2

The latter is the characteristic equation for the original homogeneous equa-

tion (check out Chapter 5 for more on characteristic equations). How do you

solve this equation for the roots?

Here’s when you start seeing one of the difficulties of higher order differential

equations — they’re like first and second order differential equations, only

more so. That is, a second order differential equation gives you a second order

characteristic equation, which you can solve with the quadratic equation.

But what if you’re faced with a differential equation of order 5? There is no

“quintic” equation — you’re on your own when it comes to finding the roots.

In the case of the characteristic equation in this example, you can (luckily)

factor it into this:

(r – 1) (r – 2) (r – 3) = 0

So the roots are:

r1 = 1

r2 = 2

r3 = 3

The roots are real and distinct, and the linearly independent solutions are:

y1 = e

x

y2 = e2x

y3 = e3x





158

**Part II: Surveying Second and Higher Order Differential Equations**

So the general solution to the original homogeneous equation is:

y = c1e + c2e2x + c3e3x

x

Now turn to the initial conditions. In addition to the form for y, you also need

y' and y" to meet the initial conditions:

y' = c1e

x

\+ 2c2e2x + 3c3e3x

and

y" = c1e

x

\+ 4c2e2x + 9c3e3x

From the initial conditions, y(0) = 9, y'(0) = 20, and y"(0) = 50, here are your

three simultaneous equations in c , c , and c :

1

2

3

y(0) = c + c + c = 9

1

2

3

y'(0) = c + 2c + 3c = 20

1

2

3

y"(0) = c + 4c + 9c = 50

1

2

3

Once again, here’s another place where you see the difference between first

and second order differential equations and those of higher order. With first

order differential equations that have initial conditions, solving for c1 is trivial.

With second order differential equations that have initial conditions, you end

up with a 2 x 2 system of equations — and solving that is easy. However, start-

ing with third order differential equations that have initial conditions, the n x n

system of simultaneous equations can be a little more challenging.

Solving a 3 x 3 system of simultaneous equations for c , c , and c involves

1

2

3

some tedious algebra. You can calculate this out if you want to invest the

time, or you can just use a computer. If you want to solve the system online,

there are various services to do so. One such Web site is math.cowpi.com/

systemsolver, which is a handy tool. You can simply select the type of

system you’re dealing with (such as 3 x 3, 4 x 4, and 5 x 5), plug in the right

numbers, and voila! You have an answer.

The solutions of your equations, simply stated, are:

c1 = 2

c2 = 3

c3 = 4





159

**Chapter 7: Handling Higher Order Linear Homogeneous Differential Equations**

So the solution of the original homogeneous equation with the initial condi-

tions applied is:

y = 2e + 3e2x + 4e3x

x

Cool. Good work!

A fourth order equation

Now you’re ready to try a differential equation of fourth order. Take a look at

this beauty:

y(4) + 10y''' + 35y" + 50y + 24 = 0

Yep, that’s a whopper. And it has initial conditions, too:

y(0) = 10

y'(0) = –20

y"(0) = 50

y'''(0) = –146

The differential equation has constant coefficients, so you can try a solution

of the following form:

y = erx

Substituting this solution into your original homogeneous equation gives you:

r

4

e

rx + 10r

And dividing by erx gives you this characteristic equation:

\+ 10r + 35r + 50r + 24 = 0

3

e

rx + 35r

2

erx + 50rerx + 24erx = 0

r

4

3

2

Okay, now you’re in a pickle. What are the roots of this equation? Well, by just

looking at it, you can figure out that it can be factored this way:

(r + 1) (r + 2) (r + 3) (r + 4) = 0

Just kidding — you can’t really tell that just by looking at the equation; I only

knew because I’m the one who made up the problem. So, if you have a char-

acteristic equation like this one that’s tough to factor, you can turn to online

equation solvers. One of my favorites is www.hostsrv.com/webmab/app1/

MSP/quickmath/02/pageGenerate?site=quickmath&s1=equations&s2=

solve&s3=basic (yes, I know — that’s a heck of an URL). A quick tip: When





160

**Part II: Surveying Second and Higher Order Differential Equations**

you enter variables raised to any power, be sure to add a caret (for instance,

you enter r as r^2). After you enter your equation, click the Solve button,

2

and if your equation is factorable, you’ll get the roots.

The roots of your characteristic equation are:

r1 = –1

r2 = –2

r3 = –3

r4 = –4

In other words, you have these three linearly independent solutions:

y1 = e–x

y2 = e–2x

y3 = e–3x

y4 = e–4x

So the general solution to the original homogeneous equation is:

y = c1e–x + c2e–2x + c3e–3x + c4e–4x

To meet the initial conditions, you need y', y", and y''':

y' = –c1e–x –2c2e–2x – 3c3e–3x – 4c4e–4x

y" = c1e–x + 4c2e–2x + 9c3e–3x + 16c4e–4x

y''' = –c1e–x – 8c2e–2x – 27c3e–3x – 64c4e–4x

Substituting the initial conditions gives you:

y(0) = c + c + c + c = 10

1

2

3

4

y'(0) = –c – 2c – 3c – 4c = –20

1

2

3

4

y"(0) = c + 4c + 9c + 16c = 50

1

2

3

4

y'''(0) = –c – 8c – 27c – 64c = –146

1

2

3

4

Well, this is another fine mess — you have a 4 x 4 system of simultaneous

equations in c , c , c , and c . You can invest the time to solve it algebraically,

1

2

3

4

or you can use a program to solve this system, such as math.cowpi.com/

systemsolver (which I mention in the previous section).





161

**Chapter 7: Handling Higher Order Linear Homogeneous Differential Equations**

You can see that:

c1 = 4

c2 = 3

c3 = 2

c4 = 1

which makes the general solution, including initial conditions, to the original

homogeneous equation look like this:

y = 4e–x + 3e–2x + 2e–3x + e–4x

Real and imaginary roots

Linear homogeneous equations with constant coefficients often have both

real and imaginary roots. Check out this equation, for instance:

y(4) – y = 0

Here are the initial conditions:

y(0) = 3

y'(0) = 1

y"(0) = –1

y'''(0) = –3

Because this is a linear homogeneous differential equation with constant

coefficients, you decide to try a solution of the following form:

y = ert

Plugging the solution into the original equation gives you:

4

r e

rt – ert = 0

After canceling out ert, you get this equation:

– 1 = 0

r

4





162

**Part II: Surveying Second and Higher Order Differential Equations**

As you may have noticed, this is a more manageable characteristic equation

than the one in the previous section. You can easily factor this characteristic

equation into:

(r

2

– 1) (r + 1) = 0

2

So the roots of this characteristic equation are:

r1 = 1

r2 = –1

r3 = i

r4 = –i

It looks as though you have real and imaginary roots for r and r . You can

3

4

handle complex roots with the following relations:

e

(α + iβ)x = eαx(cos βx + i sin βx)

and:

e

(α – iβ)x = eαx(cos βx – i sin βx)

Here, α = 0 for r and r , and you get:

3

4

e

iβx = cos βx + i sin βx

and:

e

–iβx = cos βx – i sin βx

So y and y can be expressed as a linear combination of sines and cosines.

3

4

Thus you have these solutions:

y1 = e

x

y2 = e–x

y3 = cos x

y4 = sin x

The general solution to the original homogeneous equation is:

y = c1e + c2e–x + c cos x + c sin x

3 4

x





163

**Chapter 7: Handling Higher Order Linear Homogeneous Differential Equations**

What happened to the i multiplying sin βx? As I discuss in Chapter 5, the i can

be absorbed into the constants c and c , because i is, after all, just a constant.

3

4

Now you have to handle the initial conditions. To do that, you also need y',

y", and y''':

y' = c1e

y" = c1e

y''' = c1e

x

x

x

– c2e–x – c sin x + c cosx

3 4

\+ c2e–x – c cos x – c sin x

3

4

– c2e–x + c sin x – c cos x

3

4

Substituting the initial conditions into the equation gives you:

y(0) = c + c + c = 3

1

2

3

y'(0) = c – c + c = 1

1

2

4

y"(0) = c + c – c = –1

1

2

3

y'''(0) = c – c – c = –3

1

2

4

And there you have it again — a 4 x 4 system of simultaneous equations.

You can solve this system by doing the algebra, or you can make it easy

on yourself and check out an online simultaneous equation solver, such as

math.cowpi.com/systemsolver. Go ahead; I’ll wait for you to come up

with the answers . . . .

Ready? So you have:

c1 = 0

c2 = 1

c3 = 2

c4 = 2

which means that the general solution with initial conditions is:

y = e–x + 2 cos x + 2 sin x

It’s lucky that c1 = 0. Why? Otherwise the solution would grow exponentially.

You can see a graph of the solution in Figure 7-1, where the exponential term

dies away in time.





164

**Part II: Surveying Second and Higher Order Differential Equations**

**Figure 7-1:**

The solution

to an

equation

with real

and

imaginary

roots.

Complex roots

The previous section handles the case where you have both real and imaginary

roots. What about the case where you have complex roots? For example, take a

look at this fine equation:

y(4) + 4y = 0

Because this is a fourth order linear homogeneous differential equation with

constant coefficients, you can try a solution of the following form:

y = erx

Plugging the solution into the original equation gives you:

4

r e

rx + 4erx = 0

Next, dividing by erx gives you this characteristic equation:

\+ 4 = 0

r

4





165

**Chapter 7: Handling Higher Order Linear Homogeneous Differential Equations**

So now you need the fourth root of –4, which isn’t something you’re likely to

find on your calculator. Once again, these equations come to the rescue:

e

(α + iβ)x = eαx(cos βx + i sin βx)

and:

e

(α - iβ)x = eαx(cos βx – i sin βx)

You can think of –4 as –4 + 0i, so:

–4 = 4 cos π + 4i sin π = 4eiπ

Note that this relation is determined only up to multiples of 2π, so this is

actually:

–4 = 4 cos (π + 2nπ) + 4i sin (π + 2nπ) = 4ei(π + 2nπ)

where n is an integer.

You can therefore find the fourth root of –4 this way:

(–4)1/4 = 41/4

e

i(π/4 + nπ/2)

Expanding the exponent gives you:

(–4)1/4 = 41/4 (cos (π/4 + nπ/2) + i sin (π/4 + nπ/2)

)

And using different values of n gives you the fourth roots of –4:

r1 = 1 + i

r2 = –1 + i

r3 = –1 – i

r4 = 1 – i

Great! You’ve made progress. Now you know that the fundamental set of solu-

tions is e(1 + i)x, e(–1 + i)x, e(–1 – i)x, and e(1 – i)x. By using these equations:

e

(α + iβ)x = eαx(cos βx + i sin βx)

and

e

(α – iβ)x = eαx(cos βx – i sin βx)





166

**Part II: Surveying Second and Higher Order Differential Equations**

the fundamental set of solutions can be given this way in the general solution:

y = c1e

x

cos x + c2e sin x + c3e–x cos x + c4e–x sin x

x

And that’s the general solution of your original homogeneous equation. Cool.

Duplicate roots

Duplicate roots are just what they sound like: one or more roots that are

repeated as you figure out the general solution of a homogeneous equation.

I describe several types of duplicate roots in the following sections.

A fourth order equation with identical real roots

Take a look at this differential equation, which is a fourth order homogeneous

differential equation with constant coefficients:

y(4) + 4y''' + 6y" + 4y' + y = 0

You can try a solution of the following form:

y = erx

Plugging the solution into the original homogeneous equation gives you this

characteristic equation:

r

4

\+ 4r

3

\+ 6r + 4r + 1 = 0

2

Holy mackerel, you might think. What are the roots of that thing? You can

factor this equation using an online equation factoring program, such as

hostsrv.com/webmab/app1/MSP/quickmath/02/pageGenerate?

site=quickmath&s1=equations&s2=solve&s3=basic.

If you’re determined to rely on your own brain to factor such an equation,

here’s a trick that sometimes helps: Convert the equation from base r to base

\10. That is, r + 2r + 1 becomes 100 + 20 + 1 = 121, which can be easily factored

2

into 11 x 11. Converting 11 from base 10 back to base r gives you (r + 1) (r + 1),

so the roots are –1 and –1. You can use this quick trick to astound your friends.

No matter which method you use, you’ll sooner or later figure out that you

can factor r

4

\+ 4r

3

\+ 6r + 4r + 1 = 0 this way:

2

(r + 1) (r + 1) (r + 1) (r + 1)





167

**Chapter 7: Handling Higher Order Linear Homogeneous Differential Equations**

So the roots of the characteristic equation are –1, –1, –1, –1 — all repeated

real roots. Does that mean the solutions are:

y1 = e–x

y2 = e–x

y3 = e–x

y4 = e–x

Hardly. You need linearly independent solutions to get a fundamental set of

solutions from which to build your general solutions. And because these are

all e–x, they’re obviously not linearly independent. (I talk about linear inde-

pendence in more detail in the earlier section “The general solution of a

higher order linear homogeneous equation.”)

What can you do here? Well, clearly you can’t have this as the general solution:

y = c1e–x + c2e–x +c3e–x +c4e–x

Why? Because that’s really equivalent to:

y = ce–x

where c = c + c +c + c

4

1

2

3

So what can you do? Easy: You add powers of x until you have as many linearly

independent solutions as you need. You can convert y = c e–x + c e–x + c3e–x + c4e–x

1

2

into a true general solution by introducing factors of x, x

2

, and x like this:

3

y = c1e–x + c2xe–x +c3x –x +c4x

2

e

3 –x

e

A fifth order equation with identical real roots

Take a look at this whopper, which is a fifth order homogeneous differential

equation:

y(5) – y(4) – 2y''' + 2y" + y' – y = 0

Because it’s homogeneous and has constant coefficients, you can try a solu-

tion in the form y = erx, giving you:

r

5

e

rx – r

After dividing by erx, you get this equation:

– r – 2r + 2r + r – 1= 0

4

e

rx – 2r

3

e

rx + 2r erx + rerx – erx = 0

2

r

5

4

3

2





168

**Part II: Surveying Second and Higher Order Differential Equations**

Your response may sound something like this: “I’m supposed to factor that?

Are you crazy?” Never fear; you can turn for help to an online equation

solver, such as hostsrv.com/webmab/app1/MSP/quickmath/02/

pageGenerate?site=quickmath&s1=equations&s2=solve&s3=basic.

The roots are –1, –1, 1, 1, 1, so r

5

– r

4

– 2r

3

\+ 2r + r – 1 = 0 can be factored

2

into this:

(r – 1) (r – 1) (r – 1) (r + 1) (r + 1) = 0

or:

(r – 1)

3

(r + 1) = 0

2

As you can see, this equation looks a lot more manageable than r

2r + r – 1 = 0. Because –1 is a root of the characteristic equation, this is a

solution:

5

– r

4

– 2r +

3

2

y1 = e–x

In fact, –1 is a double root, which also makes this a solution:

y2 = xe–x

Because you can also have 1 as a root, you have this solution:

y3 = e

Finally, you may also notice that 1 is a triple root, so in that case you also have:

y4 = xe

x

x

and

y5 = x

So the general solution to the original homogeneous equation is:

y = c1e–x + c2xe–x + c3e + c4xe + c5x

2ex

x

x

2ex

Notice that once again, the general solution is a linear combination of n lin-

early independent solutions, where n is the order of the differential equation.

And note that also, you multiply solutions by x, x , and so on depending on

2

their multiplicity as roots of the characteristic equation. Here, one root had

multiplicity 2 and the other multiplicity 3.





169

**Chapter 7: Handling Higher Order Linear Homogeneous Differential Equations**

Identical imaginary roots

Are you curious about the case where the roots of a characteristic equation

are duplicate and imaginary? For example, take a look at this differential

equation with constant coefficients:

y(4) + 8y" + 16y = 0

You can try a solution of the following form:

y = erx

Substituting this solution into your original homogeneous equation gives you:

r

4

e

rx + 8r

So your characteristic equation is:

\+ 8r + 16 = 0

You can factor this into:

(r + 4) (r + 4) = 0

2

erx +16erx = 0

r

4

2

2

2

So the roots are 2i, 2i, –2i, and –2i. As you can see, you have duplicate imagi-

nary roots here.

You can use these equations as I described earlier in this chapter:

e

(α + iβ)x = eαx(cos βx + i sin βx)

and:

e

(α – iβ)x = eαx(cos βx – i sin βx)

Here are the first two solutions, y and y :

1

2

y1 = cos 2x

and

y2 = sin 2x





170

**Part II: Surveying Second and Higher Order Differential Equations**

What about y and y ? You can use the same technique as in the previous sec-

3

4

tion: Multiply by progressively higher powers of x until you get all the linearly

independent solutions you need. In this case, all you need is one power of x

to give you:

y3 = x cos 2x

and

y4 = x sin 2x

So the general solution to the homogeneous equation is:

y = c cos 2x + c sin 2x + c x cos 2x + c x sin 2x

1

2

3

4

Identical complex roots

Here’s another example; it’s a fourth order equation with constant coefficients:

y(4) – 8y''' + 32y" – 64y' + 64y = 0

This equation is no problem. You just assume a solution of the form y = erx

and plug it into the original equation to get:

r

4

e

rx – 8r

So your characteristic equation is:

– 8r + 32r – 64r + 64 = 0

3

e

rx + 32r erx – 64rerx + 64erx = 0

2

r

4

3

2

Solving this characteristic equation gives you these roots:

r1 = 2 + 2i

r2 = 2 + 2i

r3 = 2 – 2i

r4 = 2 – 2i

So 2 + 2i is a root of multiplicity 2, and so is 2 – 2i. That leads to the following

general solution:

y = b1e(2 + 2i)x + b2xe(2 + 2i)x + b3e(2 – 2i)x + b4xe(2 – 2i)x





171

**Chapter 7: Handling Higher Order Linear Homogeneous Differential Equations**

where b , b , b , and b are constants. You can rewrite this equation as the

1

2

3

4

following:

y = e2x(b1e2ix + b2xe2ix) + e2x(b3e–2ix + b4xe–2ix

)

or:

y = e2x(b1e2ix + b3e–2ix) + e2xx(b2e2ix + b4e–2ix

)

Once again, you can turn to these relations:

e

iβx = cos βx + i sin βx

–iβx = cos βx – i sin βx

and:

e

Using these equations gives you:

(

)

y = e2x b (cos 2x + i sin 2x) + b (cos 2x - i sin 2x) + e2xx(b2(cos 2x + i sin 2x) +

1

3

b (cos 2x - i sin 2x))

4

Combining terms and consolidating constants gives you this form for the

general solution:

y = e2x(c cos 2x + c sin 2x) + e2xx(c cos 2x + c sin 2x)

1

2

3

4

And there you go, that’s the general solution where the characteristic equa-

tion has the roots 2 + 2i, 2 + 2i, 2 – 2i, and 2 – 2i.





172

**Part II: Surveying Second and Higher Order Differential Equations**





**Chapter 8**

**Taking On Higher Order**

**Linear Nonhomogeneous**

**Differential Equations**

In This Chapter

` `Breaking down higher order equations with the method of undetermined coefficients

` `Using the variation of parameters to solve higher order equations

T

he door to your office opens. A group of rocket scientists enters, looking

embarrassed. “We need you to solve a differential equation,” they say.

“I thought you were math specialists,” you retort.

“We thought so too. But this one has us stumped. It specifies the shape of the

rocket. Without it, we can’t take off.” They slide a sheet of paper onto your

desk. “Nobody has to know that we came to you for help, right?” They look

over their shoulders nervously.

“Right,” you say, taking a look at the sheet of paper, on which you see this

differential equation:

y''' + 6y" + 11y' + 6y = 336e5x

The equation has the following initial conditions:

y(0) = 9

y'(0) = –7

y"(0) = 47





174

**Part II: Surveying Second and Higher Order Differential Equations**

“It’s a nonhomogeneous third order differential equation,” the rocket scien-

tists say. “You’re stumped, right? We knew it!”

“Not so fast!” you say. “The solution is:”

y = 5e–x + 2e–2x + e–3x + e5x

The rocket scientists are stunned. “How did you do that?” they ask.

“Easy,” you say. “I read Chapter 8 of Differential Equations For Dummies. I

highly recommend it. Here’s my bill for solving your equation.”

The rocket scientists take the bill, and, reading it, raise their eyebrows.

“That’s astronomical,” they say.

“Well, you are rocket scientists, aren’t you?” you ask.

This chapter shows you how to handle nonhomogeneous linear differential

equations of order n, where n = 3, 4, 5, and so on. They look like this:

d

n

y

n

^ h dn - 1

y

^ h dn - 2

y

^ h dy

^ h

^ h

\+ p x

\+ p

x

\+ . . . + p

n 1

\-

x

\+ p x y = g x

dx

1

dx

n

1

2

dx

n

2

dx

n

\-

\-

In a higher order (or nth order) linear nonhomogeneous equation, the p vari-

ables are various functions. And in this case, unlike in Chapter 7, where I dis-

cuss higher order homogeneous equations, g(x) ≠ 0. When you’re done with

this chapter, you’ll be able to handle nonhomogeneous equations with ease.

Mastering the Method of Undetermined

Coefficients for Higher Order Equations

I first discussed the method of undetermined coefficients in Chapter 6 for

second order differential equations like this one:

y" + p(x)y' + q(x)y = g(x)

In this chapter, however, I generalize that method to help you get a handle on

differential equations of arbitrarily high order, not just two.





175

**Chapter 8: Taking On Higher Order Linear Nonhomogeneous Differential Equations**

The method of undetermined coefficients is all about finding a particular solu-

tion to a nonhomogeneous equation, yp. This method says that when you find

a candidate solution, yp, and plug it into the left-hand side of the equation, you

end up with g(x). Because g(x) is only a function of x, it’s often possible to

guess the form of yp(x), up to arbitrary coefficients, and then solve for those

coefficients by plugging yp(x) into the differential equation.

The form of g(x) can often tell you what a particular solution looks like (just

as it can when you’re dealing with second order equations). In particular, if

g(x) is in the form of:

` `**erx,** try a particular solution of the form Aerx, where A is a constant.

Because derivatives of erx reproduce erx, you have a good chance of find-

ing a particular solution this way.

` `**A polynomial of order n,** try a polynomial of order n.

` `**A combination of sines and cosines,** sinαx + cosβx, try a combinations

of sines and cosines with undetermined coefficients, Asinαx + Bcosβx.

Then you can plug into the differential equation and solve for A and B.

I explain these different forms in the following sections, but before I get to

them, here’s a summary of the method of undetermined coefficients for a

higher order differential equation:

**1. Find the general solution, y = c y + c y + . . . + c y of the associated**

**h**

**1**

**1**

**2**

**2**

**n**

**n**

**homogeneous differential equation.**

**2. If g(x) is of the form erx, a polynomial, a combination of sines and**

**cosines, or a product of any of these, assume that the particular solu-**

**tion is of the same form, using coefficients whose values have yet to**

**be determined.**

**3. If g(x) is the sum of terms, g (x), g (x), g (x), and so on (as they are in a**

**1**

**2**

**3**

**polynomial), break the problem into various subproblems like this:**

d

n

y

n

^ h dn - 1

y

^ h dn - 2

y

^ h dy

^ h

^ h

\+ p x

\+ p

\+ p

\+ p

x

\+ . . . + p

\+ . . . + p

\+ . . . + p

x

\+ p x y = g

x

dx

1

dx

n

1

2

2

2

dx

n

2

n

n

n

1

1

1

dx

n

1

2

3

\-

\-

\-

\-

\-

d

n

y

n

^ h dn - 1

y

^ h dn - 2

y

^ h dy

^ h

^ h

\+ p x

x

x

\+ p x y = g

x

dx

1

dx

n

1

dx

n

2

dx

n

\-

\-

d

n

y

n

^ h dn - 1

y

^ h dn - 2

y

^ h dy

^ h

^ h

\+ p x

x

x

\+ p x y = g

x

dx

1

dx

n

1

dx

n

2

dx

n

\-

\-

The particular solution of the nonhomogeneous equation is the sum of

the solutions of those subproblems.





176

**Part II: Surveying Second and Higher Order Differential Equations**

**4. Substitute yp into the differential equation, and solve for the undeter-**

**mined coefficients.**

**5. Find the general solution of the nonhomogeneous differential equa-**

**tion, which is the sum of y and y :**

**h**

**p**

y = yh + yp

**6. Use the initial conditions to solve for c , c . . . c .**

**1**

**2**

**n**

When g(x) is in the form erx

Take a look at the nonhomogeneous differential equation you solve so bril-

liantly for the rocket scientists at the beginning of this chapter:

y''' + 6y" + 11y' + 6y = 336e5x

Here are the equation’s initial conditions:

y(0) = 9

y'(0) = –7

y"(0) = 47

As with second order differential equations, the general solution to this non-

homgeneous differential equation is the sum of the solution to the corre-

sponding homogeneous differential equation, in which g(x) equals 0:

y''' + 6y" + 11y' + 6y = 0

and a particular solution to the full nonhomogeneous differential equation. In

other words:

y = yh + yp

where yh is the general solution to the homogeneous differential equation,

and yp is a particular solution to the nonhomogeneous differential equation.

The general solution to the homogeneous equation

The first order of business is to solve the homogeneous differential equation

y''' + 6y" + 11y' + 6y = 0. This is a third order linear homogeneous differential

equation with constant coefficients (like in Chapter 7), so you decide to try a

solution of the following form:

y = erx





177

**Chapter 8: Taking On Higher Order Linear Nonhomogeneous Differential Equations**

Plugging this solution into the homogeneous equation gives you:

r

3e

rx + 6r erx + 11rerx + 6erx = 0

2

And dividing by erx (to make things a bit simpler) gives you the following

characteristic equation (see Chapter 5 for more about this type of equation):

r

3

\+ 6r + 11r + 6 = 0

2

If you’re feeling extra sharp today and can do the algebra yourself, or if you

have an online equation solver at your beck and call like the one at www.

hostsrv.com/webmab/app1/MSP/quickmath/02/pageGenerate?site=

quickmath&s1=equations&s2=solve&s3=basic, you can see that the roots

of this equation are:

r1 = –1

r2 = –2

r3 = –3

You can factor r

3

\+ 6r + 11r + 6 = 0 this way:

2

(r + 1) (r + 2) (r + 3) = 0

So the general solution to the homogeneous differential equation y''' + 6y" +

11y' + 6y = 0 is:

y = c e–x + c2e–2x + c3e–3x

h

1

The particular solution to the nonhomogeneous equation

After you find the general solution to the homogeneous equation, you have to

find a particular solution, yp, to the nonhomogeneous equation. In this case,

g(x) has the following form:

g(x) = 336e5x

The method of undetermined coefficients says that you should try to match

the form of g(x) so that differentiating yp gives you the same form, up to the

value of multiplicative constants. Because differentiating simple exponents

gives you the same exponent back with possibly a different coefficient, the

method of undetermined coefficients says that in this case you should try yp

of this form:

yp = Ae5x





178

**Part II: Surveying Second and Higher Order Differential Equations**

Substituting this solution into the equation gives you:

125Ae5x + 150Ae5x + 55Ae5x + 6Ae5x = 336e5x

or:

125A + 150A + 55A + 6A = 336

Do the math and you get:

336A = 336

So:

A = 1

which means that the particular solution, yp, of the nonhomogeneous equa-

tion is given by this:

yp = e5x

And because:

y = yh + yp

the general solution to the nonhomogeneous equation is:

y = c1e–x + c2e–2x + c3e–3x + e5x

Applying initial conditions

To handle the initial conditions of the original nonhomogeneous equation,

you need to find y, y' and y":

y = c1e–x + c2e–2x + c3e–3x + e5x

y' = –c1e–x – 2c2e–2x – 3c3e–3x + 5e5x

y" = c1e–x + 4c2e–2x + 9c3e–3x + 25e5x

Plugging in x = 0 gives you the following:

y(0) = c + c + c + 1 = 9

1

2

3

y'(0) = –c – 2c – 3c + 5 = –7

1

2

3

y"(0) = c + 4c + 9c + 25 = 47

1

2

3





179

**Chapter 8: Taking On Higher Order Linear Nonhomogeneous Differential Equations**

Time to do a little simplifying:

y(0) = c + c + c = 8

1

2

3

y'(0) = –c – 2c – 3c = –12

1

2

3

y"(0) = c + 4c + 9c = 22

1

2

3

This is a 3 x 3 system of simultaneous equations. You can work it out step

by step, or you can use a handy equation system solver like the one at

math.cowpi.com/systemsolver. Either way you work it, you find that c1,

c , and c are:

2

3

c1 = 5

c2 = 2

c3 = 1

So the general solution to your original nonhomogeneous equation with the

given initial conditions is:

y = 5e–x + 2e–2x + e–3x + e5x

Just as you told the rocket scientists at the beginning of the chapter. Nice work!

When g(x) is a polynomial of order n

Take a look at this differential equation stumper that I put together for you:

y''' – y' = x + 60e–4x + 9 sin x

It’s the triple play: A third degree differential equation that’s equal to a poly-

nomial, an exponential, and a trig function — all at the same time. Seriously,

though, solving this equation isn’t as difficult as you may think; just check

out the following sections.

The general solution to the homogeneous equation

Start by looking for the general solution to the corresponding homogeneous

differential equation:

y''' – y' = 0

This equation looks like a linear homogeneous differential equation with con-

stant coefficients, so you can plug in the handy y = erx

:

3

r erx – rerx = 0





180

**Part II: Surveying Second and Higher Order Differential Equations**

So the characteristic equation, after dropping erx, is:

r

3

– r = 0

One root is clearly r = 0, and dividing by r gives you:

– 1 = 0

r

2

The roots of this equation are 1 and –1, and so the solution to the homoge-

neous differential equation is:

y = c + c e – c3e–x

x

h

1

2

The particular solution to the nonhomogeneous equation

Okay, so far so good. But now you have to find a particular solution, yp. In this

case, g(x) is:

g(x) = x + 60e–4x + 9 sin x

Clearly, you have a polynomial on your hands. What to do? The way to

handle this situation is to break g(x) into three parts:

g1(x) = x

g2(x) = 60e–4x

g3(x) = 9 sin x

Now you have three differential equations to solve:

y''' – y' = x

y''' – y' = 60e–4x

y''' – y' = sin x

And the corresponding particular solutions are y , y , and y , respectively,

p1

p2

p3

which means that the general solution of the nonhomogeneous equation is:

y = y + y + y + y

p3

h

p1

p2

Alright, start by looking for y , with g (x) = x. To do so you have to solve

p1

1

y''' – y' = x.





181

**Chapter 8: Taking On Higher Order Linear Nonhomogeneous Differential Equations**

Because g1(x) = x here, you may think of using yp1 = Ax, but unfortunately, x is

already a solution of the homogeneous differential equation. So yp1 = Ax is

out. Instead, you can try:

yp1 = Ax

2

Plugging that solution into y''' – y' = x gives you:

–2Ax = x

So:

A = –1

⁄

2

And therefore:

-x

2

2

y p1 = Ax

2

\=

Okay, now for yp2, which is the solution to y''' – y' = 60e–4x. Because g2(x) = e–4x

here, you can try a solution of the following form:

yp2 = Ae–4x

Plugging yp2 into y''' – y' = 60e–4x gives you:

–64Ae–4x + 4Ae–4x = 60e–4x

or:

–60Ae–4x = 60e–4x

So:

A = –1

and

yp2 = –e–4x

Great! You’re making progress. The last thing you have to do is find yp3, the

third particular solution. That means solving y''' – y' = sin x, for which you

may be tempted to try a solution like this:

yp3 = Acos x + Bsin x





182

**Part II: Surveying Second and Higher Order Differential Equations**

However, take a look at the equation you’re trying to solve here:

y''' – y' = sin x

The first and third derivatives of Acos x yield terms in sin x, which is what

you’re looking for here, but the first and third derivatives of Bsin x yield

terms in cos x, which means that B = 0. So try a solution like yp3 = Acos x.

Plugging yp3 into y''' – y' = sin x gives you:

Asin x + Asin x = sin x

After dropping sin x you get:

A + A = 1

So:

A = ⁄

2

1

which makes yp3 equal to:

cosx

y

\=

p3

2

You now have all the particular solutions to the nonhomogeneous equation

(and the general solution to the homogeneous equation from the previous

section), so you can finally put everything together! Because:

y = y + y + y + y

p3

h

p1

p2

you get:

y = c + c e

x

2

cosx

2

x

\- c3 e- x

\- e- 4x

\+

\-

1

2

2

When g(x) is a combination

of sines and cosines

Here’s another higher order problem to work through; this time, the solution

is a combination of sines and cosines, and the problem is of the fourth order:

y(4) + 2y" + y = 8 sin x – 16 cos x

Easy, right? All you have to do is find the general solution to the homoge-

neous equation, followed by the particular and general solutions to the non-

homogeneous equations. Read on for details.





183

**Chapter 8: Taking On Higher Order Linear Nonhomogeneous Differential Equations**

The general solution to the homogeneous equation

The homogeneous differential equation, in which g(x) equals 0, is:

y(4) + 2y" + y = 0

This is a linear homogeneous differential equation with constant coefficients.

This means you can try a solution of the form y = erx. Plugging this solution

into the homogeneous equation gives you:

r

4

e

rx + 2r

Or, for simplicity’s sake:

\+ 2r + 1 = 0

You can factor this into:

(r + 1) (r + 1) = 0

2

erx + erx = 0

r

4

2

2

2

So the roots of the characteristic equation are i, i, –i, and –i. Two solutions to

the homogeneous differential equation are:

y1 = eix

and

y2 = e–ix

And because i and –i are repeated roots, you also have:

y3 = x eix

and

y4 = x e–ix

So:

y = b eix + b2e-ix + b3 x eix + b4 x e–ix

h

1

where b – b are constants. And because:

1

4

e

iβx = cos βx + i sin βx

–iβx = cos βx – i sin βx

and:

e





184

**Part II: Surveying Second and Higher Order Differential Equations**

you can express the general solution to the homogeneous equation as:

y = c cos x + c sin x + c x cos x + c x sin x

h

1

2

3

4

The particular solution to the nonhomogeneous equation

Now it’s time to find a particular solution, yp, of your original nonhomogeneous

equation. In this case,

g(x) = 8 sin x – 16 cos x

You might consider trying a particular solution of the following form:

yp = A sin x + B cos x

But that particular solution isn’t linearly independent from yh, which has sin x

and cos x terms in it. (Linear independence is important to find a complete

set of solutions; see Chapter 5 for more information.) So you might consider

a solution of the form yp = A x sin x + B x cos x. But once again, this solution

isn’t linearly independent with respect to yh, which has terms in x sin x + x

cos x already. So you’re left with the following for yp:

yp = A x

2

sin x + B x cos x

2

Substituting this solution into your nonhomogeneous equation, and collect-

ing terms gives you:

–8 A sin x – 8 B cos x = 8 sin x – 16 cos x

So, comparing terms, you can see that:

A = –1

and:

B = 2

Now you know that the particular solution is:

yp = –x

The general solution to the nonhomogeneous equation is:

y = c cos x + c sin x + c x cos x + c x sin x – x sin x + 2 x cos x

2

sin x + 2 x

2

cos x

2

2

1

2

3

4

Wow, a pretty lengthy solution. Impressive!





185

**Chapter 8: Taking On Higher Order Linear Nonhomogeneous Differential Equations**

**A handy trick for finding particular**

**solutions in sine and cosine form**

The method of undetermined coefficients (which Also, because x

2

e–x sin x is a solution, so is x

2

e

–x

is discussed earlier in this chapter) is based on cos x, because complex roots of the character-

the fact that when g(x) is of a certain form, you istic equation come in conjugate pairs. This

can often guess the form of the particular solu- means that you can find the other three solu-

tion up to arbitrary coefficients. In fact, you can tions:

play a neat trick this way. If, for example, you

y4 = e–x cos x

have a sixth order homogeneous differential

equation (yowza!) and know that x

2e–x sin x is a

y5 = xe–x cos x

solution, can you determine the other solutions?

That is, given that:

y6 = x e–x cos x

2

So the general solution to the homogeneous dif-

y1 = x e–x sin x

2

ferential equation that has x e sin x as a solu-

2

–x

can you find y – y so that all solutions are lin- tion is:

2

6

early independent? The short answer is this:

y = x

2

e–x sin x + e–x sin x + x e–x sin x + e–x cos

Yes, you can. Because x e–x sin x is a solution,

2

x + xe–x cos x + x e–x cos x

2

so are these two:

And you can determine all that starting with just

y2 = e–x sin x

one solution, y = x e sin x.

2

–x

1

y3 = x e–x sin x

Solving Higher Order Equations with

Variation of Parameters

The method of undetermined coefficients, which I discuss earlier in this

chapter, is good only for certain forms of g(x). For more general differential

equations of a higher order, you can try the method of variation of parameters.

This method was first introduced in Chapter 6 for differential equations of

the second order, but here I generalize it for equations of order n.

The basics of the method

To get a good grasp on this method, imagine that you have this general linear

nonhomonegeous differential equation of order n:

d

n

y

n

^ h dn - 1

y

^ h dn - 2

y

^ h dy

^ h

^ h

\+ p x

\+ p

x

\+ . . . + p

n 1

\-

x

\+ p x y = g x

dx

1

dx

n

1

2

dx

n

2

dx

n

\-

\-





186

**Part II: Surveying Second and Higher Order Differential Equations**

The corresponding homogeneous differential equation is:

d

n

y

n

^ h dn - 1

y

^ h dn - 2

y

^ h dy

^ h

\+ p x

\+ p

x

\+ . . . + p

n 1

\-

x

\+ p x y = 0

dx

1

dx

n

1

2

dx

n

2

dx

n

\-

\-

If the general solution to the homogeneous differential equation is:

y = c y + c y + c y + . . . + c y

n n

h

1

1

2

2

3

3

then the variation of parameters says to look for a particular solution of the

following form:

y = u (x)y + u (x)y + u (x)y + . . . + u (x)y

n

p

1

1

2

2

3

3

n

where u (x), u (x), and so on are functions.

1

2

The method of variation of parameters for differential equations of order n

says that to find yp, you can solve this system of simultaneous equations for

u' (x), u' (x), and so on like this:

1

2

u' y + u' y + . . . u' y = 0

1

1

2

2

n n

u' y' + u' y' + . . . u' y' = 0

1

1

2

2

n

n

u'1y(n–2) + u'2y(n–2) + . . . u'ny(n–2) = 0

1

2

n

u'1y(n–1) + u'2y(n–1) + . . . u'ny(n–1) = g(x)

1

2

n

Then you integrate u' (x), u' (x), and so on to find u (x) and u (x), which in

1

2

1

2

turn gives you yp.

Working through an example

Here’s an example that can help you get your feet wet with the method of vari-

ation of parameters. Try solving this differential equation using the method:

y

(4) = 6x

To do so, you first need the solution to the homogeneous differential equation:

(4) = 0

y

You can solve this equation by integration to get:

y1 = 1

y2 = x

y3 = x

y4 = x

2

3





187

**Chapter 8: Taking On Higher Order Linear Nonhomogeneous Differential Equations**

The homogeneous equation’s general solution is:

y = c + c x + c x

2

\+ c4x

3

h

1

2

3

Now you insert u (x), u (x), and so on for the constants to find the particular

1

2

solution of the nonhomogeneous solution:

y = u (x) + u (x)x + u (x)x + u4(x)x

2

3

p

1

2

3

Here’s where the method of variation of parameters kicks in, giving you these

simultaneous equations in u' (x), u' (x), u' (x), and u' (x) by integration:

1

2

3

4

u' + u' x + u' x

2

\+ u'4x

3

= 0

1

2

3

u' + u' 2x + u' 3x = 0

2

2

3

4

u' 2 + u' 6x = 0

3

4

u'46 = 6x

True, this is a set of four simultaneous equations in four unknowns, but it

isn’t so difficult to solve. Why? Because the equations get progressively sim-

pler. Starting at the bottom, for example, you can see that after you cancel

the 6 on each side, you get this:

u'4(x) = x

You can then substitute that result into the previous equation:

u' 2 + u' 6x = 0

3

4

to get:

u'32 + 6x

2

= 0

So:

u'3(x) = –3x

2

You can find the others the same way. Here are u' (x), u' (x), u' (x), and u' (x):

1

2

3

4

u'1 = –x

u'2 = 3x

4

3

u'3 = –3x

u'4 = x

2





188

**Part II: Surveying Second and Higher Order Differential Equations**

Integrating these gives you:

-x

5

5

u1 =

3x

4

4

u2 =

u3 = –x

3

x

2

u4 =

2

Because:

y = u (x)y + u (x)y + u (x)y + . . . + u (x)y

n

p

1

1

2

2

3

3

n

the particular solution, yp, equals:

-x

5

5

3x

4

5

x

5

y p =

\- x

\+

5

\+

2

Or, to even out the denominators:

-4x

5

15x

5

20x

5

10x

5

5

y p =

\+

\-

\+

20

20

20

20

So:

-4x

20

5

15x

20

5

20x

20

5

10x

20

y p =

\+

\-

\+

which gives you the long-awaited result:

x

5

y p =

20

Now you know that the general solution of the nonhomogeneous equation is:

x

5

y = c + c x + c x

2

\+ c4 x

3

\+

h

1

2

3

20

And there you have it — you arrived at the general solution using the method

of variation of parameters. (**Note:** You can get the same result by simply inte-

grating the differential equation four times.)





**Par t III**

**The Power Stuf f:**

**Advanced**

**Techni ques**





In this part . . .

T

his part is where I help you pull out the power tools.

Here, you use series solutions, Laplace transforms,

and systems of differential equations. In addition, you

figure out how to use numerical methods to solve differen-

tial equations — this is the last-chance method, but it

rarely fails.





**Chapter 9**

**Getting Serious with Power**

**Series and Ordinary Points**

In This Chapter

` `Checking out the basics of power series

` `Trying the ratio test

` `Shifting the index value of a series

` `Surveying the Taylor Series

` `Putting your knowledge to use by solving second order equations

I

n Parts I and II of this book, I describe a variety of useful methods for solv-

ing first order, second order, and higher order differential equations. But

sometimes, those methods, as cool as they are, just won’t work. You have to

solve some differential equations (such as those involving what differential

equations experts call ordinary points) with a power series — that is, a sum-

mation of an infinite number of terms. I know this work sounds intimidating,

but believe it or not, it’s sometimes the easiest way to go. I show you what

you need to know in this chapter.

Perusing the Basics of Power Series

Power series are (often infinite) sums of terms. Here’s an example of a

common power series:

!

3

y =

an x

n

n = 0





192

**Part III: The Power Stuff: Advanced Techniques**

In this series, an and x are constants. The infinity sign on top of the sigma

n

indicates that n goes from 0 to infinity, and the sigma is the notation for a

summation. This series is shorthand for the following infinite expansion,

where the coefficients (a , a , a , and so on) are constants:

0

1

2

y = a + a x + a x

2

\+ a3x + . . .

3

0

1

2

The trouble with an infinite expansion, of course, is that it might diverge. That

is, it might become infinite as you add more and more terms. Power series

that become infinite aren’t of much help to anyone, so in this chapter, you

work only with series that stay finite — those that converge to a particular

value. A power series is said to converge for a particular x if this limit is finite:

!

m

lim

an x

n

n " 3

n = 0

If this limit is infinite, the series doesn’t converge. In fact, your series might

also converge absolutely. A series is said to converge absolutely if the summa-

tion of the absolute values of its terms converges (note the use of absolute

value notation):

!

3

y =

an x

n

n = 0

If a series converges absolutely, it also converges (of course).

Determining Whether a Power Series

Converges with the Ratio Test

So how do you know whether a series converges? That’s an easy question:

You use the ratio test. I discuss the basics of this test and provide a few

numerical examples in the following sections.

The fundamentals of the ratio test

The ratio test compares successive terms of a series to see whether the series

will converge. If the ratio of the (n + 1)th term to the nth term is less than 1 for

a fixed value of x, the series is said to converge for that x. The series diverges

if the ratio is greater than 1. For example, suppose you had this series:

\_

i

!

3

n

y =

a

x - x

n

0

n = 0





193

**Chapter 9: Getting Serious with Power Series and Ordinary Points**

The ratio of the (n + 1)th term to the nth term is:

\_

i

n + 1

a

x - x

x - x

n + 1

0

\_

i

n

a

n

0

To find out whether the series converges or diverges, take a look at the limit

of the ratio:

\_

\_

i

i

n + 1

a

x - x

n + 1

0

lim

n

n " 3

a

x

\-

x

n

0

This limit can also be written this way:

\_

\_

i

i

n + 1

a

x - x

a

n + 1

0

0

lim

= x - x0 lim n + 1 = x - x

L

0

n

a

n " 3

a

x

\-

x

n

n

So the series is said to converge absolutely for a particular x if |x – x | < 1/L.

0

The series diverges if |x – x | > 1/L. And if |x – x | = 1/L, the ratio test is

0

0

inconclusive and can’t be used.

In the large world of mathematics, there’s a number that’s either positive or

zero, called the radius of convergence, ρ, such that the series converges

absolutely if |x – x | < ρ and diverges if |x – x | > ρ. The region in which

0

0

|x – x | < ρ in which the series converges is called the interval of convergence.

0

Plugging in some numbers

The ratio test makes a lot more sense with numbers plugged into it. So in the

following sections, I walk you through several examples. That way you can

see for yourself just how useful this test is.

Example 1

Here’s an easy example to begin with. Where, if anywhere, does the following

series converge absolutely?

^

h ^

h

!

3

n

n

-1 x - 3

n = 0

The first step is to look at the limit of the ratio of the (n + 1)th term to the

nth term:

^

h

^

h

h

n + 1

n + 1

-1

^

x - 3

lim

h ^

n

n

n " 3

-1 x - 3





194

**Part III: The Power Stuff: Advanced Techniques**

This ratio works out to:

^

h

^

h

n + 1

n + 1

-1

^

x - 3

lim

= x - 3

h ^

h

n

n

n " 3

-1 x - 3

As you can see, the ratio is |x – 3|, and that ratio must be less than one. So

the range in which the series converges absolutely is |x – 3| < 1, or 2 < x < 4.

And the series diverges if x < 2 or x > 4.

Example 2

Ready for another example? Take a look at this series:

~~^~~

~~h~~

n

x + 1

!

3

4

n

n = 0

Determine the radius of convergence and the interval of convergence for this

series. To do so, first apply the ratio test, which gives you this limit:

~~^~~

~~h~~

n + 1

x + 1

x + 1

4

4

n

lim

~~^~~

~~h~~

\=

4

n + 1

x

1

n

n " 3

\+

As you can see, this series converges absolutely for |x + 1| / 4 < 1 or |x + 1|

< 4. So, in this case, the radius of convergence is 4, and the series converges for

–5 < x < 3, which is the interval of convergence. That wasn’t so difficult, was it?

Example 3

Here’s a final example showing how to use the ratio test. Take a look at this

series:

~~^~~

~~h~~

n

2x + 1

!

3

n

2

n = 0

As always, you use the ratio test, like so:

^

h

^

h

2

n + 1

n + 1

2x + 1

lim

< 1

^

h

n

2

n

n " 3

2x + 1

which equals:

^

h

2

n + 1

2x + 1 lim

< 1

n

2

n " 3





195

**Chapter 9: Getting Serious with Power Series and Ordinary Points**

The limit evaluates to 1 as n →

∞, so you get this:

|2x + 1|< 1

or:

|x +

1

⁄2|<

1⁄2

The radius of convergence is

2

1⁄ , and the interval of convergence is –1 < x < 0.

Shifting the Series Index

A method that can come in handy when working with differential equations is

called shifting the series index. For example, say that you have this series,

which starts at an index value of 3:

\_

i

!

3

n

a

x - x

0

n

n = 3

If you want this series to start at n = 0 instead of n = 3, you can simply shift

the index by 3, like this:

\_

i

!

3

n

\+ 3

a

x - x

0

n + 3

n = 0

Here’s another example. Say that you have this series:

^

h\_

i

!

3

n

\- 2

n + 2 x - x

0

n = 2

And say that you want to shift this so only powers of n were involved, not

n – 2. You can make this shift by replacing the dummy variable n with n + 2,

giving you:

^

h\_

i

!

3

n

n + 4 x - x

0

n = 0

Taking a Look at the Taylor Series

You can express continuous functions (those functions that don’t take discon-

tinuous jumps) as a series: the Taylor series. The Taylor series says that a

function can be expressed as an expansion around a point, x0, like this:

\_

i

f

(n)

x

0

n!

^ h

\_

i

!

3

f x =

x - x

0

n = 0





196

**Part III: The Power Stuff: Advanced Techniques**

In this series, n! is n factorial, or n · (n – 1) · (n – 2) . . . 3 · 2 · 1. If a function

has a Taylor series expansion at x = x0 with a nonzero radius of convergence

(see the earlier section “The fundamentals of the ratio test” for more about

this radius), the function is said to be analytic at x = x0.

A few types of Taylor series are especially important. Recognize this particu-

lar series?

!

3

x

n

= e

x

n!

n = 0

It’s your old friend e

x!

Here’s sin x:

~~^~~

~~h~~

n

-1

x

2n + 1

!

3

~~^~~

~~h~~

= sinx

2n + 1 !

n = 0

And don’t forget cos x:

^

h

n

-1

x

2n

!

3

^

h

= cosx

2n !

n = 0

Solving Second Order Differential

Equations with Power Series

This section is all about tackling second order differential equations (which

I introduce in Chapters 5 and 6) with power series. Say, for example, that you

have a linear homogeneous second order differential equation like this:

^ h d

2

y

2

^ h dy

dx

^ h

P x

\+ Q x

\+ R x y = 0

dx

Throughout the examples in this chapter, assume that P(x), Q(x), and R(x)

are all polynomials with no common factors. That’s the easiest type of prob-

lem to solve with power series. However, this method is also applicable when

P(x), Q(x), and R(x) are general analytic functions, such as sin x or cos x.

When working with power series, you divide the problems that fit the form

of the previous equation into two types — those where you don’t end up

dividing by zero and those where you do. In this chapter, I focus on ordinary

points. Ordinary points are points x where P(x ) isn’t equal to zero:

0

0

P(xo) ≠ 0





197

**Chapter 9: Getting Serious with Power Series and Ordinary Points**

Because P(x) is continuous, it follows that there’s an interval around x0 in

which P(x) isn’t 0. Because P(x) is a nonzero polynomial, you can divide by it

to get the following (but remember that P(x), Q(x), and R(x) have no common

factors):

d

2

y

2

^ h dy

dx

^ h

\+ p x

\+ q x y = 0

dx

where:

~~^ h~~

^ h Q x

p x =  ~~^ h~~

P x

and:

~~^ h~~

^ h R x

q x =  ~~^ h~~

P x

This equation is the type that you’re going to look at in the following sec-

tions, and you’re going to use ordinary points where nothing goofy happens

(like functions suddenly going to infinity). In addition, you can impose initial

conditions on this type of equation, such as:

y(0) = c1

and

y'(0) = c2

Points where functions go to infinity are called singular points (you can take a

look at those in Chapter 10). At singular points, P(x0) = 0, and at least one of

Q(x ) and R(x ), isn’t 0. So at least one of p(x) or q(x) becomes unbounded as

0

0

x → x . In this chapter, the functions are much better behaved.

0

So how do you solve second order differential equations using power series?

The most basic way is to simply substitute a power series like this one:

\_

i

!

3

n

a

x - x

0

n

n = 3

into a differential equation. Then you can try to solve for the coefficients

(which will be constants in this chapter). Because p(x) and q(x) are restricted

to be polynomials in this chapter, working with power series will be even

easier as you try to figure out the solution.





198

**Part III: The Power Stuff: Advanced Techniques**

When you already know the solution

Take a look at this second order differential equation:

d y

2

\+ y = 0

2

dx

In your eagle-eyed solving mode, you no doubt recognize this equation to be

a favorite among second order differential equations. You probably realize

that the solution is:

y = c y (x) + c y (x)

1

1

2 2

where:

y1(x) = sin(x)

and

y2(x) = cos(x)

So you’ve solved the problem, but hold off crowing just yet, because you’re

going to tackle this problem using a power series. This problem is usually the

first one you tackle, because you already know the solution, and you already

know what sin(x) and cos(x) look like in terms of power series (see the ear-

lier section “Taking a Look at the Taylor Series”). Here’s sin(x):

~~^~~

~~h~~

n

-1

x

2n + 1

!

3

~~^~~

~~h~~

= sinx

2n + 1 !

n = 0

And here’s cos x:

^

h

n

-1

x

2n

!

3

^

h

= cosx

2n !

n = 0

You’re ready to start solving your original differential equation using a power

series of the following form:

\_

i

!

3

n

a

x - x

0

n

n = 0





199

**Chapter 9: Getting Serious with Power Series and Ordinary Points**

Centering the power series on a selected point

When solving a differential equation using a power series, you first have to

select a point on which to center the power series (x0 in the previous series).

In the case of your original example equation, do what you’ll usually do

(unless there’s a compelling reason otherwise): Choose x0 to be 0. So your

series will be an expansion of the solution around the ordinary point 0:

!

3

an x

n

n = 0

Take a deep breath and then substitute this series into the original differen-

tial equation you’re trying to solve. To do so, you need to find the second

derivative of the series. Keep reading to find out what to do.

Finding the derivatives of a series

How do you find the second derivative of a series? As you may have guessed,

you work term by term. So you start off with a solution y of the following form:

!

3

y =

an x

n

n = 0

To find y", start by finding y'. Here’s what the terms of the series look like:

y = a + a x + a x + a3x + . . .

So after differentiating term by term you get

y' = a + 2a x + 3a x + . . .

2

3

0

1

2

2

1

2

3

The general nth term here is:

nanxn–1

So y' equals:

!

3

yl=

nan xn - 1

n = 1

Note that this series starts at n = 1, not n = 0 as the series for y does, because

you took the derivative of the series.

You can find y" by differentiating y' = a + 2a x + 3a x + . . . . You get this result

for y":

2

1

2

3

y" = 2a + 6a x + . . .

2

3





200

**Part III: The Power Stuff: Advanced Techniques**

The general term here is:

n(n – 1)anxn–2

So you can give y" as the following:

^

h

!

3

y'' = n n - 1 a xn - 2

n

n = 2

Substituting power series into the differential equation

The original differential equation looks like this:

d y

2

\+ y = 0

2

dx

So you can substitute the power series for y and y" to get this result:

^

h

!

3

!

3

n n - 1 a xn - 2

\+

an x = 0

n

n

n = 2

n = 0

which is your differential equation in series form.

Ensuring the same index value

To compare the series in the differential equation, make sure they start at the

same index value, n = 0. You can shift the first series here by replacing n with

n + 2 to get this result (I explain how to shift a series index in detail earlier in

this chapter):

^

h^

h

!

3

!

3

n + 2 n + 1 a

x

n

\+

an x = 0

n

n + 2

n = 0

n = 0

When you do some simplifying, you get:

8^

h^

h

B

!

3

n + 2 n + 1 a

x

n

\+ an x

n

= 0

n + 2

n = 0

You can factor out x as well:

n

8^

h^

h

B

!

3

n + 2 n + 1 a + a

n

x = 0

n + 2

n

n = 0

Believe it or not, you’re making progress here. Seriously!

Using the recurrence relation to find even coefficients

Because the series shown in the previous section equals 0, and because it

must work for all x, each term must equal 0. In other words, you get this:

(n + 2)(n + 1)an + 2 + an = 0





201

**Chapter 9: Getting Serious with Power Series and Ordinary Points**

which is called a recurrence relation. When you have a differential equation’s

recurrence relation, you practically have the solution in your pocket. Alright,

not really, but the recurrence relation goes a long way.

In this case, the recurrence relation says that, for n = 0:

(2)(1)a + a = 0

2

0

So:

-a

2 1

a = ~~^ h^~~

0

~~h~~

2

and for n = 2:

(4)(3)a + a = 0

4

2

So:

-a

4

a = ~~^ h^~~

2

3

~~h~~

4

Substituting a2 from the first equation into the second equation gives you this

result:

a

a = ~~^ h^ h^~~

0

~~h^ h~~

4

4

3 2 1

But (4)(3)(2)(1) = 4!, so you get:

a

4!

a4 =

0

Similarly, for a6:

(6)(5)a + a = 0

6

4

or:

-a

6

a = ~~^ h^~~

4

5

~~h~~

6

Substituting for a in terms of a gives you:

4

0

-a

5

a = ~~^ h^ h~~

0

~~^ h~~

6

6

4!

But (6)(5)(4!) = 6!, so you have:

-a

6!

a6 =

0





202

**Part III: The Power Stuff: Advanced Techniques**

To summarize, you have the following:

-a

2!

a2 =

a4 =

a6 =

0

a

4!

0

-a

6!

0

So now you can relate the even coefficients in general. If n = 2m (in which m

stands for a positive integer or zero):

~~^~~

~~h~~

m

-1

a

an = a =  ~~^~~

~~h~~

0

m = 0,1,2,3 . . .

2m

2m !

Because you set a0 based on the initial conditions for a given problem, you

can now find the even coefficients of the solution.

Using the recurrence relation to find odd coefficients

Now you can move on to the odd coefficients. Turn back to the recurrence

relation in the previous section for the solution:

(n + 2)(n + 1)an+2 + an = 0

You can see that for n = 1 you get:

(3)(2)a + a = 0

3

1

So:

-a

3 2

a = ~~^ h^~~

1

~~h~~

3

Taking a clue from the even coefficients in the previous section, you can see

that (3)(2) = 3!, so you get this:

-a1

3!

a3 =

Now, for n = 3 in the recurrence relation, you get:

(5)(4)a + a = 0

5

3

or:

-a

a = ~~^ h^~~

3

~~h~~

5

5

4





203

**Chapter 9: Getting Serious with Power Series and Ordinary Points**

Substituting a in terms of a into this equation gives you:

3

1

a

4

a = ~~^ h^~~

1

~~h^ h~~

5

5

3!

or:

a1

5!

a5 =

Substituting n = 5 into the recurrence relation gives you:

(7)(6)a + a = 0

7

5

or:

-a

7 6

a = ~~^ h^~~

5

~~h~~

7

And substituting a5 into this equation gives you:

-a

7 6 5!

a = ~~^ h^ h~~

1

~~^ h~~

7

which means that:

-a1

7!

a7 =

To sum up, the odd coefficients you have so far are:

-a1

a3 =

a5 =

a7 =

3!

a1

5!

-a1

7!

So now you can relate the odd coefficients of the solution this way in general,

if n = 2m + 1:

~~^~~

~~h~~

m

-1

a

an = a

= ~~^~~

~~h~~

1

m = 0,1,2, 3 . . .

2m + 1

2m + 1 !

Putting together the solution

Using the two equations for even and odd coefficients from the previous sec-

tions, you get the following general solution to your differential equation in

series terms:





204

**Part III: The Power Stuff: Advanced Techniques**

^

h

m

-1

x

2m

!

3

y = a

^

h

0

2m !

m = 0

~~^~~

~~h~~

m

-1

x

2m + 1

!

3

+a1

~~^~~

~~h~~

2m + 1 !

m = 0

That’s the solution to the differential equation in series terms. In this case,

the two series are recognizable as cos(x) and sin(x). Here’s sin(x):

~~^~~

~~h~~

n

-1

x

2n + 1

!

3

~~^~~

~~h~~

= sinx

2n + 1 !

n = 0

And here’s cos x:

^

h

n

-1

x

2n

!

3

^

h

= cosx

2n !

n = 0

So you can rewrite the solution as:

y = a cos(x) + a sin(x)

0

1

The terms a and a are arbitrary constants (just like c and c ), and they’re

0

1

0

1

set by matching the initial conditions.

When you don’t know the

solution beforehand

How do you use a power series to solve a differential equation for which you

don’t already know the solution? For instance, what if you have an equation

like this:

d

2

y

dy

dx

\- x

2

\+ 2y = 0

dx

Give it a try, using a power series like this:

!

3

y =

an x

n

n = 0

The following sections will guide you through the process.

Differentiating and substituting power series

into the differential equation

Differentiating the power series from the previous section gives you the fol-

lowing equation:

!

3

yl=

nan xn - 1

n = 1





205

**Chapter 9: Getting Serious with Power Series and Ordinary Points**

And differentiating this gives you:

^

h

!

3

y''= n n - 1 a xn - 2

n

n = 2

Now for the fun part: substitution! Substituting these equations into the origi-

nal differential equation gives you this result:

^

h

!

3

n n - 1 a xn - 2

n

n = 2

!

3

-x

nan xn - 1

n = 1

!

3

+2 an x = 0

n

n = 0

Using the recurrence relation to find coefficients

Now it’s time to equate powers of x on the left side of the equation to 0 on the

right side. Combining the coefficients for powers of x gives you this equation:

[2a + 2a ] + [6a + a ] x + 12a x

2

\+ [20a – a ] x . . .

3

2

0

3

1

4

5

3

\+ [(n + 2)(n + 1) an+2 – (n – 2)an ] x = 0

n

Note that every power of x must be 0 for the equation to work, so the last term

in the previous equation gives you the recurrence relation for this solution:

(n + 2)(n + 1) an+2 – (n – 2)an = 0

After some simplifying, you get:

~~^~~

~~h~~

n - 2 a

n + 2 n + 1

a

= ~~^~~

~~h^~~

n

~~h~~

n + 2

That doesn’t look so bad. This equation gives you these values for the coeffi-

cients when you plug in for n:

a2 = –a0

1

a3 = - a1

6

a4 = 0

1

20

a5 =

a

3

Substituting a in terms of a into the previous equation gives you the

3

1

following:

1

20

1

120

a5 =

a3 = -

a1





206

**Part III: The Power Stuff: Advanced Techniques**

Here’s a6:

2

30

a6 =

a

4

And substituting a4 into this equation gives you:

^ h

2

30

2

30

a6 =

a4 =

0 = 0

Keep going! Here’s a7:

3

42

a7 =

a

5

Or, to simplify:

1

a7 =

a

5

14

Substituting a in terms of a into this equation gives you:

5

1

~~^~~

~~h~~

1

-1

1

14

a7 =

a5 =

a1

14 120

So:

-1

1,680

a7 =

a1

How about a8? Here’s what you get:

4

56

a8 =

a

6

But you know that a6 = 0, so:

4

56

a8 =

a6 = 0

In fact, because a4 = 0, all subsequent even coefficients must be 0 by the

recurrence relation:

~~^~~

~~h~~

n - 2 a

n + 2 n + 1

a

= ~~^~~

~~h^~~

n

~~h~~

n + 2

Putting together the solution

Because all the even coefficients are 0 beyond a2, life is a little easier. You just

need to plug in the odd coefficients to get the entire solution to the differen-

tial equation. Here’s what you have for the solution:

y = a + a x - a x

2

0

1

0

1

6

1

120

1

a1 x

3

\-

a1 x

5

\-

a1 x + . . .

7

\-

1,680





207

**Chapter 9: Getting Serious with Power Series and Ordinary Points**

Grouping terms together by their coefficients gives you:

^

h

y = a 1 - x +

0

d

n

1

6

1

120

1

a1 x - a1 x

3

\-

a1 x

5

\-

a1 x + . . .

7

1,680

If you define the following:

y1 = (1 – x )

2

and:

d

n

1

1

120

1

y = x - a1 x

3

\-

a1 x

5

\-

a1 x + . . .

7

2

6

1,680

then you can see that the general solution is:

y = a y + a y

1 2

0

1

A famous problem: Airy’s equation

Before you wrap up the chapter, take a look at one more differential equation.

Get ready, though. It’s a famous one! In fact, it even has its own name —

Airy’s equation. Here’s what it looks like:

y" – xy = 0

To solve this equation, you can assume, as you do earlier in this chapter, that

the solution is of the following form:

!

3

y =

an x

n

n = 0

I explain the rest of the process in the following sections.

Differentiating and substituting power series

into the differential equation

As always, be sure to start off by differentiating the equation. Doing so

gives you:

!

3

yl=

nan xn - 1

n = 1

After differentiating this equation one more time, you get:

^

h

!

3

y''= n n - 1 a xn - 2

n

n = 2





208

**Part III: The Power Stuff: Advanced Techniques**

**Who was Airy?**

Sir George Biddell Airy (1801–1892) was an the Earth’s density, and came up with a solution

English mathematician and astronomer. In fact, of two-dimensional problems in mechanics.

he was the Astronomer Royal from 1835 to 1881. He’s also the one responsible for establishing

He was a man of many achievements. For Greenwich in Britain at the location of the prime

instance, he found planetary orbits, measured meridian.

Plugging the derivatives into the original differential equation gives you this

result:

^

h

!

3

!

3

n n - 1 a xn - 2 - x

an x = 0

n

n

n = 2

n = 0

With some simplifying you get:

^

h

!

3

!

an xn + 1 = 0

3

n n - 1 a xn - 2

\-

n

n = 2

n = 0

You can also write this equation as:

^

h

!

3

!

an xn + 1

3

n n - 1 a xn - 2

\-

n

n = 2

n = 0

Ensuring the same index value

Now you need to compare the coefficients of equal powers of x on the two

sides of this equation to find the recurrence relationship. To compare those

coefficients, it helps to make sure that the powers of x are the same in each

series.

Compare the coefficients in terms of x

n

. Shifting the series on the right (as I

show you earlier in this chapter) gives you this result:

^

h

!

3

!

3

n n - 1 a xn - 2

\-

a

x

n - 1

n

n

n = 2

n = 1

You can also shift the series on the left by substituting n + 2 for n, which

gives you:

^

h^

h

!

3

!

3

n + 2 n + 1 a

x

n

\=

a

x

n - 1

n

n + 2

n = 0

n = 1





209

**Chapter 9: Getting Serious with Power Series and Ordinary Points**

Using the recurrence relation to find coefficients

Now you’re ready to compare coefficients of powers of x. Note from the previ-

ous section that the series on the left starts at n = 0 and the series on the

right starts at n = 1; to compare the terms, it’s easier if the series starts at the

same value, say n = 1. You can break the first term out of the series on the left

to make the initial values of the indexes of the two series match, like this:

^

h^

h

!

3

!

3

2a2 +

n + 2 n + 1 a

x

n

\=

a

x

n - 1

n

n + 2

n = 1

n = 1

Note that the left side of this equation has a constant term, 2a2, but the right

side doesn’t. So right off the bat you know that a2 = 0.

Because the two sides of this equation must be equal in their terms, you get

the following for the recurrence relation:

(n + 2)(n + 1)an + 2 = an – 1 n = 1, 2, 3, 4 . . .

The coefficients are determined in steps of three because if you know an – 1

,

you can get an + 2. That is, when you have a , you know you can get a , a , a ,

0

3

6

9

and so on. And when you have a , you can get a , a , a , and so on. Because

1

4

7

10

you already know that a = 0, you know that a = 0, a = 0, a = 0, and so on.

2

5

8

11

Start with the sequence a , a , a , a , and so on. And remember that a and a

1

0

3

6

9

0

are set by the initial conditions. This means that you should start with a .

3

Here’s a in terms of a :

3

0

a

2 3

a = ~~^ h^~~

0

~~h~~

3

Here’s a :

6

a

5 6

a = ~~^ h^~~

3

~~h~~

6

Substituting a in terms of a into this equation gives you:

3

0

a

a = ~~^ h^ h^~~

0

~~h^ h~~

6

5 6 2 3

Here’s a9:

a

8 9

a = ~~^ h^~~

6

~~h~~

9

Substituting a6 into this equation gives you:

a

a = ~~^ h^ h^ h^~~

0

~~h^ h^ h~~

9

8 9 5 6 2 3





210

**Part III: The Power Stuff: Advanced Techniques**

So:

a

a = ~~^ h^ h^ h^ h~~

~~^~~

0

~~h^~~

~~h^~~

~~h^~~

~~h~~

n = 1, 2,3 . . .

3n

2 3 5 6 . . . 3n - 4 3n - 3 3n - 1 3n

Now look at the sequence a , a , a , a , and so on. Because a is set by the ini-

1

4

7

10

1

tial conditions, you should start with a :

4

a

3 4

a = ~~^ h^~~

1

~~h~~

4

Here’s a :

7

a

6 7

a = ~~^ h^~~

4

~~h~~

7

Substituting a in terms of a gives you:

4

1

a

a = ~~^ h^ h^~~

1

3

~~h^ h~~

7

6 7

4

And here’s a10:

a

a = ~~^ h^~~

7

~~h~~

10

9 10

Substituting a7 into this equation gives you:

a

a = ~~^ h^ h^ h~~

1

~~^ h^ h^ h~~

10

9 10 6 7 3 4

So you can say that in general:

a1

a

= ~~^ h^ h^ h^ h~~

~~^~~

~~h^~~

~~h^ h^~~

~~h~~

n = 1, 2,3 . . .

3n + 1

3

4

6 7 . . . 3n - 3 3n - 2 3n 3n + 1

Putting together the solution

After you get through with all the previous steps, you’ll know that you can

write the general solution to Airy’s equation like this:

R

V

S

x

3

x

6

x

3n

W

y = a 1 +

\+

\+ . . . ~~^ h^ h^ h^ h~~

~~^~~

x

~~h^~~

~~h^~~

~~h^ h~~ +

0

S

T

6

180

2 3 5 6 . . . 3n - 4 3n - 3 3n - 1 3n W

X

R

V

S

x

4

x

7

3n + 1

W

a x +

\+

\+ . . . ~~^ h^ h^ h^ h~~

~~^~~

~~h^~~

~~h^ h^~~

~~h~~

1

S

T

12 504

3

4

6 7 . . . 3n - 3 3n - 2 3n 3n + 1 W

X

You can write this in the following shorter form:

R

V

S

!

3

x

3n

W

y = a 1 +

~~^ h^ h^ h^ h~~

~~^~~

~~h^~~

~~h^~~

~~h^ h~~ +

o

S

T

2 3 5 6 . . . 3n - 4 3n - 3 3n - 1 3n W

n = 0

X

R

V

S!

3

x

3n + 1

W

a1

~~^ h^ h^ h^ h~~

~~^~~

~~h^~~

~~h^ h^~~

~~h~~

S

T

3

4

6 7 . . . 3n - 3 3n - 2 3n 3n + 1 W

n = 0

X





211

**Chapter 9: Getting Serious with Power Series and Ordinary Points**

So if you write:

!

3

x

3n

y1 = 1 +

~~^ h^ h^ h^ h~~

~~^~~

~~h^~~

~~h^~~

~~h^~~

~~h~~

2 3 5 6 . . . 3n - 4 3n - 3 3n - 1 3n

n = 0

and:

!

3

x

3n + 1

y2 =

~~^ h^ h^ h^ h~~

~~^~~

~~h^~~

~~h^ h^~~

~~h~~

3

4

6 7 . . . 3n - 3 3n - 2 3n 3n + 1

n = 0

you can see that the general solution to Airy’s equation is:

y = a y + a y

1 2

0

1





212

**Part III: The Power Stuff: Advanced Techniques**





**Chapter 10**

**Powering through Singular Points**

In This Chapter

` `Perusing singular points

` `Examining Euler equations

` `Surveying series solutions near regular singular points

I

n Chapter 9, I briefly introduce you to the concept of singular points, but

this chapter is where the real action is. I cover a number of topics, includ-

ing working with Euler equations, handling power series solutions near singu-

lar points, and dealing with a mix of the two — series solutions to Euler

equations near singular points.

Pointing Out the Basics of

Singular Points

In this chapter, you work with second order homogeneous differential equa-

tions of the following form:

^ h d

2

y

2

^ h dy

dx

^ h

P x

\+ Q x

\+ R x y = 0

dx

where P(x), Q(x), and R(x) have no common factors.

You can also divide each term in the equation by P(x) to get:

d

2

y

2

^ h dy

dx

^ h

\+ p x

\+ q x y = 0

dx

where p(x) = Q(x)/P(x) and q(x) = R(x)/P(x).





214

**Part III: The Power Stuff: Advanced Techniques**

So far, so good, right? Not so fast! Now I’m going to throw singular points into

the mix. Points where functions go to infinity are called singular points. At sin-

gular points, P(x ) = 0, and at least one of Q(x ) and R(x ) isn’t zero. So at least

0

0

0

one of p(x) or q(x) becomes unbounded (goes to infinity) as x → x .

0

In the following sections, I introduce you to the fundamentals of singular

points, including how to find them, how they behave, and the difference

between regular and irregular points.

Finding singular points

Time to get your feet wet! What are the singular points of the following differ-

ential equation?

\_4 - x

i d

2

y

\+ x

2

dy

dx

\+ 1 + x y = 0

^

h

2

3

dx

The singular points are where P(x) = 0, so you have:

(4 – x ) = 0

2

Simply use your excellent algebra skills to solve this equation, and you find

that the singular points are x = ±2.

As another example, determine the singular points of this differential equation:

d

2

y

2

\+ \_8 - x

i dy

^

h

x

2

3

\+ 1 - 9x y = 0

dx

dx

Here, P(x) is simply x

2

. So the singular point is x = 0.

The behavior of singular points

When studied closely, singular points look like they have the potential to

become unruly. After all, singular points are where a solution may go to infin-

ity or change rapidly in magnitude. If you’re asking whether you can simply

ignore them, the answer is no.

Why? Because solutions to differential equations with singular points vary so

much near those singular points that you need to take special care. In fact,

it’s often the case that the solution to a differential equation is the most inter-

esting around its singular points. That’s where the most interesting physics

goes on. For example, an electrical circuit may reach resonance there. And

reaching resonance is often the whole point of amplifying circuits, so ignoring

the behavior at singular points just wouldn’t do.





215

**Chapter 10: Powering through Singular Points**

For example, take a look at this second order homogeneous equation:

d y

dx

2

x

2

\- 2y = 0

2

By using your unbeatable differential equation solving skills, you can tell that

the two independent solutions to this differential equation are:

y1 = x

2

and

y2 = x–1

The y1 solution is fine — its behavior is well-defined around x = 0, for exam-

ple. In fact, the y solution is still analytic (meaning that it has a working

1

Taylor expansion; see Chapter 9 for more about Taylor series) as x → 0, even

though the differential equation looks like this if you divide by P(x):

d

2

y

2

2y

x

\-

= 0

2

dx

This equation looks unbounded as x → 0, but everything is okay if you substi-

tute y1 = x here.

2

The situation is different with y2 = x–1 (also written as 1/x), however. This solu-

tion isn’t analytic at x = 0 (in other words, it has no Taylor expansion at x = 0).

So you can’t use the methods of Chapter 9 to solve this differential equation.

As you find out in the next section (and throughout this chapter), different

kinds of singular points exist — and all of them have varying levels of man-

ageability. It is often the case that you can’t use the Taylor expansion used in

Chapter 9 to solve differential equations with singular points, because those

expansions become unbounded at the singular points. Because of this, you

have to use more general expansions from time to time.

Regular versus irregular singular points

An important concept when it comes to singular points is severity. A singular

point’s severity is an indication of how strong the singular point is — how

strongly it tends toward infinity. The severity of a singular point has a lot to

do with how you handle the solution; does the solution, for instance, include

terms like 1/x, or does it include terms like 1/x

8

? (It turns out that you can

handle 1/x in most cases, but 1/x ? Good luck with that one.) The idea is to

8

extend the techniques of Chapter 9, which allow you to use series expansions

near ordinary points, to help you use series expansions near singular points —

if they’re well-behaved enough.





216

**Part III: The Power Stuff: Advanced Techniques**

A well-behaved singular point is called a regular singular point. Regular singu-

lar points are well-behaved enough that you can handle them using the tech-

niques in this chapter.

What’s the definition of a regular singular point? They’re defined in terms of

the ratio Q(x)/P(x) and R(x)/P(x), where P(x), Q(x), R(x) are the polynomial

coefficients in the differential equation that you’re trying to solve:

^ h d

2

y

2

^ h dy

dx

^ h

P x

\+ Q x

\+ R x y = 0

dx

In order for x0 to be a regular singular point of this equation, these two rela-

tions have to be true:

^~~ h

\_

i Q x

lim x - x

^~~ h remains finite

0

0

P x

x " x

0

and

^~~ h

\_

i R x

2

lim x - x

^~~ h remains finite

x " x

0

P x

Another way of thinking about this is to say that x is a regular singular point

0

if (x – x )Q(x)/P(x) and (x – x )

2

Q(x)/P(x) have Taylor expansions (that is,

0

0

they’re analytic) around x .

0

As you may have guessed, if singular points aren’t regular, they’re irregular.

And irregular singular points are much more — shall I say interesting? — to

handle.

Take a look at some example differential equations to see if their singular

points are regular or irregular.

Example 1

Start with this differential equation (which you just saw in the previous

section):

d

2

y

2

2y

x

\-

= 0

2

dx

The solutions for this equation are:

y1 = x

2

and

y2 = x–1





217

**Chapter 10: Powering through Singular Points**

There’s a singular point at x = 0 because y2 becomes infinite. Now take some

time to evaluate the relations:

^~~ h

\_

i Q x

lim x - x

^~~ h remains finite

0

P x

x " x

0

and

^~~ h

\_

i R x

2

lim x - x

^~~ h remains finite

0

P x

x " x

0

You test the first relation by plugging in some numbers, like so:

^ h

0

1

lim x

= 0

x " 0

And because 0 is finite, you’re okay so far. Now for the second relation,

R(x) = –2/x

2

and P(x) = 1:

^ h

-2

2

lim x

= -2

2

x

x " 0

Because –2 is finite, x = 0 is a regular singular point of your original differen-

tial equation. Cool, huh?

Example 2

Now try this one:

^

h

d

2

y

dy

dx

^

h

2

x - 4

x

\+ 4x

2

\+ x - 4 y = 0

dx

What are the singular points in this equation? Are they regular? Here, P(x) =

(x – 4) x, and that’s 0 at x = 0 and x = 4. So x = 0 and x = 4 are your singular

2

points. Start with the x = 0 singular point first; here’s what the first relation

has to say about it:

^ h

4x

x - 4

1

4

lim x

\=

^

h

2

x " 0

x

Because ⁄ is finite, you’re good to go. Now for the second relation:

4

1

^

h

^ h

x - 4

2

lim x

= 0

^

h

2

x " 0

x - 4

x

Zero is finite, so the x = 0 singular point is a regular singular point.

So far, so good. Now, however, you have to try the other singular point, x = 4.

The first relation gives you:

^

h

4x

x - 4

4

lim x - 4

" ^

h

is NOT FINITE

^

h

2

x - 4

x " 4

x





218

**Part III: The Power Stuff: Advanced Techniques**

Whoops — this relation is unbounded as x → 4, so x = 4 isn’t a regular singu-

lar point. In other words, it’s an irregular singular point.

Example 3

Try your hand at this equation, which is a famous one, the Legendre equation

(see the nearby sidebar “Discovering the legacy of Legendre” for more on the

man who unearthed this famous equation):

\_1 - x

i d

2

y

\- 2x

2

dy

dx

\+ α α + 1 y = 0

^

h

2

dx

where α is a constant. Because P(x) = (1 – x

Look at the x = 1 point first. From the first relation and because (1 + x)(1 – x) =

(1 – x ):

2

), the singular points are x = ±1.

2

^

h

2x

1 - x

-2x

1 + x

lim x - 1

\_

i = ^

h = -1

2

x " 1

As you know, –1 is, of course, finite.

Now for the second relation:

^

h

^

h α α + 1

2

lim x - 1

\_

i

1 - x

2

x " 1

This equation can be broken down to:

^

h

^

h

α α + 1

1 - x 1 + x

2

^

h^

h

lim x - 1

x " 1

which is:

^

h

^

h α α + 1

lim - x - 1

^

h~~  = 0

1 + x

x " 1

Because 0 is finite, x = 1 is a regular singular point.

Now try the other singular point, x = –1. Here’s what the first relation gives you:

^

h

2x

1 - x

2x

1 - x

lim x + 1

\_

i = ^

h = -1

2

x " - 1

As you know, –1 is finite. Now check out the second relation, which gives you:

^

h

^

h α α + 1

2

lim x + 1

\_

i

1 - x

2

x " - 1





219

**Chapter 10: Powering through Singular Points**

**Discovering the legacy of Legendre**

Adrien-Marie Legendre (1752–1833) was the because he had to. He started publishing works

French mathematician who discovered the ever- on physics — specifically on the motion of

important Legendre equation. His work was done cannonballs — but then moved on to math. In

in the fields of statistics, abstract algebra, math- 1782, he became a member of the French

ematical analysis, and number theory. He was Academy of Sciences. He even got a crater on

born to a rich family, and studied physics in Paris. the moon named after him. How many mathe-

Then he took up teaching at a military academy. maticians can say that?

He took on this job because he enjoyed it, not

You can also write this as:

^

h

^

h

α α + 1

2

^

h^

h

lim x + 1

1 - x 1 + x

x " - 1

or:

^

h

^

h α α + 1

lim x + 1

^

h

1 - x

x " - 1

The limit is:

^

h

^

h α α + 1

lim x + 1

^

h~~  = 0

1 - x

x " - 1

Because 0 is finite, x = –1 is also a regular singular point.

Exploring Exciting Euler Equations

A good way to understand how to handle regular singular points is to see

how one of the most famous differential equations — which has a regular sin-

gular point — is handled. The equation I’m talking about is Euler’s equation:

d

2

y

dy

dx

x

2

\+ α x

2

\+ β y = 0

dx





220

**Part III: The Power Stuff: Advanced Techniques**

Here, α and β are real constants. If you assume that the solution to this equa-

tion has the following form:

y = x

(where r is a constant), substituting the solution into the equation gives you:

[r(r – 1) + αr + β] x = 0

gives you:

r

r

Dividing both sides by x

r(r – 1) + αr + β = 0

or:

r

r

2

– r + αr + β = 0

So:

r

2

\+ (α – 1) r + β = 0

The roots, r and r , of this equation are:

1

2

^

h

^

h

\- α - 1 ! α - 1

2

\- 4β

r ,r =

1

2

2

Because you’re considering the general Euler’s equation, you don’t know

what α and β are, so you have to consider three cases for these roots:

` `r and r are real and distinct

1

2

` `r and r are real and equal

1

2

` `r and r are complex conjugates

1

2

In the following section, you consider each of these cases separately.

Euler was a pretty busy guy; he also came up with Euler’s method, which is a

simple numerical method of solving differential equations. Flip to Chapter 4

for details.

Real and distinct roots

If the roots of r + (α – 1) r + β = 0 are real and distinct, r ≠ r . The general

1 2

2

solution to Euler’s equation is:

y = c1 xr1 + c2 xr2





221

**Chapter 10: Powering through Singular Points**

To see how to come up with this solution, try solving this differential equation:

d

2

y

dy

dx

4x

2

\+ 6x

2

\- 2y = 0

dx

This equation has a regular singular point at x = 0, and you can assume that

the solution is of the following form:

y = x

Substituting this solution into the original equation gives you:

[4r (r – 1) + 6r – 2] x = 0

r

r

or:

[4r (r – 1) + 6r – 2] = 0

After some simplifying, the equation looks like this:

4r + 2r – 2 = 0

2

Factoring gives you:

2(2r – 1)(r + 1) = 0

So the roots are:

r1 = ⁄

2

1

and

r2 = –1

This means that the general solution to the original equation is

y = c1 x

1

⁄2 + c2 x–1

Note how this technique is similar to the one in the situation where the differ-

ential equation you’re dealing with has constant coefficients (as in Chapter 5)

and you assume a solution of the form y = erx. Here, there are powers of x

x already appearing in the coefficients of the differential equation, so you

assume that the solution is of the form y = x

2

and

r.





222

**Part III: The Power Stuff: Advanced Techniques**

Real and equal roots

Sometimes the two roots of r

look at this differential equation:

2

\+ (α – 1) r + β = 0 are equal. For example, take a

d

2

y

dy

dx

x

2

\+ 3x

2

\+ 2y = 0

dx

Substituting y = x

r

into this equation gives you:

[r (r – 1) + 3 r + 2] x

r

= 0

or:

r (r – 1) + 3 r + 2 = 0

After some simplifying, this becomes:

\+ 2 r + 2 = 0

r

2

which in turn becomes:

(r + 1)(r + 1) = 0

So the roots here are –1 and –1. How do you handle a case like this? Clearly

y1 = x–1, but what’s y2?

As you find out in Chapter 5, when you have a second order differential equa-

tion with constant coefficients, you try a solution of the following form:

y = erx

After you substitute this solution into the differential equation, you may find

that the two roots, r and r , are equal. In that case, you end up with these two

1

2

solutions:

y1 = er1

x

and:

y2 = x er1

x

Is there an analog for Euler equations? You bet. If r = r , then:

1

2

y1 = xr1

And in that case:

^ h

y = ln x xr1

2





223

**Chapter 10: Powering through Singular Points**

So the general solution of Euler equations with equal roots of the characteris-

tic equation is:

^ h

y = c1 xr1 + c ln x xr1

2

And that’s it. The solution to your original equation is:

y = c1 x–1 + c2 ln(x) x–1

Complex roots

In this section, you take a look at the case where the roots of a Euler equation

are complex and of the form a ± ib. In this case, a and b are constants, and i is

the square root of –1. Your solutions look like this:

y1 = xa+ib

and:

y2 = xa–ib

To deal with complex roots, you have to get into some trigonometry. Start by

noting that this is true:

x

r

= erln(x)

And note that as long as x > 0:

a+ib = e(a+ib)ln(x)

and this equals:

(a+ib)ln(x) = ealn(x)

which is:

x

x > 0

x > 0

x > 0

e

e

ibln(x)

e

alnx

e

iblnx = x

a iblnx

e

Whew! At this point, you can use the following relation:

mx = cos mx + i sin mx x > 0

Here, m is a constant. So after using the relation, your equation becomes:

[cos(bln(x)) + i sin(bln(x))] x > 0

e

x

aeiblnx = x

a





224

**Part III: The Power Stuff: Advanced Techniques**

Absorbing the pesky factor of i into c2 gives you the general solution, which

looks like this:

y = c1 xa

cos(bln(x)) + c2 x

a

sin(bln(x))

x > 0

Now try putting all this trig to work with an example. Try solving this Euler

equation, where all the coefficients are 1:

d

2

y

dy

dx

x

2

\+ x

2

\+ y = 0

dx

Trying a solution of the following form:

y = x

gives you:

[r (r – 1) + r + 1] x

r

r

= 0

or:

r (r – 1) + r + 1 = 0

After some simplifying, this equation becomes:

\+ 1 = 0

r

2

Uh oh! The roots here are complex: ±i. This means that a = 0 and b = 1, so

you get:

y = c cos(ln(x)) + c sin(ln(x))

x > 0

1

2

This equation is only valid for x > 0. Let me guess: You’re wondering whether

you can do anything for x < 0. Well, actually, it can be shown that this is the

way to handle the regions x < 0 and x > 0 (not x = 0):

y = c cos(ln |x|) + c sin(ln |x|)

x > 0

1

2

Putting it all together with a theorem

The following formal theorem summarizes the previous sections:

**If you have a Euler equation:**

**d**

**2**

**y**

**dy**

**dx**

**x**

**2**

\+ α **x**

**2**

\+ β **y** = **0**

**dx**





225

**Chapter 10: Powering through Singular Points**

**where** α **and** β **are real constants, then the solution is of this fundamental**

**form in any interval that doesn’t include the origin:**

**y = x**

**r**

**where you can find r by solving the characteristic equation:**

**r (r + 1) +** α **r +** β **= 0**

**If the roots are real and distinct, then the general solution is of this form:**

**y** = **c1 x r1** + **c2 x**

**r2**

**If the roots are real and equal, then the general solution is of this form:**

**y** = **c1 x r1** + **c2 ln x x**

**r1**

**And if the roots are complex, a** ± **ib, then the general solution is of this**

**form:**

**y = c1 x**

**a**

**cos(b ln x ) + c2**

**a**

**x sin(b ln x )**

Figuring Series Solutions Near

Regular Singular Points

In the following sections, you take a look at how to find the series solution

near regular singular points. Have fun!

Identifying the general solution

Take a look at the general second order differential equation that you want to

solve:

^ h d

2

y

2

^ h dy

dx

^ h

P x

\+ Q x

\+ R x y = 0

dx

You can assume that the solution has a regular singular point. For conve-

nience, you can also assume that the singular point is at x = 0. (If the singular

0

point isn’t at zero, you can make a substitution of variables, x → x – c, where

c is a constant, so that it is).





226

**Part III: The Power Stuff: Advanced Techniques**

Divide this equation by P(x) to get:

d

2

y

2

^ h dy

dx

^ h

\+ p x

\+ q x y = 0

dx

where:

^~~ h

^ h Q x

p x =  ^~~ h

P x

and:

^~~ h

^ h R x

q x =  ^~~ h

P x

From here, with a few tricks up your sleeve, you can decipher a general solu-

tion near singular points, as you find out in the following sections.

Seeing the series of products

Because x = 0 is a regular singular point, it follows that x p(x) and x q(x) both

2

have finite limits as x → 0. This means that both products have convergent

series of the following form (see Chapter 9 for an introduction to power series):

^ h

!

3

x p x =

pn x

n

n = 0

and:

^ h

!

3

x

2

q x =

qn x

n

n = 0

Both series converge for x < a for some interval, a > 0.

Substituting the series into the differential equation

Now multiply the original differential equation by x to get the following

2

equation:

d

2

y

2

8

^ hB dy

dx

^ h

x

2

\+ x x p x

\+ x

2

q x y = 0

dx

Substituting the two series from the previous section into this equation gives

you this result:

d y

2

x

2

dx

2

7

A dy

+x p + p x + p x

2

\+ . . . + pn x

n

\+ . . .

0

1

2

dx

7

A

\+ q + q x + q x

2

\+ . . . + qn x

n

\+ . . . y = 0

0

1

2





227

**Chapter 10: Powering through Singular Points**

Recognizing a Euler equation

The previous equation looks a little difficult. But don’t worry. Here’s what to

do: Try tackling problems of this kind by assuming that all coefficients except

p and q are equal to 0. Doing so in the case of the example gives you:

0

0

d

2

y

2

dy

dx

x

2

\+ x p

0

\+ q0 y = 0

dx

Does this equation look familiar? It should — it’s a Euler equation, like the

ones I discuss earlier in this chapter. The fact that this looks like a Euler

equation helps you see how to tackle the more general differential equation

with a regular singular point.

Here’s the key: If not all the coefficients (besides p and q ) are equal to 0, you

0

0

have to assume that the solution is of this Euler-like form:

!

3

y = x

r

qn x

n

n = 0

This series is the same as this one:

!

3

y =

qn xn + r

n = 0

The fundamental solution is a Euler solution, with the power series added in

to take care of any non-Euler coefficients. In other words, even if your differ-

ential equation has a regular singular point, you can sometimes find a valid

solution of the form of this power series in the region of the singular point.

The basics of solving equations

near singular points

Before I get to a numerical example, I want to walk you through the steps of

solving an equation near singular points. The following sections show you

everything you need to know. Fasten your seat belt!

Determining the solution’s form and differentiating

Say you start with a differential equation of the following form:

d

2

y

2

8

^ hB dy

dx

8

^ hB

x

2

\- x x p x

\+ x

2

q x y = 0

dx





228

**Part III: The Power Stuff: Advanced Techniques**

where:

^ h

!

3

x p x =

pn x

n

n = 0

and:

^ h

!

3

x

2

q x =

qn x

n

n = 0

Here’s the Euler equation that matches the differential equation:

d

2

y

dy

dx

x

2

\- p0 x

2

\+ q0 y = 0

dx

As you find out in the earlier section “Recognizing a Euler equation,” you can

assume that a solution to this equation is of the following form:

!

3

y = x

r

qn x

n

n = 0

This solution is the same as the following:

!

3

y =

qn xn + r

n = 0

Differentiating this series gives you:

dy

dx

^

h

!

3

\=

a r + n xn + r - 1

n

n = 0

And after differentiating again you get:

d

2

y

2

^

h^

h

!

n

3

\=

a r + n r + n - 1 xn + r - 2

dx

n = 0

Substituting series into the original equation

Now it’s time for the heavy-lifting. Substituting the previous three series

into the original differential equation and collecting terms gives you this form

of the differential equation:

^ h

= ^

h

n - 1

8^

h

BG

!

3

!

a f r x

r

\+

f n + r a +

a

m + r p

\+ q

n - m

xn + r = 0

0

n

m

n - m

n = 1

m = 0

where:

f(r) = r(r + 1) + p0r + q0

and

^ h

p = lim x p x

0

x " 0





229

**Chapter 10: Powering through Singular Points**

and

^ h

q = lim x

2

q x

0

x " 0

Wow. What do you do next? Read on to find out.

Finding the indicial equation

You know that in order for the terms on the left side of the previous equation

to equal zero, every power of x must equal zero. In particular, note that this

means:

a0 f(r) x = 0

r

Because a0 and x

f(r) = 0

r

aren’t zero, you know that:

When this equation is expanded, you get the following:

r(r + 1) + p r + q = 0

0

0

This equation is the indicial equation for the original differential equation;

in other words, it’s the same characteristic equation for the roots you’d get if

you solved the differential equation’s corresponding Euler equation.

Working with the roots

You use the two roots of the indicial equation to find the two solutions to the

differential equation, y and y .

1

2

Next, you can set the coefficients of xn+r to zero in the previous section’s

equation. Doing so gives you this relation:

^

h

n

\- 1

8^

h

B

!

f n + r a +

a

m + r p

\+ q

= 0 n $ 1

n

m

n - m

n - m

m = 0

which gives you the following recurrence relation (see Chapter 9 for details):

n

!

\- 1

8^

h

B

\-

a

m + r p

\+ q

n - m n - m

m

an =  m = 0

^

h

n $ 1

f n + r

You can then find the coefficients, an, from this recurrence relation.

There are two solutions to the original differential equation, each of which

corresponds to the two roots, r and r . Here’s the first solution, y :

1

2

1

<

\_ i

F

!

3

y1 = xr1 1 +

a

r

x

n

x ! 0

n

1

n = 1





230

**Part III: The Power Stuff: Advanced Techniques**

So how do you go about finding the second solution, y2? Well, how you do

that depends on the two roots of the indicial equation. (See the later section

“Taking a closer look at indicial equations” for details.)

A numerical example of solving an

equation near singular points

The stuff in the previous sections can be tough, so take a look at a numerical

example to make it all clear in your mind.

Uncovering the solution’s form

To start, take a look at this differential equation:

d

2

y

dy

dx

^

h

2x

2

\- x

2

\+ 1 + x y = 0

dx

This equation has a regular singular point at x = 0. How would you find a solu-

tion to this equation? Well, after you give it some thought, it looks a lot like

this Euler equation:

d

2

y

dy

dx

2x

2

\- x

2

\+ y = 0

dx

So you can try a solution of the following form:

!

3

y =

an xn + r

n = 0

Differentiating this solution gives you:

dy

dx

^

h

!

3

\=

a r + n xn + r - 1

n

n = 0

After differentiating again, you get:

d

2

y

2

^

h^

h

!

n

3

\=

a r + n r + n - 1 xn + r - 2

dx

n = 0

Using series as substitutes in the original equation

Substituting the previous three series into your original differential equation

gives you this impressive result:





231

**Chapter 10: Powering through Singular Points**

^

h^

h

h

!

3

2

a r + n r + n - 1 xn + r - 2

n

n = 0

^

!

3

\-

\+

\+

a r + n xn + r

n

n = 0

!

3

an xn + r

n = 0

!

3

an xn + r + 1 = 0

n = 0

This equation can also be written as:

8

^

h

B

a 2r r - 1 - r + 1 x

r

0

b8 ^

h^

h

^

h

B

l

!

3

\+

2 r + n r + n - 1 - r + n + 1 a + a

x

r + n = 0

n

n - 1

n = 1

Wow. Can you decipher this? Keep reading to find out!

Unearthing the indicial equation

Because the coefficients of all powers of x in the previous equation must be

zero for the whole equation to be zero, you can set the coefficient of x to

r

be zero, like so:

2r(r – 1) – r + 1 = 0

Multiplying this out gives you the following equation:

2r

2

– 3r + 1 = 0

This turns out to be the same characteristic equation you would have

received from the Euler equation that’s closest to the equation that you’re

trying to solve, namely:

d

2

y

dy

dx

2x

2

\- x

2

\+ y = 0

dx

You can factor 2r

2

– 3r + 1 = 0 into the following indicial equation:

(r – 1)(2r – 1) = 0

As you can see, the roots of this equation are:

r1 = 1

and

r2 = ⁄

2

1





232

**Part III: The Power Stuff: Advanced Techniques**

These two roots are given a big name: exponents at the singularity. They’re

given this name because they describe the behavior of the solution near the

singular point, x = 0. You put these roots to work in the next two sections.

Getting back to the original differential equation in impressive series form,

you now set the coefficients of xr+n equal to zero to get this:

[2(r + n)(r + n – 1) – (r + n) + 1]an + an–1 = 0

You can rewrite this equation as:

-a

an =

n - 1

^

h

^

h

2

2 r + n - 3 r + n + 1

Or, with some regrouping you get:

-a

a =  ^

h

n -

^

1

h

8

B8

B

n

r

n

1 2 r

n

\-

1

\+

\-

\+

For each root of the initial equation, r and r , you can use this recurrence

1

2

relation to find the coefficients a . Keep reading to find out what to do next!

n

Applying the first root

Plugging the first root, r1 = 1, into the recurrence relation gives you:

-a

n 2n + 1

an =

^

n - 1

h

So when you plug in 1 for a, you get this:

-a

3

a1 =

0

And when you plug 2 in for a you get this:

-a

a = ^~~ h^

1

h

2

5 2

Substituting a1 into this equation gives you:

-a

5 2 3

a = ^~~ h^~~ h

0

^~~ h

2

Now here’s the next coefficient:

-a

a = ^~~ h^

2

h

3

7

3

Substituting a2 into this equation gives you:

-a

a = ^~~ h^~~ h^~~ h

0

^~~ h^~~ h

3

7 3 5 2 3





233

**Chapter 10: Powering through Singular Points**

You can rewrite this equation as:

-a

a = ^~~ h^~~ h^~~ h^

0

h^~~ h^~~ h

3

3 5 7 1 2 3

In general, you get this relation:

^

h

n

-1 a

a =  ^~~ h^~~ h

^

0

h

8

B

n

3 5 . . . 2n

1

n!

\+

which means that y1 of the general solution is:

R

V

^

h

S

-1

n

x

n

W

!

3

y = x S1 +

^~~ h^~~ h

^

h

W x > 0

8

B

1

3 5 . . . 2n

1

n!

S

\+

W

X

n = 1

T

Here’s the million-dollar question: Does this series converge? As you may

expect, you can use the ratio test to find out (see Chapter 9 for details):

a

x

n + 1

an x

n + 1

lim

n

n " 3

which works out to be:

x

lim ^

h^

h

2n + 3 n + 1

n " 3

And as n →

∞, this limit → 0, so the series expansion is valid for all values of x.

Plugging in the second root

Now how about r2 = ⁄ ? To work with the second root, turn back to the follow-

2

1

ing recurrence relation:

-a

a =  ^

h

n -

^

1

h

8

B8

B

n

r

n

1 2 r

n

\-

1

\+

\-

\+

Plugging in r =

1⁄

2

gives you:

-a

an =

n - 1

;

E6

@

1

n -

2n

2

which equals:

-a

2n - 1 n

a = ^

n -

h

1

n





234

**Part III: The Power Stuff: Advanced Techniques**

As you may know, a0 is arbitrary and is set to match the initial conditions of

the problem. So you start by finding a1:

-a

1 1

a = ^~~ h^

0

h

1

So:

a1 = –a0

Now for a2:

-a

3 2

a = ^~~ h^

1

h

2

Substituting a1 into this equation gives you the following result:

a

a = ^~~ h^~~ h^

0

h^~~ h

2

1 3 1 2

And for a3:

-a

3 5

a = ^~~ h^

2

h

3

Substituting a2 into this equation gives you:

-a

a = ^~~ h^~~ h^~~ h^

0

h^~~ h^~~ h

3

1 2 3 1 3 5

And for a4:

-a

4 7

a = ^~~ h^

3

h

4

Substituting a3 into this equation gives you:

-a

a = ^~~ h^~~ h^~~ h^~~ h^

0

h^~~ h^~~ h^~~ h

4

1 2 3 4 1 3 5 7

So, in general:

^

h

n

-1 a

an =  ^~~ h^~~ h^~~ h^~~ h

0

^

h

n! 1 3 5 7 . . . 2n - 1

You can give the second solution, y2, like this:

R

V

^

h

S

-1

n

x

n

W

!

3

y2 = x1/2 S1 +

^~~ h^~~ h^~~ h

^

h

W

x > 0

8

B

1 3 5 . . . 2n 1 n!

\-

S

W

X

n = 1

T





235

**Chapter 10: Powering through Singular Points**

How about the radius of convergence? To find out, you can use the ratio test

as you did in the previous section:

a

x

n + 1

an x

n + 1

lim

n

n " 3

After some simplification, this equation can be rewritten as:

x

lim ^

h

2n - 1 n

n " 3

Congratulations! Now you know that the series converges for all x.

Taking a closer look at indicial equations

In the numerical example in the previous section, there were two real and dis-

tinct roots to the indicial equation (the equation you would get if the differen-

tial equation were an Euler equation). So you got two distinct solutions, y1

and y2. The general solution is:

y = c y + c y

2 2

1

1

What happens if the indicial equation’s roots are the same — that is, real and

equal? In that case, the first solution is of the following form:

!

3

y1 =

an xn + r

n = 0

The second solution usually involves a logarithmic term. If the roots of the

indicial equation are complex, on the other hand, the solution usually

involves sines and cosines.

In the following sections, I examine a bit more closely the several types of

roots you can have in indicial equations.

Distinct roots that don’t differ by a positive integer

If r ≠ r , and r – r isn’t a positive integer, the second solution, y , is given by

2

1

1

2

2

the following:

<

\_

i

F

!

3

y2 = xr2 1 +

a

r

x

n

x ! 0

n

2

n = 1





236

**Part III: The Power Stuff: Advanced Techniques**

Because these two series:

\_ i

!

3

1 +

a

r

x

n

n

1

n = 1

and:

\_

i

!

3

1 +

a

r

x

n

n

2

n = 1

are analytic at x = 0. The behavior of the solutions at x = 0, where there’s a

regular singular point, is entirely due to these terms:

x

r1

and

x

r2

That’s why r and r are called the exponents at the singularity, as I explain

1

2

in the earlier section “Finding the indicial equation” — they determine what

happens at the singular point.

Equal roots

What if the roots r and r are equal? In that case, y takes the following form:

1

2

2

\_ i

!

3

y = y ln x + xr1

b

r

x

n

x > 0

2

1

n

1

n = 1

You have to calculate the coefficients, bn, as usual: You substitute this equa-

tion into the differential equation, collect terms, set the coefficients of x equal

to zero, and get a recurrence relationship working.

Roots that differ by a positive integer

If the roots of the indicial equation differ by a positive integer, r – r = N, things

1

2

get complex pretty quickly. And you can’t use a solution, y , of this form:

2

<

\_

i

F

!

3

y2 = xr2 1 +

a

r

x

n

x ! 0

n

2

n = 1

Why? Well, because if r – r = N, you would start overlapping with the y

solution:

1

2

1

<

\_ i

F

!

3

y1 = xr1 1 +

a

r

x

n

x ! 0

n

1

n = 1





237

**Chapter 10: Powering through Singular Points**

So what does the second solution look like when r – r = N? Here’s what it

1

2

turns out to be:

<

\_

i

F

!

3

y = a y ln x + xr2 1 +

c

r

x

n

2

1

n

2

n = 1

Here’s what the constant a looks like (which may be zero):

\_

i

^ h

a = lim r - r

a

r

2

N

r " r

2

Here, a is the Nth coefficient , where r – r = N, and

N

1

2

\_

i

9\_

i

^ hC

d

dr

c

r

\=

r - r a r

n

2

2

n





238

**Part III: The Power Stuff: Advanced Techniques**





**Chapter 11**

**Working with Laplace Transforms**

In This Chapter

` `Looking at the elements of a Laplace transform

` `Determining whether a Laplace transform converges

` `Figuring some Laplace transforms

` `Using Laplace transforms to solve differential equations

` `Getting a grip on factoring, convolutions, and step functions

T

his chapter is all about a powerful new tool for handling particularly

tough differential equations. This tool is called a Laplace transform, which

is a type of integral transform; you use it to change a differential equation

into something simpler, solve the simpler equation, and then invert the trans-

form to recover the solution to your original differential equation. Cool, huh?

Read on for all the details.

Breaking Down a Typical

Laplace Transform

To get to know Laplace transforms, start by taking a look at what a general

integral transform looks like:

β

^ h

\_

i ^ h

\#

F s =

K s,t f t dt

α

In this case, f(t) is the function that you’re taking an integral transform of, and

F(s) is the transformed function. The limits of integration, α and β, can be

∞

∞

anything you choose, but the most common limits are – to + . And here’s

the key to the transform: K(s, t) is called the kernel of the transform, and you

choose your own kernel. The idea is that choosing your own kernel gives you

a chance to simplify your differential equation more easily.





240

**Part III: The Power Stuff: Advanced Techniques**

**Who was Laplace?**

Pierre-Simon Laplace (March 23, 1749–March 5, Laplace was responsible for what is now called

\1827) was a French mathematician and Laplace’s equation and for the Laplace transform

astronomer. One of his most important contribu- (which is important to mathematical physics).

tions was his five-volume work, Mécanique The Laplacian operator, which is a differential

Céleste (Celestial Mechanics), in which he laid operator that’s central to many areas of physics,

the groundwork of modern mathematical astron- also is named after Laplace.

omy. This work was used by Sir Isaac Newton.

When you restrict yourself to differential equations with constant coeffi-

cients, as you do in this chapter, a useful kernel is e–st. Why? Because when

you differentiate this kernel with respect to t, you end up with powers of s,

which you can equate to the constant coefficients. Here’s what this process

looks like:

^ h

3

^ h

\#

F s =

e

\- st f t dt

0

Note that besides using the kernel e–st, the limits of integration in the previous

∞

transform are from 0 to because negative values of t would make the inte-

gral diverge.

$ ^ h.

The symbol for Laplace transforms is j f t , which is the Laplace trans-

form of f(t):

$ ^ h.

^ h

3

^ h

\#

j f t = F s

e

\- st f t dt

0

Deciding Whether a Laplace

Transform Converges

A potential difficulty exists with Laplace transforms: Sometimes an integral

won’t converge. Frequently, integrals with infinite ranges don’t converge, and

if the Laplace transform of a function won’t converge, it won’t be of any use

to you in solving differential equations.





241

**Chapter 11: Working with Laplace Transforms**

Take the following equation, for example: f(t) = e. The Laplace transform for

t

this equation is:

^ h

3

\#

F s =

e

\- st

t

e dt

0

So here’s what the new and improved transform looks like:

^ h

3

\#

F s =

e- s dt

0

Taking the e–s factor outside the integral leaves you with this equation:

^ h

3

\#

F s = e- s dt

0

This equation is all fine and good, but integrating it gives you:

^ h

F s = t e- s

3

0

And for finite values of s, this equation tends toward infinity instead of con-

verging, which is obviously a problem.

So how do you know if a Laplace transform exists in finite form? It’s time for a

theorem. But first, I start by defining what it means for the function f(t) to be

piecewise continuous. The function f(t) is piecewise continuous if both of the

following are true:

` `f(t) is continuous on each subinterval ti – 1 < t < ti, where i stands for the

number of the interval

` `f(t) stays finite as the endpoints of each subinterval are approached

(from inside the subinterval)

Now that you’re armed with that definition, here’s the theorem that helps you

determine whether a Laplace transform exists for your particular function:

**If f(t) is piecewise continuous in the interval 0** ≤ **t** ≤ α **for any positive** α**,**

**and | f(t) |** ≤ **Ceat where t** ≥ **K, where C, a, and K are real and positive,**

$ ^ h.

**then the Laplace transform F(x) =** k **f t exists for s > a.**

Calculating Basic Laplace Transforms

In this section, you can take a look at how to calculate some basic Laplace

transforms. Enjoy!





242

**Part III: The Power Stuff: Advanced Techniques**

The transform of 1

In this section, you start off by calculating just about the easiest Laplace

transform there is — the Laplace transform of 1. Here’s what that transform

looks like:

" ,

3

^ h

\#

j 1 =

e

\- st 1 dt

0

Integration gives you:

" ,

3

^ h

1

\#

j 1 =

e

\- st 1 dt=

s > 0

s

0

So the Laplace transform of 1 remains finite for all s > 0, and it depends on the

value you choose for s.

The transform of eat

Now move on to solving the transform of eat: f(t) = eat. Here’s what the Laplace

transform looks like:

\#

\-

3

\#

j eat

\=

e

\- st

eat dt

0

With a little simplifying, this equation becomes:

\#

\-

3

\#

j eat

\=

e- (s - a) t dt

0

And this, in turn, becomes the following after integration:

\#

\-

3

1

\#

j eat

\=

e

\- (s - a) t dt=

s > a

s - a

0

Again, this result depends on the value you choose for s.

The transform of sin at

The Laplace transforms in the previous two sections don’t look so bad. How

about now trying your hand at the Laplace transform of some trig functions,

such as sin at? Here’s the Laplace transform of sin at, which I calculate in the

following sections:

"

,

3

\#

j sinat = sinat e- st dt

0





243

**Chapter 11: Working with Laplace Transforms**

Integrating by parts

So how do you go about tackling the integration to this tricky transform?

Well, you have to be crafty here. The best way to solve this transform is to

integrate by parts, giving you:

"

,

3

e

\- st cosat

s

\#

cosat eat dt

j sinat =

3

\-

a

a

0

0

Wow, did all that work buy you anything? Well, sure! It turns out that the first

term is 1/a (substituting in 0 for t), so this breaks down to:

"

,

3

1

s

\#

cosat eat dt

j sinat =

\-

a

a

0

Here’s where the clever part comes in. Note that the second term has become

similar to the original integral, except that it uses cosine. Maybe if you inte-

grate by parts again, you’ll get back to an integral that uses sine. And if that’s

"

,

the case, maybe you can actually factor j sinat onto the left side, which

would leave you with some reasonable expression on the right.

Integrating the previous transform by parts again gives you:

"

,

3

1

s

a

2

2

\#

sinat eat dt

j sinat =

\-

a

0

Simplifying the result

After going through the previous section, you may be asking yourself: “Is this

just getting worse and worse?” Actually, no. Things truly are improving —

"

,

note that the second term is s

becomes:

2

/a2

multiplied by j sinat . So this transform

"

,

"

,

1

s

a

2

2

j sinat =

\-

j sinat

a

It turns out that you have been clever after all, because you can recast the

equation this way:

"

,

"

,

s

a

2

2

1

j sinat

\+

j sinat =

a

Or even simpler, you get:

"

,

s

2

\+ a

2

1

j sinat =

a

a

2

which becomes:

"

,

a

\+ a

j sinat =

s > 0

s

2

2

"

,

Can that be it? Yes, that’s j sinat . Great work!





244

**Part III: The Power Stuff: Advanced Techniques**

Consulting a handy table for some relief

As you see in the previous sections, things can become complex pretty fast

when it comes to calculating Laplace transforms. Are you going to be expected

to jump through these kinds of hoops each time you need a Laplace transform?

If so, wouldn’t it just be easier to hit yourself on your head with a brick?

Thankfully, you usually don’t have to jump through those hoops very often.

Instead, you can use some handy tables of Laplace transforms. After all, why

reinvent the wheel? Check out Table 11-1, which is designed to save you a lot

of work.

Keep in mind that the Laplace transform of f(t) is defined this way:

$ ^ h.

^ h

3

^ h

\#

j f t = F s =

e

\- st f t dt

0

So the Laplace transform depends on the value you choose for s.

**Table 11-1**

**Laplace Transforms of Common Functions**

**Function**

**Laplace Transform**

**Restrictions**

s > 0

1

1

s

1

e

at

s > a

s - a

n!

t

n

s > 0, n an integer > 0

s > 0

s

n

\+ 1

s

\+ a

a

\+ a

s

\- a

a

\- a

cos at

sin at

s

2

2

2

s > 0

s

s

s

2

cosh at

sinh at

s > |a|

s > |a|

s > a

2

2

2

2

s - a

\- a

e

e

at cos bt

at sin bt

\_s

\_s

i

i

\+ b

\+ b

2

2

2

2

2

b

s > a

\- a

2

n!

t

n

e

at

s > a, n an integer > 0

c > 0

^

c

h

s - a n + 1

1

$ ^

h.

f(ct)

(n)(t)

j f s /c

$ ^ h.

^ h

^ h

^ h

f

s

n

j f t - s

n

1

f 0 - . . . - s f (n 2) 0 - f (n 1)

0

\-

\-

\-





245

**Chapter 11: Working with Laplace Transforms**

Solving Differential Equations

with Laplace Transforms

Now here comes the fun stuff: using Laplace transforms to solve differential

equations. Take a look at this differential equation, for example:

y" + 3y' + 2y = 0

The initial conditions for this equation are:

y(0) = 2

and

y'(0) = –3

“Wait a minute,” you say. “I know how to solve this! You know that to solve

this equation you just assume a solution of the following form:

y = ceat

Then you plug into the original equation to get:

ca

Dividing by ceat gives you:

\+ 3a + 2 = 0

which becomes:

(a + 1) (a + 2) = 0

2

eat + 3caeat + 2ceat = 0

a

2

So a = –1 and –2, which means that the solution is:

y = c1e–t + c2e–2t

Now, matching the initial condition y(0) = 2 means that:

y(0) = c + c = 2

1

2

Take the first derivative of the solution, which gives you:

y' = –c1e–t + –2c2e–2t





246

**Part III: The Power Stuff: Advanced Techniques**

So y'(0) = –3 gives you:

y'(0) = –c + –2c = –3

1

2

And solving y(0) = c + c = 2 and y'(0) = –c + –2c = –3 results in:

1

2

1

2

c1 = 1

and:

c2 = 1

So the general solution is:

y = e–t + e–2t

Excellent, you solved the problem with traditional techniques. Now try doing

the same thing using Laplace transforms in the following sections. Having

already solved the problem means that you can check the answer you get.

And beginning with this relatively simple problem will show how to use

Laplace transforms to solve differential equations.

A few theorems to send you on your way

To start solving the example problem, you need a few more theorems. You’ve

figured out how to do a number of individual Laplace transforms, but what

about doing the Laplace transform of an equation like this one:

y" + 3y' + 2y = 0

The Laplace transform is a linear operator

The first theorem I want to introduce you to says that the Laplace transform

is a linear operator:

**Because the Laplace transform is a linear operator, this is a true statement:**

$

^ h

^ h.

$

^ h.

$

^ h.

k **c f t** + **c f**

**t**

= **c** k **f**

**t**

\+ **c** k **f**

**t**

**1**

**1**

**2**

**2**

**1**

**1**

**2**

**2**

**In other words, the Laplace transform of the sum of two terms is the sum**

**of the Laplace transforms of those two terms.**

Taking the Laplace transform of the differential equation you want to solve

gives you:

j{y'' + 3y' + 2y}





247

**Chapter 11: Working with Laplace Transforms**

which becomes:

j{y''} + 3j{y'}+ 2j{y}

So you’ve made some progress in solving differential equations already — as

you can see, you can break things up by terms, which is a great help.

The Laplace transform of a first derivative

Okay, so you already know something about the term j y — that’s the

Laplace transform of the function y(x). But what about the j yl term? That

brings me to the next theorem:

\# -

\#

\-

**Say that f(t) is continuous and f'(t) is piecewise continuous in an interval**

**0** ≤ **t** ≤ α **and there exist constants C,** β**, and** δ **such that |f(t)|** ≤ **Ce**β**t for t** ≥ δ**.**

$

^ h.

**In that case,** k **f** l **t exists for s >** β**, and:**

$

^ h.

$ ^ h.

^ h

k **f** l **t** = **s** k **f t** - **f 0**

The Laplace transforms of higher derivatives

What about j {f''(t)}, j {f'''(t)}, all the way up to j f (n)

$

^ h.

t

? It turns out that

you can apply the previous equation over and over to find the higher deriva-

tives. Here’s the theorem that formalizes this application:

**Say that f(t), f'(t), f"(t) . . . f (n–1)(t) are continuous and f (n)(t) is piecewise con-**

**tinuous in an interval 0** ≤ **t** ≤ α **and there exist constants C,** β**, and** δ **such**

**that |f(t)|** ≤ **Ce**β**t, |f'(t)|** ≤ **Ce**β**t , |f"(t)|** ≤ **Ce**β**t . . . |f (n–1)(t)|** ≤ **Ce**β**t for t** ≥ δ**.**

$

^ h.

**In that case,** k **f (n)**

**t**

**exists for s >** β**, and:**

$

^ h.

$ ^ h.

^ h

^ h

^ h

k **f (n)**

**t**

= **s**

**n**

k **f t** - **sn** - **1 f 0** - **. . .** - **sf (n** - **2) 0** - **f (n** - **1)**

**0**

Solving a second order

homogeneous equation

Alright, now that you’re armed with the theorems from the previous section,

you’re ready to solve this differential equation in the following sections:

y" + 3y' + 2y = 0

In general, here’s how the process works:

**1. Figure out the Laplace transform of the differential equation.**

**2. Solve the equation algebraically.**

**3. Try to find the inverse transform.**





248

**Part III: The Power Stuff: Advanced Techniques**

Using Laplace transforms in this process has one major advantage: It changes

a differential equation to an algebraic equation. The only sticky part is finding

the transforms and inverse transforms of the various terms in the differential

equation (and that’s what the tables of Laplace transforms are for).

You can generalize the solution technique used in the upcoming problem to

the general second order differential equation ay" + by' + cy = f(t). It turns out

that the Laplace transform of the solution to this differential equation is:

$~~ ^~~ h.

^

h~~ ^~~ h

^~~ h

j f t

$ ^ h.

as + b y 0 + ayl 0

j y s

\=

\+

as

2

\+ bs + c

as

2

\+ bs + c

Note that when you use this equation, you don’t have to find the solution to

the homogeneous version of the differential equation first — doing so isn’t

necessary when you use Laplace transforms.

Finding the Laplace transform of the equation’s unknown solution

Taking the Laplace transform of the differential equation (see the earlier sec-

tion “The Laplace transform is a linear operator”) gives you:

j{y''} + 3j{y'}+ 2j{y}

Then, using the theorem from the earlier sections on the Laplace transforms

of derivatives, you get:

\# -

^ h

^ h

j{y''}=s

j y - sy 0 - yl 0

2

and

\#

\-

\# -

^ h

j yl = sj y - y 0

After plugging these two derivatives into the Laplace transform of the original

differential equation, you get this result:

\# -

^ h

^ h

9

\# -

^ hC

\# -

s

2

j y - sy 0 - yl 0 + 3 sj y - y 0 + 2j y = 0

Collecting terms gives you:

\_s

\+ 3s + 2 j y - 3 + s y 0 - yl 0 = 0

i

\# -

^

h ^ h

^ h

2

Now you can use the initial conditions:

y(0) = 2

and

y'(0) = –3





249

**Chapter 11: Working with Laplace Transforms**

in the collected version of the equation’s Laplace transform, which gives you:

\_s

\+ 3s + 2 j y - 6 + 2s + 3 = 0

i

\# -

^

h

2

Or, more simply:

\_s

\+ 3s + 2 j y - 2s - 3 = 0

i

\# -

2

Moving all the terms to the correct spots gives you this result:

\# -

2s + 3

s + 3s + 2

j y = \_

i

2

Factoring the denominator leaves you with this equation for the Laplace

transform of the differential equation’s solution:

\# -

2s + 3

j y = ^

h^

h

s + 1 s + 2

Discovering a function to match the Laplace transform

Now you have to find a function whose Laplace transform is the same as the

previous solution. To do that, use the method of partial fractions, and then

write the solution as:

\# -

2s + 3

a

s + 1

b

s + 2

j y = ^

h^

h = ^

h + ^

h

s + 1 s + 2

And now you have to figure out what a and b are. To do so, write the

fractions as:

^

h

^

h

\# -

a s + 2 + b s + 1

2s + 3

j y = ^

h^

h =

^

h^

h

s + 1 s + 2

s + 1 s + 2

At this point, you can equate the numerators in the fractions to get:

2s + 3 = a (s + 2) + b(s + 1)

Because it’s up to you to choose s, you can first set it to –1 (to make it easy

on yourself), which gives you:

1 = a

And now you can set s to –2 to get:

–1 = –b

or:

1 = b





250

**Part III: The Power Stuff: Advanced Techniques**

Okay, so a = 1 = b. You have these fractions:

\# -

a

s + 1

b

s + 2

j y = ^

h + ^

h

Substituting for a and b gives you a more detailed Laplace transform of the

differential equation’s solution:

\# -

1

s + 1

1

s + 2

j y = ^

h + ^

h

Uncovering the inverse Laplace transform

to get the equation’s solution

Whew. After you know what the Laplace transform of the solution looks like,

it’s time to find the inverse Laplace transform to find the actual solution to

the differential equation.

$ .

Your calculator isn’t going to have an inverse Laplace transform j - 1

button on it (and if it does, I’d be glad to buy it from you). Your best bet,

then, is to use a table, like Table 11-1 earlier in this chapter, to find the form

of the transform that you’re dealing with. Then you simply have to find the

function whose transform that is.

From Table 11-1, you can see that the Laplace transform of eat is:

\#

\-

1

j eat

\=

s > a

s - a

This transform looks promising. You can use this information to get the

inverse transform. Take a look at the first term:

1

^

h

s + 1

Comparing this to the Laplace transform of eat tells you that in this case,

a = –1, so the first term in the differential equation’s solution is:

y1 = e–t

Now look at the second term:

1

^

h

s + 2

Comparing this to the Laplace transform of eat tells you that a = –2, so the

second term in the differential equation’s solution is:

y2 = e–2t





251

**Chapter 11: Working with Laplace Transforms**

And the solution to the differential equation is y = y + y , which equals this

1

2

final result:

y = y + y = e–t + e–2t

1

2

This solution is confirmed by your earlier solution (which you determined at

the very beginning of this section). But this time, you did it with Laplace

transforms. Not too bad, huh?

Solving a second order nonhomogeneous

equation

Ready for another example? How about this little gem:

y" + y = –15 sin 4t

where

y(0) = 2

and

y'(0) = 5

“Hmm,” you say, “I think I know how to solve this one as well.” Good! You

must have read Chapter 6! So, you likely know that you should first take a

look at the homogeneous equation:

y" + y = 0

And because it looks like sines and cosines would work, you can assume a

solution of the following form:

y = c sin t + c sin t

1

2

Now you need a particular solution. The right side has a term in sin 4t, so try a

similar term here. Doing so would give you this form for the general solution:

y = c sin t + c cos t + c sin 4t

1

2

3

Plugging this into y" + y = –15 sin 4t gives you:

–c sin t – c cos t – 16c sin 4t + c sin t + c cos t + c sin 4t = sin 4t

1

2

3

1

2

3





252

**Part III: The Power Stuff: Advanced Techniques**

Or, with some simplification you get:

–15 c3 sin t = –15 sin 4t

So c3 = 1, and so far, your general solution looks like this:

y = c sin t + c cos t + sin 4t

1

2

Now you can use the initial conditions to determine c and c . Here’s y(0):

1

2

y(0) = c sin t + c cos t + sin 4t = c = 2

1

2

2

So c2 = 2. So far, your general solution looks like this:

y = c1sin t + 2 cos t + sin 4t

Now you can determine c1 with the last initial condition, which means that

you have to calculate y'(0). Here’s what y' looks like:

y' = c1cos t – 2 sin t + 4 cos 4t

And here’s y'(0):

y'(0) = c1 + 4 = 5

So c1 = 1. And the general solution is:

y = sin t + 2 cos t + sin 4t

Okay, very nice. You obviously have been paying attention! Now, in the fol-

lowing sections you can try the same thing using Laplace transforms.

Determining the Laplace transform

Here’s the differential equation you’re trying to solve with the Laplace trans-

form, in case you forgot:

y" + y = –15 sin 4t

To begin, take the Laplace transform of it, using the relation from the earlier

section “The Laplace transforms of higher derivatives”:

\# -

^ h

^ h

j{y''}=s

j y - sy 0 - yl 0

2

So here’s your differential equation:

\# -

^ h

^ h

\# -

-15

s + 16

2

s

2

j y - sy 0 - yl 0 + j y = \_

i





253

**Chapter 11: Working with Laplace Transforms**

where you’ve put in the Laplace transform of sin 4t, according to Table 11-1.

Here are the initial conditions for this problem:

y(0) = 2

and

y'(0) = 5

Substituting these initial conditions into the previous equation gives you this

result:

\# -

\# -

-15

s + 16

2

s

2

j y - 2s - 5 + j y = \_

i

Or, with some simplifying you get:

\_s

\+ 1 j y - 2s - 5 = \_

i

\# -

-15

s + 16

2

2

i

Now, taking 2s + 5 over to the right side gives you:

\_s

\+ 1 j y = \_

i

\# -

-15

2

2

\+ 16i + 2s + 5

s

Be careful, because you’re into some heavy algebra now! After the calcula-

tions, the equation works out to be:

^

h\_

\+ 16i

\_s

i

\# - -15 + 2s + 5

s

2

2

\+ 1 j y =

\_

i

s

2

\+ 16

Next, after expanding the terms you get the following equation:

\_s

\+ 1 j y =

i

\# -

-15 + 2s\_

\+ 32s + 5s

s + 16

2

\+ 80

3

2

2

i

which works out to become:

\# -

2s

3

\+ 5s

2

2

\+ 32s + 65

s + 16

2

j y =

\_s

i\_

i

\+ 1

Matching a function to the Laplace transform

Wow. How the heck do you expand the previous equation using partial frac-

tions so you can find a function to match the transform? It’s actually pretty

easy! You simply break it up and assume a form like this:

\# -

as + b

cs + d

s + 16

2

j y = \_

\+ 1i + \_

i

s

2





254

**Part III: The Power Stuff: Advanced Techniques**

which is:

^

as + bh\_

\+ 16 + cs + dh\_s

i

^

\+ 1i

\# -

s

2

2

j y =

\_s

i\_

i

2

\+ 1

s

2

\+ 16

Now tackle the numerator. The first term is:

(as + b)(s + 16)

Multiplying this out gives you:

as + 16as + bs + 16b

The second term in the numerator is:

(cs + d)(s + 1)

After you multiply the term out, you get:

cs + cs + ds + d

2

3

2

2

3

2

Adding the two terms that you multiplied out gives you this form for the

numerator:

as

Or, after some simplifying:

(a + c)s + (b + d)s + (16a + c)s + (16b + d)

This numerator must equal the numerator in the other equation you have for

3

\+ 16as + bs

2

\+ 16b + cs

3

\+ cs + ds

2

\+ d

3

2

the same Laplace transform, 2s

3

\+ 5s + 32s + 65. So equating the two numera-

2

tors gives you:

2s

3

\+ 5s

2

\+ 32s + 65 = (a + c)s

3

\+ (b + d)s + (16a + c)s + (16b + d)

2

Does this really buy you anything? Well, it still looks like a cubic equation.

And it still is a cubic equation, but the powers of s must be equal on the two

sides of the equation, so you have these relations:

a + c = 2

b + d = 5

16a + c = 32

16b + d = 65





255

**Chapter 11: Working with Laplace Transforms**

Solving these equations for a, b, c, and d gives you the following:

a = 2

b = 1

c = 0

d = 1

Here’s your equation for the Laplace transform:

\# -

as + b

cs + d

j y = \_

\+ 1i + \_

i

s

2

s

2

\+ 16

Expanding this gives you:

\# -

as

2

b

cs

d

\+ 16

j y = \_

\+ 1i + \_

\+ 1i + \_

\+ 16i + \_s

i

s

s

2

s

2

2

Finally, plugging in values for a, b, c, and d gives you:

\# -

2s

2

1

1

\+ 16

j y = \_

\+ 1i + \_

\+ 1i + \_

i

s

s

2

s

2

Using the handy table to find the inverse Laplace transform

So the general solution, after you check Table 11-1 and plug in all the right

numbers, is:

y = sin t + 2 cos t + sin 4t

As you may have noticed, this solution agrees with the one you got earlier in

this chapter using the traditional method. Great work.

Solving a higher order equation

Try out this ever-popular higher order differential equation in the land of

Laplace transforms:

y

(4) – y = 0

where:

y(0) = 0

y'(0) = 1

y"(0) = 0

y'''(0) = 0





256

**Part III: The Power Stuff: Advanced Techniques**

So now you probably want to know how to go about solving y(4) – y = 0 using

Laplace transforms. The following sections will show you how.

Figuring out the equation’s Laplace transform

A fourth derivative may seem dreadful, but the fact that three of the four ini-

tial conditions are zero will definitely help. Here’s the Laplace transform of

y(4) – y = 0:

\# -

^ h

yl^0h - s y''(0) - y'''(0) - j{y} = 0

s

4

j y - s

3

y 0 - s

2

This equation looks like it has the potential of being a tough nut to crack, but

substituting the initial conditions simplifies things, giving you this:

\# -

\# -

s

4

j y - s

2

\- j y = 0

Looks a lot more manageable, doesn’t it? Solving for

^

as + bh\_

\+ 16 + cs + dh\_s

i

^

\+ 1i

\# -

s

2

2

j y =

\_s

i\_

i

j{y} gives you:

2

\+ 1

s

2

\+ 16

\# -

s

2

j y =

s - 1

4

Unearthing a function to match the Laplace transform

Now the plan is to get the transform from the previous section into a form

that’s recognizable in Table 11-1. You can use partial fractions to do just that.

Because s

4

– 1 = (s

2

\+ 1) (s – 1), you can write the previous transform in the

2

following format:

\# -

as + b cs + d

j y =

\+

s

2

\- 1

2

s + 1

Adding these terms together gives you:

^

as + bh\_

\+ 1 + cs + dh\_s

i

^

\- 1i

\# -

s

2

2

j y =

s

4

\- 1

The numerator here must equal the numerator in the other equation you

\# -

have for j y . Equating the numerators gives you:

s

2

= (as + b)(s

2

\+ 1) + (cs + d)(s – 1)

2

Don’t forget that you can choose the value of s yourself. For example, if you

choose s to equal 1, the previous equation simplifies to:

1 = 2(a + b)





257

**Chapter 11: Working with Laplace Transforms**

How about if you choose s = –1? Then you get this result:

1 = 2(–a + b)

Adding these two equations together gives you:

2 = 4b

So:

b =

Substituting b =

1 = 2(a + ⁄ )

2

1⁄

2

1

⁄ into 1 = 2(a + b) gives you:

2

1

Or with some simplification:

1 = 1 + 2a

So:

a = 0

Okay, so a = 0 and b = 1. How about c and d? You can set s = 0 in 2s =

2

(as + b)(s

2

\+ 1) + (cs + d)(s – 1) to get:

2

0 = b – d

Or:

b = d

And because b =

1⁄

2

, d = ⁄ also.

2

1

Alright, that gives you a, b, and d. But you still have to figure out c. Take a

look at your equation that equated the two numerators:

s

2

= (as + b)(s

Note that equating the cubic terms on the two sides gives you this equation:

0 = as + cs

But because a = 0, this becomes:

0 = cs

2

\+ 1) + (cs + d)(s

2

– 1)

3

3

3





258

**Part III: The Power Stuff: Advanced Techniques**

So c = 0. That gives you:

a = 0

b =

c = 0

d =

1

⁄

2

1⁄

2

Substituting these numbers into the Laplace transform gives you this more

detailed result:

1

1

\# -

2

2

j y =

\+

s

2

\- 1

s

2

\+ 1

So, as you can see, having used the initial conditions in the problem has sig-

nificantly simplified the form of the Laplace transform.

Getting the equation’s inverse Laplace transform

After you have the Laplace transform, check out Table 11-1 for the inverse

transform, and then plug in the correct numbers. Here’s the result you

should get:

^

h

1

y = sinh t + sint

2

Factoring Laplace Transforms

and Convolution Integrals

Sometimes, the Laplace transforms you end up with require a little extra

work to solve. But no worries; you just have to be a little creative. And in the

following sections, I explain how to do just that. For instance, I show you how

to factor a Laplace transform into a sum of fractions and how to work with

convolution integrals.

Factoring a Laplace transform

into fractions

When you face an especially funky-looking Laplace transform, factoring the

denominator and the numerator often helps. For example, imagine that you

end up with this Laplace transform when solving a differential equation:

\# -

s + 4

j y =

s + 4s + 8

2





259

**Chapter 11: Working with Laplace Transforms**

There’s no entry in Table 11-1 that matches this transform. But the form of

the denominator indicates that you may be able to factor it. Here’s what the

factoring may look like:

s

2

\+ 4s + 8 = (s + 2)

2

\+ 2

2

This equation looks somewhat more promising, don’t you think? You can now

convert your original transform into this new form:

\# -

s + 4

s + 2 + 2

j y = ^

h

2

2

Hey, wait a minute. This expression isn’t in Table 11-1 either. But take a closer

look at the numerator; you can factor it as well. For instance, you can rewrite

the numerator like this:

s + 4 = (s + 2) + 2

This in turn gives you the following for the Laplace transform:

^

h

\# -

s + 2 + 2

j y = ^

h

2

s + 2 + 2

2

Or, with a little simplifying you get:

^

h

\# -

s + 2

2

j y = ^

\+ ^

h

h

2

2

s + 2 + 2

2

s + 2 + 2

2

Doesn’t this look a whole lot better? According to Table 11-1, you can now

find the inverse Laplace transform, which is:

\# -

j y = e- 2t cos2t + e- 2t sin2t

Checking out convolution integrals

The example in the previous section factored a Laplace transform into a sum

of fractions. But what if, instead of a sum, you end up with a product of recog-

nizable Laplace transforms? What do you do then?

For example, what if you had this Laplace transform:

\# -

a

s + a

j y =

^

h

2

s

2

Looking at Table 11-1, you can see that the inverse transform of this expres-

sion doesn’t appear. However, if you write this Laplace transform as:

\# -

1

a

s + a

j y =

^

h

s

2

2





260

**Part III: The Power Stuff: Advanced Techniques**

then you can see that this is the product of the Laplace transforms for t and

sin at. This product brings you to an important question: Can you write the

inverse Laplace transform this way:

\# -

j y = tsinat

Nope, it doesn’t work like that. The inverse of the sum of Laplace transforms

is the sum of the inverses of the individual Laplace transforms, but it doesn’t

work that way when you multiply Laplace transforms together. Instead, you

have to turn to convolution integrals, as defined in the following theorem:

**If:**

$ ^ h. $ ^ h.

$ ^ h.

k **f t**

k **g t** = k **h t**

**then:**

^ h

**t**

^

h

^ h

\#

**h t** = **f t** - α **g** α **d**α

**0**

**which also equals:**

^ h

**t**

^ h

^

h

\#

**h t**

**f** α **g t** - α **d**α

**0**

**where** α **is a new variable. The integrals in these transforms are called**

**convolution integrals.**

Sometimes you may see the convolution operation denoted with an asterisk

(\*), like this:

h(t) = (f \* g)(t)

Using this new operator means that you can write the products of Laplace

transforms in much the same way that you would use the multiplication

operator:

f(t) \* 0 = 0 \* f(t) = 0

f(t) \* g(t) = g(t) \* f(t)

f(t) \* (g(t) + i(t))= f(t) \* g(t) + f(t) \* i(t)

(f(t) \* g(t)) \* i(t) = f(t) \* (g(t) \* i(t))

Armed with this theorem, you can now tackle the example problem:

\# -

1

a

s + a

j y =

^

h

s

2

2





261

**Chapter 11: Working with Laplace Transforms**

These terms are the Laplace transforms of t and sin at. So you can write the

inverse Laplace transform like this:

^ h

t

^

h

^

h

\#

y t

t - α sin at dα

0

which equals:

^ h

t

sinat

y t =

\-

a

a

2

Surveying Step Functions

In the world of Laplace transforms, there’s an interesting function called the

step function, which looks like this: ua(t). In the following sections, I break

down the elements of the step function, and I show how it relates to Laplace

transforms.

Defining the step function

The function’s value is defined as 0 up to a certain point, a, but then as 1

thereafter. Here’s the definition of the step function in equation form:

^ h '0 t<a

u

t =

a

1 t $a

As an example, if a = 0, you have that u0(t) equals:

^ h '0 t<0

u t =

0

1 t $0

Note that the subscript on the u indicates the point at which the step func-

tion “steps.”

And if a = 1, you have that u1(t) equals:

^ h '0 t<1

u t =

1

1 t $1

You can see what ua(t) looks like graphically in Figure 11-1.





262

**Part III: The Power Stuff: Advanced Techniques**

**Figure 11-1:**

The step

function in

graph form.

Figuring the Laplace transform

of the step function

Now that you’re familiar with the step function, go a bit further and take the

Laplace transform of the step function:

$

^ h.

3

^ h

\#

j u

t

\=

e

\- st

u

t dt

a

a

0

Substituting the step function into this transform gives you the following result:

$

^ h.

3

\#

j u

t

\=

e- st dt

a

a

Note that the lower limit of the integral has become a. Why? Because the inte-

gral is zero up to that point. Now this equation becomes:

$

^ h.

e

\- as

j u

t

\=

s > 0

s

a

And that brings me to a new theorem:

**If a is a positive constant, then:**

$

^ h ^

h.

$ ^ h.

k **u t f t** - **a** = **e**- **as** k **f t**

**a**

This theorem can help you with Laplace transforms that have exponentials in

them. To see how, try finding the inverse Laplace transform of this equation:

\# -

1 - e- s

j y =

s

2

Begin by breaking it into the following:

\# -

1

e

\- s

j y =

\-

s

2

s

2





263

**Chapter 11: Working with Laplace Transforms**

Using the theorem, you can find the inverse Laplace transform:

y(t) = t – u1(t)(t – 1)

That is, for t < 1:

y(t) = t

and for t ≥ 1:

y(t) = 1

So the step function helped you find a Laplace transform. Pretty cool, right?





264

**Part III: The Power Stuff: Advanced Techniques**





**Chapter 12**

**Tackling Systems of First Order**

**Linear Differential Equations**

In This Chapter

` `Brushing up on matrix basics

` `Handling matrix operations

` `Checking out linear independence, eigenvalues, and eigenvectors

` `Working out homogeneous and nonhomogeneous systems

T

his chapter is all about systems of differential equations, where a system

is a set of linear differential equations that share some common vari-

ables. In this chapter, I show you how to apply many of the techniques used

to handle systems of standard algebraic equations to solving systems of dif-

ferential equations.

Being able to handle systems of differential equations is useful in two cases:

` `When you want to reduce the order of a differential equation to a system

of first order differential equations

` `When you have a problem that consists of interdependent differential

equations — such as when you have an electrical circuit with linked

loops in it that share the current (don’t worry; I won’t delve into such

science here)

This chapter is heavy in its use of matrices, which are usually used to solve sys-

tems of linear equations. After you brush up on the fundamentals of matrices,

you find out about some important concepts, such as linear independence,

eigenvalues, and eigenvectors. I wrap up the chapter by explaining how to

solve both homogeneous and nonhomogeneous systems.





266

**Part III: The Power Stuff: Advanced Techniques**

Introducing the Basics of Matrices

Take a look at the following system of three simultaneous equations:

x + y + z = 6

x – y – z = –4

x + y – z = 0

How do you solve this system of equations for x, y, and z? A fair bit of algebra

is involved here, so to keep things straight, you can use a matrix. You’re most

likely already familiar with matrices, but in the following sections, I go over

the fundamentals just in case you need to refresh your memory.

Setting up a matrix

Simply put, a matrix is a set of numbers arranged into columns and rows,

like this:

J

N

a

a

b

c

a

3

K

O

1

1

1

2

2

2

Kb

b O

K

3

3

O

K

O

c

c

L

P

When creating a matrix, you place the coefficients of each equation in a row.

For instance, a , a , and a are from one equation; b , b , and b are from a

1

2

3

1

2

3

second equation; and c , c , and c are from a third equation. Similarly, the first

1

2

3

coefficient of any equation is in the first column; the second coefficient of any

equation is in the second column; and the third coefficient of any equation is

in the third column. (I’m sure you get the idea!) A matrix can contain as many

rows and columns as you need.

Putting numbers into rows and columns like this helps you keep track of

them. (Neatniks rejoice!) For example, you can represent the coefficients in

these equations:

x + y + z = 6

x – y – z = –4

x + y – z = 0

like this:

J

N

1

1

1

K

O

K1 -1 -1O

K

L

O

K

O

1

1 -1

P





267

**Chapter 12: Tackling Systems of First Order Linear Differential Equations**

And to keep track of the constants on the right side of these equations, you

can create what’s called an augmented matrix. With this type of matrix, a ver-

tical line keeps the constants on the right sides of the equations separate

from the coefficients on the left sides of the equations, like this:

J

N J

N

6

1

1

1

K

O K

O

K1 -1 -1O K-4O

K

L

O K

O K

O

K

O

P

1

1

-1

P L

0

Working through the algebra

After you set up a matrix, it’s easy to keep track of the algebraic manipula-

tions involved in solving the system of simultaneous equations. Here, you’re

going to work on the individual rows.

You can see how this works using the matrix you set up in the previous sec-

tion. Remember that your goal is to solve for x, y, and z. First, add the second

row to the first and place the result in the first row, making sure that you

leave the second row intact. Doing all this gives you:

J

N J

N

2

2

0

0

K

O K

O

K 1 -1 -1O K-4O

K

O K

O K

O

K

O

P

1

1

-1

P L

0

L

Now divide the first row by 2 to simplify:

N J

J

N

1

1

0

0

K

O K

O

K1 -1 -1O K-4O

K

L

O K

O K

O

K

O

P

1

1

-1

P L

0

Next, add –1 times the first row to the second row and place the result in the

second row:

J

N J

N

1

1

0

0

K

O K

O

K0 -1 -1O K-5O

K

O K

O K

O

K

O

P

1

1

-1

P L

0

L

Then multiply the second row by –1:

N J N

J

1 0

0

1

K

O K O

1O K5O

O K O

K0

1

1

K

K

O K O

-1

1

0

L

P L P





268

**Part III: The Power Stuff: Advanced Techniques**

Add –1 times the first row to the third row and place the result in the third

row, like so:

J

N J

N

1 0

0

1

K

O K

O

K0

1

1

1O K 5O

K

O K

O K

O

K

O

P

0

-1 -1

L

P L

Now add –1 times the second row to the third, placing the result in the

third row:

J

N J

N

1 0

0

1

K

O K

O

K0

1

0

1O K 5O

K

O K

O K

O

K

O

P

0

-2 -6

P L

L

Finally, you divide the third row by –2:

N J N

J

1 0

0

1

K

O K O

1O K5O

O K O

K0

1

0

K

K

O K O

0

1

3

L

P L P

Note that you now have a triangular matrix on the bottom left; in other words,

the bottom left triangle’s elements all equal zero. This triangle simplifies mat-

ters considerably, because this new augmented matrix now represents this

system:

x = 1

y + z = 5

z = 3

And from the latter two equations, finding the solution for y is pretty trivial:

y = 2. Now you’ve solved for all three variables. Nice work.

Examining matrices

Did you know that you can name matrices? Yup, that’s right. In matrix terms,

a name is denoted in **bold.** For instance, you can name the following matrix,

which contains both real and complex elements, **A** (imaginative, I know):

J

N

1

2 + 2i

**A** = K

O

K

O

P

3 + 3i

4

L





269

**Chapter 12: Tackling Systems of First Order Linear Differential Equations**

The transpose of a matrix swaps its rows and columns; in other words, the

rows become the columns, and the columns become the rows. Here’s what

the transpose of **A** (called **A** ) looks like:

T

J

N

1

3 + 3i

**A**

T

= K

O

K

O

P

2 + 2i

4

L

You can also define the complex conjugate of a matrix. To denote a complex

conjugate, you simply add a line above the name of a matrix. The complex

conjugate of a matrix is simply the complex conjugate element by element of

the matrix. Here’s the complex conjugate of **A**, where you flip the sign of the

imaginary part:

J

N

1

2 - 2i

**A** = K

O

K

O

P

3 - 3i

4

L

The adjoint of a matrix is the transpose of the complex conjugate of the

matrix. You denote an adjoint by adding an asterisk (\*) to the name of

the matrix. Here’s what **A** looks like:

\*

J

N

1

3 - 3i

**A\***= K

O

K

O

P

2 - 2i

4

L

Mastering Matrix Operations

After you’re familiar with the basics of matrices, you can take the next step

and start working with a variety of matrix operations, such as addition, sub-

traction, multiplication, and other fun stuff. I explain what you need to know

in the following sections.

Equality

Two matrices are considered equal if every element in the first matrix is

equal to the corresponding element in the other matrix. For instance, if:

J

N

O

P

1

3

2

4

**A** = K

O

K

L

And:

J

N

O

P

1

3

2

4

**B** = K

O

K

L

then **A** = **B**. Easy enough, right?





270

**Part III: The Power Stuff: Advanced Techniques**

Addition

If you need to, you can add two matrices together. Doing so involves adding

the elements at corresponding positions in the two matrices. For example, if:

J

N

O

P

J

N

O

P

1

3

2

4

5

7

6

8

**A** = K

O and **B** = K

O

K

K

L

L

then:

J

N

O

P

J

N

O

P

J

N

8

1

2

4

5

7

6

8

6

**A** + **B** = K

O+ K

O= K

O

K

K

K

O

3

10 12

L

L

L

P

And just so you know: **A** + **B** = **B** + **A**.

Subtraction

Like matrix addition, matrix subtraction works as you’d expect: element by

element. For example, take a look:

J

N

O

P

J

N

O

P

J

N

1

3

2

4

5

7

6

8

-4 -4

-4 -4

**A** - **B** = K

O- K

O= K

O

K

K

K

O

P

L

L

L

Note that **A** – **B** doesn’t equal **B** – **A.** In fact, as you’d expect, **A** – **B** = –(**B** – **A**),

as you can see here:

J

N

O

P

J

N

O

P

J

N

O

P

5

7

6

8

1

3

2

4

4

4

4

4

**B** - **A** = K

O- K

O= K

O

K

K

K

L

L

L

Multiplication of a matrix and a number

In some cases, you need to multiply a matrix by a number; to do so, you multi-

ply each element in the matrix by that number. For example, 4**A** looks like this:

J

N

O

P

J

N

8

1

3

2

4

4

4**A** = 4 K

O= K

O

K

K

O

12 16

L

L

P

Multiplication of two matrices

How about multiplying two matrices together, such as **A** and **B**? Unfortunately,

this is a little more involved than just adding them. It turns out that **AB** is

defined when the number of columns in **A** is the same as the number of rows in

**B**. That is, if **A** is an l × m matrix (that’s row × column notation, so **A** has l rows





271

**Chapter 12: Tackling Systems of First Order Linear Differential Equations**

and m columns) and **B** is an m × n matrix, the product **AB** exists — and the

product is an l × n matrix.

If **AB** = **C**, here’s how it works: the (i, j) (that’s row, column) element of **C** is

found by multiplying each element of the ith row of **A** by the matching ele-

ment in the jth column of **B**. Then when you add the products you get:

!

m

C ij =

A B = A B + A B + A B + . . . + A B

ik kj i1 1j i2 2j i3 3j im mj

k = 1

Now put in the numbers:

J

N J

N

O

P

1

3

2

4

5

7

6

8

**AB** = K

O K

O K

O

K

L

P L

Applying the rules of multiplying matrices, you get:

J

N J

N

J

N

J

N

1

3

2

4

5

7

6

8

5 + 14 6 + 16

15 + 28 18 + 32

19 22

O

43 50

**AB** = K

O K

O K

O= K

O= K

O

K

O

K

O

K

L

P L

P

L

P

L

P

One thing to note is that in general, **AB** ≠ **BA**. Using the same example, here’s

what **BA** looks like:

J

N J

N

O

P

J

N

J

N

O

P

5

7

6

8

1

3

2

4

5 + 18 10 + 24

7 + 24 14 + 32

23 34

31 46

**BA** = K

O K

O= K

O= K

O

K

O K

K

O

P

K

L

P L

L

L

Multiplication of a matrix and a vector

You’ll often see matrices that only have one set of rows or one set of

columns. These matrices are called vectors. For example, here’s a vector with

one column:

J N

1

K O

K2O

K O

K O

3

L P

Here’s a vector with one row:

\_

i

1 2

3

Sometimes you’ll see vectors that are used to hold variables, as in this one,

which I’ll call **x**:

J N

x

K O

**x** = K yO

K O

K O

z

L P





272

**Part III: The Power Stuff: Advanced Techniques**

With vectors, you can express a set of simultaneous equations like this:

J

N J N J N

x 3

1

2

K

O K O K O

K3 4O K yO= K4O

K

O K O K O

O K O K O

K

5

6

z

5

L

P L P L P

This set of simultaneous equations can be written as:

**Ax** = **b**

Identity

The identity matrix, which is labeled **I**, holds 1s along its upper-left to lower-

right diagonal, and all 0s otherwise. Here’s a 2 × 2 identity matrix (with 2 rows

and 2 columns):

J

N

O

P

1

0

0

1

**I** = K

O

K

L

And here’s a 3 × 3 identity matrix (with 3 rows and 3 columns):

J

N

0

1

0

1

0

K

O

**I** = K0

0O

K

O

K

O

P

0

1

L

Multiplying any matrix, **A**, by the identity matrix gives you **A** again. (I explain

how to multiply two matrices together earlier in this chapter.) For example,

take a look at the multiplication of a matrix called **A** and the 3 × 3 identity

matrix:

J

N J

N

J

N

3

1

2

5

8

3

1

0

1

0

0

1

2

5

8

K

O K

6O K0

O

K

O

**AI** = K4

0O= K4

6O

K

O K

O

K

O

K

O K

O

P

K

O

P

7

9

0

1

7

9

L

P L

L

The inverse of a matrix

If you have simultaneous equations such as these:

x + y + z = 6

x – y – z = –4

x + y – z = 0





273

**Chapter 12: Tackling Systems of First Order Linear Differential Equations**

you can write a system in matrix form like this:

J

N J N

J

N

6

1

1

1

x

K

O K O

K

O

K1 -1 -1O K yO= K-4O

K

O K O

O K O

K

O

K

K

O

P

1

1

-1

z

0

L

P L P

L

You can further simplify this so that it looks like:

**Ax** = **b**

where:

J

N

1

1

1

K

O

**A** = K1 -1 -1O

K

L

O

K

O

1

1 -1

P

J N

x

K O

**x** = K yO

K O

K O

z

L P

J

N

6

K

O

**b** = K-4O

K

L

O

K

O

P

0

Wouldn’t it be nice if you could solve for **x** by some way dividing **Ax** = **b** by **A**

to get the following:

**x** = **A**–1

**b**

Doing so would give you the solutions, x, y, and z, to your simultaneous equa-

tions. So can you find **A**–1? Yes, you sure can! This is called the inverse of **A**

(and **A–**1 **A** = **I**, where **I** is the identity matrix). So how do you find the inverse

of a matrix? You can choose from several ways, but the easiest is the one that

I present in the following sections.

Generally, to find the inverse of a matrix **A**, apply the steps to **A** in order to

reduce it to the identity matrix **I** (that is, 1s along the upper-left to lower-right

diagonal and 0s otherwise). Then apply those same steps, in the same order,

to the identity matrix. You should end up with **A**–1. To wrap up, simply solve

for **x** by multiplying **A–**1 and **b**.

Before I can explain how to find an inverse, I need to cover an important con-

cept that’s helpful when you’re working with inverses: determinants. Read on

for details.





274

**Part III: The Power Stuff: Advanced Techniques**

Finding the determinant of a matrix

An important quantity when it comes to matrices is the determinant. The

determinant reduces a matrix to a single significant number; whether that

number is zero is important for inverses as well as other calculations. For

example, when checking to see whether the solutions you get to a system of

linear differential equations are linearly independent (and form a general

solution), you need to use determinants. (I discuss linear independence in

more detail later in this chapter.)

So how do you find a matrix’s determinant? Here’s an example that can show

you how. Say you have this 2 × 2 matrix, called **A**:

J

N

O

P

a

c

b

d

**A** = K

O

K

L

The determinant of **A**, written as det(**A**), for a 2 × 2 matrix is defined this way:

det(**A**) = ad – cb

For example, here’s a 2 × 2 matrix with some specific numbers:

J

N

O

P

1

3

2

4

**A** = K

O

K

L

What’s its determinant? Just plug the numbers into ad – cb, like so:

det(**A**) = (1)(4) – (3)(2) = –2

How about a 3 × 3 determinant? Say you have this 3 × 3 matrix **A**:

J

N

c

a

b

e

h

K

O

**A** = Kd

f O

K

O

K

O

P

g

i

L

Be careful here! Determinants rapidly become more complex beyond 2 × 2.

Here’s what the determinant of the 3 × 3 matrix is:

det(**A**) = aei – afh – bdi + cdh + bfg – ceg

Finding the inverse of a matrix

To find the inverse of a matrix **A**, apply the steps you need to **A** to reduce it

to the identity matrix, **I** (that is, 1s along the upper-left to lower right diagonal

and 0s otherwise). Then apply those same steps, in the same order, to an

identity matrix, and you’ll end up with **A**–1

.





275

**Chapter 12: Tackling Systems of First Order Linear Differential Equations**

Take a look at an example. For this system of equations:

x + y + z = 6

x – y – z = –4

x + y – z = 0

matrix **A** looks like this:

J

N

1

1

1

K

O

**A** = K1 -1 -1O

K

L

O

K

O

1

1 -1

P

Find **A**–1 by first reducing **A** to **I**. To do so, add –1 times the first row to the

third row and place the result in the third row:

J

N

1

1

1

K

O

K 1 -1 -1O

K

O

K

O

0

0 -2

L

P

Now divide the third row by –2 to simplify:

J

N

1

1

1

K

O

K 1 -1 -1O

K

O

K

O

P

0

0

1

L

Add the second row to the first row and place the result in the first row:

J

N

0

2

0

K

O

K 1 -1 -1O

K

O

K

O

P

0

0

1

L

Next, divide the first row by 2 to simplify:

J

N

0

1

0

K

O

K 1 -1 -1O

K

O

K

O

P

0

0

1

L

You’re looking good. Now add –1 times the first row to the second row and

place the result in the second row:

J

N

0

1

0

K

O

K0 -1 -1O

K

O

K

O

P

0

0

1

L





276

**Part III: The Power Stuff: Advanced Techniques**

Almost there. Add the third row to the second row and place the result in the

second row:

J

N

0 0

1

K

O

K0 -1 0O

K

O

K

O

P

0

0 1

L

Finally, multiply the second row by –1 to get that final 1:

J

N

0

1

0

1

0

K

O

K0

0O

K

O

K

O

P

0

1

L

And there you have it — the identity matrix.

After you reduce a system to the identity matrix, you have to apply the same

sequence of steps to the identity matrix to find **A**–1. Here’s the 3 × 3 identity

matrix:

J

N

0

1

0

1

0

K

O

**I** = K0

0O

K

O

K

O

P

0

1

L

Now follow the same steps that you followed earlier in this section. First, add

–1 times the first row to the third row and place the result in the third row:

J

N

1 0

0

K

O

K 0 1 0O

K

O

K

O

-1 0

1

L

P

Divide the third row by –2:

J

N

1

0

1

0

0

K

O

K 0

0 O

K

O

K

O

1

\-

1

2

2

L

P

Next, add the second row to the first row and place the result in the first row:

J

N

1

1

1

0

0

K

O

K 0

0 O

K

O

K

O

1

\-

1

2

2

L

P

Divide the first row by 2:

J

N

1

1

0

K

2

2

O

K 0

1

0 O

K

O

K

O

1

0

\-

1

2

2

L

P





277

**Chapter 12: Tackling Systems of First Order Linear Differential Equations**

And add –1 times the first row to the second row and place the result in the

second row:

J

N

1

1

1

0

0

K

2

2

O

K

O

\-

1

2

2

K

O

K

O

P

1

0

\-

1

2

2

L

Now add the third row to the second row, placing the result in the second row:

J

N

1

1

1

0

K

2

2

O

K 0

O

\-

1

2

2

2

K

O

K

O

P

1

0

\-

1

2

L

Finally, multiply the second row by –1:

J

N

1

1

0

K

2

2

O

K 0

O

2

\-

1

1

2

K

O

K

O

P

1

0

\-

1

2

2

L

And there you have it: **A**–1

.

Solving for x with a little multiplication

Now you have to find **x**, the solution to your system of equations, by using the

equation **x** = **A**–1**b**. Your equation looks like this when you fill in the numbers:

J N

J

NJ

N

6

x

1

1

0

K O

K yO= K 0

K O

K

2

2

OK

O

OK-4O

\-

1

1

2

2

K

OK

OK

O

K O

K

1

1

O

P

z

0

\-

0

L P

L

2

2

PL

Performing matrix multiplication (as I describe earlier in this chapter)

gives you:

J N J N

x

1

K O K O

K yO= K2O

K O K O

K O K O

z

3

L P L P

Voila! It worked. You found the solution to your simultaneous equations by

finding the inverse of a matrix.

Does solving for **x** always work? The answer is a resounding no. Why?

Sometimes matrices can’t be inverted (in which case they’re called singular,

or non-invertable, matrices).





278

**Part III: The Power Stuff: Advanced Techniques**

How can you tell if a matrix is singular before attempting to find its inverse?

You can check to see whether its determinant is zero. Matrices whose deter-

minants are zero are singular matrices without an inverse; matrices whose

determinants aren’t zero do have an inverse. In the original matrix in my

example, the determinant is:

det(**A**) = aei – afh – bdi + cdh + bfg – ceg

Having Fun with Eigenvectors ’n’ Things

You’re now ready for more insight into matrices using eigenvectors and

eigenvalues. What are those? Read on to find out more.

Linear independence

Determining whether a set of vectors is linearly dependent can be quite

important. It’s especially important when you’re solving systems of linear dif-

ferential equations to see whether you have linearly independent solutions.

You need to get a linearly independent set of solutions to make sure you have

the complete solution.

Say, for example, that you have a set of vectors, **x** to **x** . They’re said to be

1

k

linearly dependent if there are constants, c to c , such that:

1

k

c **x** + c **x** + . . . c **x** = **0**

1

1

2

2

k k

where **0** is a vector whose elements are all zero. In other words, **x** to **x** are

1

k

considered linearly dependent if a linear relation relates them. If there are no

constants, c to c (not all zero), such that this equation holds, the vectors, **x**

1

k

1

to **x** , are linearly independent.

k

How do you determine whether a set of vectors, **x** to **x** , is linearly indepen-

1

k

dent? You can assemble all the vectors, **x** to **x** , into a single matrix and then

1

k

check the determinant. If the determinant is zero, the vectors are linearly

dependent. If the determinant isn’t zero, the vectors are linearly independent.

I walk you through an example in the following sections.

Assembling the vectors into one matrix

Say that you have the following vectors:

J

N

2

K

O

**x** = K 4O

1

K

O

K

O

-2

L

P





279

**Chapter 12: Tackling Systems of First Order Linear Differential Equations**

J N

2

K O

**x** = K1O

2

K O

L P

K O

3

J

N

-8

K

O

**x** = K 2O

3

K

O

K

O

-22

L

P

Now you can assemble these vectors into a 3 × 3 matrix called **x**:

J

N

2

2

1

3

-8

K

O

**x** = K 4

2O

K

O

K

O

-2

-22

L

P

Determining the determinant

Okay, so now you have to figure out whether the determinant of **x** is zero. As

discussed earlier in this chapter, the determinant of a 3 × 3 matrix **A**:

J

N

c

a

b

e

h

K

O

**A** = Kd

f O

K

O

K

O

P

g

i

L

is the following:

det(**A**) = aei – afh – bdi + cdh + bfg – ceg

So the determinant of **x** in my example is:

(2)(1)(–22) – (2)(2)(3) – (2)(4)(–22) + (–8)(4)(3) + (2)(2)(–2) – (–8)(1)(–2)

which becomes:

–44 – 12 + 176 – 96 – 8 – 16 = 0

As you can see, the determinant in this case is zero. Uh-oh. That’s no good.

The determinant is zero, which means that **x** , **x** , and **x** are linearly depen-

1

2

3

dent. What should you do next? Remember the following:

c **x** + c **x** + . . . c **x** = 0

1

1

2

2

k k





280

**Part III: The Power Stuff: Advanced Techniques**

What are c , c , and c ? You can figure out those constants by solving the aug-

1

2

3

mented matrix. Here’s your matrix:

J

N

2

2

1

3

-8

K

O

K 4

2O

K

O

K

O

-2

-22

L

P

Add the first row to the third row and place the result in the third row:

J

N J N

0

2

2

1

5

-8

K

O K O

K4

2O K0O

K

O K O

O K O

K

0

-30

0

L

P L P

Next, divide the first row by 2 to simplify:

J

N J N

0

1

1

1

5

-4

K

O K O

K4

2O K0O

K

O K O

O K O

K

0

-30

0

L

P L P

Now add –4 times the first row to the second row (to get a zero in the first

position of Row 2). Place the result in the second row:

J

N J N

0

1

1

-4

K

O K O

18O K0O

O K O

K0 -3

K

K

O K O

0

0

5

-30

L

P L P

Divide the second row by –3 to simplify:

J

N J N

0

1

1

1

5

-4

K

O K O

-6O K0O

O K O

K0

K

K

O K O

0

0

-30

L

P L P

Add –5 times the second row to the third, and then place the result in the

third row:

J

N J N

0

1

1

1

0

-4

K

O K O

-6O K0O

O K O

K0

K

K

O K O

0

0

0

L

P L P

This matrix corresponds to a system of these two equations:

c + c – 4c = 0

1

2

3

c – 6c = 0

2

3





281

**Chapter 12: Tackling Systems of First Order Linear Differential Equations**

You can choose one of these constants arbitrarily. So, just for kicks, set c3 = 1.

If you plug this constant into the previous two equations and do a little alge-

bra, you’ll find that c = 6 and c = –2.

2

1

Putting it all together

Now it’s time to assemble your constants and your vectors so you can check

your work. So:

J

N

J N

J

N

2

2

-8

K

O

K O

K

O

c K 4O+ c K1O+ c K 2O

1

K

O

2

3

K

O

K O

K

O

P

K O

K

O

P

-2

3

-22

L

L P

L

becomes:

J

N

J N

J

N

J N

2

2

-8

0

K

O

K O

K

O

K O

K O

-2 4 + 6 K1O+

K

O

K

2 = 0

O

K

O

K O

K

O

K O

K O

K

O

K O

K

O

-2

3

-22

0

L

P

L P

L

P

L P

As you can see, you’ve determined c , c , and c correctly.

1

2

3

Eigenvalues and eigenvectors

Take a look at this vector equation:

**Ax** = **y**

When facing problems like this, it sometimes helps to consider **A** in a form

where a linear transformation converts **x** into **y**. That is, you want to look for

solutions of the following form:

**Ax** = λ**x**

In this case, λ stands for a constant. You can rewrite this equation as:

(**A** – λ**I**)**x** = 0

This equation has a solution only if (**A –** λ**I**)–1 exists. In other words, you can

be assured of a solution if:

det(**A** – λ**I**) ≠ 0

Any values of λ that satisfy (**A** – λ**I**) **x** = 0 are called eigenvalues of the original

equation. And the solutions **x** to (**A** – λ**I**) **x** = 0 are called the eigenvectors.

You can see how eigenvalues and eigenvectors work in the example that I go

through in the following sections.





282

**Part III: The Power Stuff: Advanced Techniques**

Changing the matrix to the right form

Here’s an example you can wrap your brain around: Try finding the eigenval-

ues and eigenvectors of the following matrix:

J

N

-1 -1

**A** = K

O

K

O

P

2

-4

L

First, convert the matrix into the **A** – λ**I** form. Doing so gives you:

J

-1 -λ -1

N

**A** - λ**I** =

K

O

K

-4 -λ

O

P

2

L

Figuring out the eigenvalues

Next, it’s time to find the determinant:

det(**A** – λ**I**) = (–1 – λ)(–4 – λ) + 2

or:

det(**A** – λ**I**) = λ

which can be factored into the following:

det(**A** – λ**I**) = λ +5λ +6 = (λ + 2)(λ + 3)

So, by equating this equation to 0, the eigenvalues of **A** are λ = –2 and λ = –3.

2

\+ 5λ + 6

2

1

2

Calculating the eigenvectors

How about finding the eigenvectors of **A**? To find the eigenvector correspond-

ing to λ , you have to substitute λ (–2) into the **A** – λ**I** matrix, like so:

1

1

J

N

1

2

-1

-2

**A** - λ**I** = K

O

K

O

P

L

Because (**A** – λ**I**)**x** = 0, you have:

J

N J

N J N

0

1

2

-1

x

x

K

O K

1

2

O

K O

\=

K

O K

O

K O

-2

0

L

P L

P

L P

And, because every row of this matrix equation must be true, you can

assume that x = x . So, up to an arbitrary constant, the eigenvector corre-

1

2

sponding to λ is:

1

J N

1

c K O

K O

1

L P





283

**Chapter 12: Tackling Systems of First Order Linear Differential Equations**

You can also drop the arbitrary constant, and write this eigenvector as:

J N

1

K O

K O

1

L P

How about the eigenvector corresponding to λ ? By plugging λ (–3) into the

2

2

**A** – λ**I** matrix, you get:

J

N

2

2

-1

-1

**A** - λ**I** = K

O

K

O

P

L

Then you have the following:

J

N J

N J N

0

2

2

-1

x

x

K

O K

1

2

O

K O

\=

K

O K

-1

O

K O

0

L

P L

P

L P

So 2x – x = 0 and x = x /2. This means that up to an arbitrary constant, the

1

2

1

2

eigenvector corresponding to λ is:

2

J N

1

c K O

K O

2

L P

Again, you can drop the arbitrary constant, and simply write this

eigenvector as:

J N

1

K O

K O

2

L P

Solving Systems of First-Order Linear

Homogeneous Differential Equations

You’ve likely discovered how to work with systems of linear equations in

algebra classes. If so, you’re in luck because working with systems of linear

differential equations follows the same techniques. In the following sections,

I give you a good look at systems of first order linear homogeneous differen-

tial equations with constant coefficients like this:

x ' = x + x

2

1

1

x ' = 4x + x

2

2

1

These differential equations are linked — that is, both contain x and x . As

1

2

such, they have to be solved together. (Flip to Chapter 5 for an introduction

to working with constant coefficients in homogeneous equations.) I show you

how in the following sections.





284

**Part III: The Power Stuff: Advanced Techniques**

Understanding the basics

You can write a set of equations such as x ' = x + x and x ' = 4x + x in this

1

1

2

2

1

2

matrix form:

J

N

J

N J

N

xl

1 1

4 1

x

x

K

1

O

K

O K

1

2

O

\=

K

O

P

K

O K

O

P

xl

2

L

L

P L

Or, shorter still, you can write the matrix like this:

**x**' = **Ax**

Here, **x**', **A**, and **x** are all matrices:

J

N

xl

K

1

O

**x**l=

K

O

P

xl

2

L

J

N

O

P

1 1

4 1

**A** = K

O

K

L

J

N

x

K

1

2

O

**x** =

K

O

P

x

L

If **A** is a matrix of constant coefficients, you can assume a solution of the fol-

lowing form:

**x** = ξert

Okay, you say, what’s that funny squiggle (ξ) doing there? Actually, it’s the

Greek letter xi in lowercase form. It couldn’t possibly stand for eigenvector,

could it? You’re right! You’re way ahead of me.

Substituting your supposed form of solution, **x** = ξert, into the system of differ-

ential equations, **x**' = **Ax**, gives you:

rξert = **A**ξert

where r is a constant. Do you see how using matrix notation makes working

with systems of differential equations easier? Now you can subtract **A**ξert

from both sides of the equation and do a little rearranging to get:

(**A** – r**I**)ξert = 0

or:

(**A** – r**I**)ξ = 0





285

**Chapter 12: Tackling Systems of First Order Linear Differential Equations**

As you may recall from the earlier section on eigenvalues and eigenvectors,

this is exactly the equation that specifies the eigenvalues and eigenvectors of

the matrix **A**. So the solution to the system of differential equations, **x**' = **Ax**,

is **x** = ξert (provided that r is an eigenvalue of **A** and ξ is the associated

eigenvector).

Making your way through an example

Now take a closer look at the example I give in the previous section:

J

N

J

N J

N

xl = 1 1

x

x

K

1

O

K

O K

1

2

O

K

O

K

O K

O

P

xl = 4 1

L

2

P

L

P L

Because this matrix has constant coefficients, you can try a solution of the

following form:

**x** = ξert

I walk you through the steps of solving this system in the following sections.

Getting the right matrix form

The next step you have to tackle is substituting **x** = ξert into the matrix, which

gives you:

J

N

J

N J

N

ξ1 ert

r ξ1 ert = 1 1

K

O

K

O K

O

K

r ξ2 ert = 4 1

O

K

O K

ξ2 ert

O

L

P

L

P L

P

By subtracting the left side from both sides of the equation, you can rewrite

this as:

J N

J

N J N

ξ1 ert

0 = 1 - r

1

K O

K O

K

O K

O

K

O K

O

0 =

L P

4

1 - r

ξ2 ert

L

P L

P

Dividing by ert gives you:

J N

J

N J

ξ1

N

0 = 1 - r

1

K O

K O

K

O K

O

K

O K

ξ

O

P

0 =

L P

4

1 - r

L

P L

2

Finding the eigenvalues

This system of linear equations has a solution only if the determinant of the

2 × 2 matrix is zero (see the earlier section “Linear independence” for

details). So:

J

N

1 - r

1

K

O

det

= 0

K

O

P

4

1 - r

L





286

**Part III: The Power Stuff: Advanced Techniques**

After expanding, your equation looks like this:

(1 – r)(1 – r) – 4 = 0

which becomes:

r

2

– 2r + 1 – 4 = 0

Or, with some simplification:

– 2r – 3 = 0

r

2

Finally, you can factor this into:

(r – 3)(r + 1) = 0

So the eigenvalues of your 2 × 2 matrix are:

r1 = 3

and

r2 = –1

Coming up with the eigenvectors

After you find the eigenvalues, you need to find the two eigenvectors.

Plugging the first eigenvalue from the previous section, r1 = 3, into the matrix

yields this result:

J N

J

N J

ξ1

N

0 = -2

1

K O

K O

K

O K

O

K

O K

ξ

O

P

0 =

L P

4

-2

L

P L

2

With some simplification you get:

–2ξ + ξ = 0

1

2

and:

4ξ – 2ξ = 0

1

2

These equations are the same up to a factor of –2. So you get:

2ξ1 = ξ2





287

**Chapter 12: Tackling Systems of First Order Linear Differential Equations**

The first eigenvector is (up to, as usual, an arbitrary nonzero constant that

doesn’t matter):

Jξ N J1N

K

1

O

P

K O

L P

\=

Kξ O K2O

L

2

How about the second eigenvector? It corresponds to the eigenvalue r2 = –1.

So plugging that into the matrix gives you:

J N

J

N J

ξ1

N

0 = 2

1

2

K O

K O

K

O K

O

K

O K

O

P

0 = 4

ξ

L P

L

P L

2

After simplification you get:

2ξ + ξ = 0

1

2

and:

4ξ + 2ξ = 0

1

2

These equations give you the same information as with the first eigenvector:

2ξ1 = – ξ2

So the second eigenvector becomes:

Jξ N J 1N

\-

K

1

O

K

O

P

\=

Kξ O K 2O

L

2

P

L

Summing up the solution

The first solution to the original system of differential equations, based on

the first eigenvector and eigenvalue, is:

J N

1

**x** = K Oe3t

K O

1

2

L P

The second solution, based on the second eigenvector and eigenvalue, is:

J

N

-1

**x** = K Oe- t

K

O

2

2

L

P

The general solution to this system is a linear combination of these two solu-

tions (c **x** + c **x** ), which in this example looks like:

1

1

2 2

J N

J

N

-1

1

**x** = c K Oe3t + c K Oe- t

K O

K

O

1

2

2

2

L P

L

P





288

**Part III: The Power Stuff: Advanced Techniques**

The solution can also be written as:

J

N

J N

J

N

\-

1

x

x

1

K

1

2

O

K O

K

O

= c

e

3t + c

e

\- t

K

O

P

K O

K

O

1

2

2

2

L

L P

L

P

By splitting up this equation, the solutions to the system of differential equa-

tions become:

x = c e3t – c2 e–t

1

1

and

x = 2c e3t + 2c2 e–t

2

1

That example wasn’t so bad, was it?

Solving Systems of First Order Linear

Nonhomogeneous Equations

Now I want you to turn your attention to systems of first order linear nonho-

mogeneous differential equations. I show you how to solve this system of

homogeneous differential equations in the previous section:

J

N

J

N J

N

xl = 1 1

x

x

K

1

O

K

O K

1

2

O

K

O

K

O K

O

P

xl = 4 1

L

2

P

L

P L

But what if the situation was changed to this:

J

N

J

N J

N

J

N

O

P

xl = 1 1

x

x

2e

3t

\- t

\-

K

1

O

K

O K

1

2

O

K

O

\+

K

O

K

O K

O

P

K

xl = 4 1

L

2

P

L

P L

L

The solution to the nonhomogeneous system is the general solution of the

homogeneous version of the system (which you already have from the previ-

ous section) plus a particular solution.

In the following sections, I show you how to assume the form of the solution

and determine the missing coefficients — all in a way entirely analogous to

the method of undetermined coefficients in linear nonhomogeneous differen-

tial equations (see Chapter 6 for an introduction to this method).





289

**Chapter 12: Tackling Systems of First Order Linear Differential Equations**

Assuming the correct form

of the particular solution

So how can you find a particular solution to a nonhomogeneous system?

Easy: By using the method of undetermined coefficients after it has been gen-

eralized to work with matrices. To do that, rewrite the system like this:

J

N

J

N J

N

J

N

O

P

J

N

O

P

xl = 1 1

x

x

2e

\- t

0

\-

K

1

O

K

O K

1

2

O

K

O

K

O

\+

\+

K

O

K

O K

O

P

K

K

xl = 4 1

0

3t

L

2

P

L

P L

L

L

It’s clear that the last two terms in this system involve terms in e–t and t, so

can you assume a solution of the following form?

**x** = **a**e–t + **b**t + **c**

Well, not so fast. As you may recall from the previous section, the eigenvalue

of the general solution to the homogenous equation here was –1. So there’s

already a e–t term in the general solution.

What do you do in cases like this? You do just what you would do for a single

differential equation — you have to add a term in te–t. That makes your

assumed solution look like this:

**x** = **a**te–t + **b**e–t + **c**t + **d**

Here’s what your system of differential equations looks like currently:

J-2e- t

N

O

P

J

N

O

P

0

**x** = **A** x + K

O+ K

O

K

K

0

3t

L

L

Plugging **x** = **a**te–t + **b**e–t + **c**t + **d** into this system gives you:

J-2e- t

N

O

P

J

N

O

P

0

**a**e- t - **a**te- t - **b**e- t + **c** = **Aa**te- t + **Ab**e- t + **Ac**t + **Ad** + K

O+ K

O

K

K

0

3t

L

L

And equating coefficients on the two sides gives you these results:

**Aa** = –**a**

J

N

O

P

-2

**Ab** = **a** - **b** - K

O

K

0

L

J N

0

**Ac** =- K O

K O

3

L P

**Ad** = **c**





290

**Part III: The Power Stuff: Advanced Techniques**

Crunching the numbers

After assuming the correct form of your solution, you’re ready to do the

math. In the following sections, I explain how to calculate all your missing

coefficients. Remember that **A** is the following:

J

N

O

P

1 1

4 1

**A** = K

O

K

L

Finding a

When you start calculating the missing coefficients, why not start with find-

ing **a**? In this case, **Aa** = –**a** becomes:

J

NJ

N

J

N

1 1 a1

a1

K

OK

O

K

O

= -

K

OK

4 1

O

P

K

O

P

a

a

L

PL

2

L

2

Or, in simpler terms:

a + a = – a

1

1

2

and:

4a + a = – a

2

1

2

These can be rewritten even more simply as:

2a1 = –a2

and:

4a1 = –2a2

These equations differ by a factor of 2. Because you’re only interested in a

single particular solution, go with a = –1 and a = 2, which gives you:

1

2

J

N

-1

**a** = K

O

K

O

2

L

P

Finding b

Now find **b**. You already know the following:

J

N

O

P

-2

**Ab** = **a** - **b** - K

O

K

0

L





291

**Chapter 12: Tackling Systems of First Order Linear Differential Equations**

So after plugging in your solution for **a**, you get:

J

N

J

N

J

N

J

N

O

P

b1 + b

2

1

b1

2

0

\-

\-

K

O

K

O

K

O

K

O

\=

\-

\-

K

O

P

K

O

K

O

P

K

4b1 + b

2

2

b

2

L

L

P

L

L

Or, more simply:

2b + b = 1

1

2

and

4b + 2b = 2

1

2

A solution to these equations (which only differ by a factor of 2) is:

J

N

1

**b** = K

O

K

O

-1

P

L

Finding c

Ready to find c? You already know the following:

J N

0

**Ac** = -K O

K O

3

L P

So in other words, you get:

J

N J

N

J N

0

1 1

4 1

c

c

K

O K

1

2

O

K O

= -

K

O K

O

P

K O

3

L

P L

L P

Here’s what you get after simplifying:

c + c = 0

1

2

and:

4c + c = –3

1

2

The solution to these equations, after a little number crunching, is:

J

N

-1

**c** = K

O

K

O

1

L

P





292

**Part III: The Power Stuff: Advanced Techniques**

Finding d

Finally you just have to find **d**. You know that **Ad = c**. In other words, by plug-

ging in your solution for **c** you get:

d + d = –1

1

2

and:

4d + d = 1

1

2

So the solution to this pair of equations is:

J

N

2

3

**d** = K

O

K

O

P

\-

5

3

L

Winding up your work

After going through the previous sections and assuming a form of the solu-

tion and crunching the numbers, you just have to put the work together to

get a particular solution to your original system. That particular solution is:

J

N

J

N

J

N

J

N

O

P

J

N

3

x

x

1

1

1

1

2

\-

\-

K

1

2

O

K

O

K

O

K

O

K

O

x =

\=

te- t

\+

e

\- t

\+

t +

K

O

P

K

O

K

O

-1

P

K

K

O

P

2

\-

5

3

L

L

P

L

L

L





**Chapter 13**

**Discovering Three Fail-Proof**

**Numerical Methods**

In This Chapter

` `Brushing up on the Euler method

` `Taking it to the next level with the improved Euler method

` `Getting great results with the Runge-Kutta method

A

group of elite computer scientists shuffles into your office with a prob-

lem: “We’re not comfortable writing software that solves differential

equations. Isn’t there an easier, more computer-friendly way of handling

differential equations?”

“Well,” you say, “you can use the method of undetermined coefficients and

then solve for . . .”

“Solve for?” the group asks. “You mean using variables? No, no — we want

something numeric.”

“Ah,” you tell them. “You want methods like Euler’s method and the Runge-

Kutta method.” You show them some programming code.

“That’s it!” the group cries, grabbing your code and running off.

“My bill,” you call after them, “will be in the mail.”

“Better use e-mail,” cries a junior member, disappearing around the corner.

Differential equations can stump even the best and brightest, but I have a

secret weapon for you: numerical methods. This chapter is all about the

computer-based methods that you can use to solve differential equations

when everything else fails. Do remember that you’ll get numbers out of these

techniques, not elegant, finished formulas. But sometimes, numbers are just

what you want, as is often the case in engineering.





294

**Part III: The Power Stuff: Advanced Techniques**

In this chapter, I use the Java programming language, so if you want to follow

along, you need to install Java on your computer. It’s free when you visit

java.sun.com. When you’re at the Web site, simply click the Java SE link and

download and install the Java Development Kit, or JDK.

Number Crunching with Euler’s Method

Euler’s method, which I introduce in Chapter 4, allows you to handle differen-

tial equations in a numeric way. In the following sections, I explain the basics

of the method, and then I show you how to enter code into your computer so

you can see the method in action.

The fundamentals of the method

Take a look at this differential equation:

dy

dx

\_

i

= f x,y

The standard Euler’s method notes that you may not have the actual function

that represents the solution to your differential equation. However, when

you’re armed with the preceding equation, you do have the slope of that

curve everywhere. That is, the rate of change of the curve is the derivative.

(See Chapter 1 for a refresher on derivatives.)

Say that you have a point, (x , y ), that’s on the solution curve. Because of

0

0

the preceding equation, you know that the slope of the solution curve at that

point is f(x , y ). Suppose that you also want to find the numeric solution at

0

0

a point, (x, y), a short distance, h, away. Here’s how Euler’s method says that

you may find y:

y = y0 + ∆y

In other words, y is equal to y at an initial point, plus the change in y.

Because the slope, m, is defined as ∆y/∆x (a change in y divided by a change

in x), this equation also can be written like this:

y = y0 + m ∆x

And because ∆x = x – x0, this equation is also:

y = y + m (x – x )

0

0





295

**Chapter 13: Discovering Three Fail-Proof Numerical Methods**

Here’s the key: The slope m is equal to the derivative at (x , y ), and because

0

0

of your original differential equation, you know that m = f(x , y ). So you have:

0

0

y = y + f(x , y ) (x – x )

0

0

0

0

Now convert (x – x0) to the symbol that it usually goes by when you discuss

Euler’s method: h, which gives you this equation:

y = y + f(x , y ) h

1

0

0

0

This equation can be generalized to any point, (x , y ), along the solution

n

n

curve like this:

yn + 1 = y + f(x , y ) h

n

n

n

And there you have it — you’ve discovered the recurrence relation, which ties

one term to the next, for Euler’s equation. (Flip to Chapter 9 for an introduc-

tion to recurrence relations.)

Using code to see the method in action

Now try testing the basics from the previous section, using this differential

equation:

dy

dx

= x

where y(0) = 0.

I’ll spare you the details of solving this equation with traditional methods

(but you can head to Chapter 4 to find out how to do so). Without further

ado, here’s the exact solution:

x

2

y =

2

Because you know the exact solution, you can check the accuracy of Euler’s

method in Java code. The following sections show you how.

Typing in the code

In Chapter 4, I develop a short Java program, e.java, to display the results of

Euler’s method versus the exact solution. The code starts at (x , y ) = (0, 0),

0

0

which you know is on the solution curve because of the initial condition,

y(0) = 0. The code calculates 100 steps, using a step size of h = 0.1.





296

**Part III: The Power Stuff: Advanced Techniques**

If you want to follow along, start by using the Java compiler, javac.exe, to

compile e.java:

C:\>javac e.java

If javac.exe isn’t in your computer’s path, you have to specify that path this

way to run javac.exe:

C:\>C:\jdk\bin\javac e.java

After compiling e.java, you should get a new file, e.class. Now you can exe-

cute the compiled code, e.class, using java.exe like this:

C:\>java e

Here’s the code that you’re going to modify in this chapter (note that the

sections of the code that you have to change when you’re solving your own

differential equations are given in **bold**):

public class e

{

**double x0 = 0.0;**

**double y0 = 0.0;**

**double h = 0.1;**

**double n = 100;**

public e()

{

}

public double f(double x, double y)

{

**return x;**

}

public double exact(double x, double y)

{

**return x \* x / 2;**

}

public static void main(String [] argv)

{

e de = new e();

de.calculate();

}

public void calculate()

{





297

**Chapter 13: Discovering Three Fail-Proof Numerical Methods**

double x = x0;

double y = y0;

double k;

System.out.println(“x\t\tEuler\t\tExact”);

for (int i = 1; i < n; i++){

k = f(x, y);

y = y + h \* k;

x = x + h;

System.out.println(round(x) + “\t\t” + round(y) +

“\t\t” + round(exact(x, 0)));

}

}

public double round(double val)

{

double divider = 100;

val = val \* divider;

double temp = Math.round(val);

return (double)temp / divider;

}

}

Surveying the results

After being run, the code will display the current x value, the Euler approxi-

mation of the solution at that value, and the exact solution, like this:

C:\>java e

x

Euler

0.0

0.01

0.03

0.06

0.1

0.15

0.21

0.28

0.36

0.45

0.55

0.66

0.78

0.91

1.05

1.2

Exact

0.01

0.02

0.05

0.08

0.13

0.18

0.24

0.32

0.4

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1.0

1.1

1.2

1.3

1.4

1.5

1.6

1.7

1.8

0.5

0.6

0.72

0.85

0.98

1.13

1.28

1.45

1.62

1.36

1.53





298

**Part III: The Power Stuff: Advanced Techniques**

1.9

2.0

2.1

2.2

2.3

2.4

2.5

2.6

2.7

2.8

2.9

3.0

3.1

3.2

3.3

3.4

3.5

3.6

3.7

3.8

3.9

4.0

4.1

4.2

4.3

4.4

4.5

4.6

4.7

4.8

4.9

5.0

5.1

5.2

5.3

5.4

5.5

5.6

5.7

5.8

5.9

6.0

6.1

6.2

6.3

6.4

6.5

6.6

6.7

6.8

6.9

1.71

1.9

2.1

2.31

2.53

2.76

3.0

3.25

3.51

3.78

4.06

4.35

4.65

4.96

5.28

5.61

5.95

6.3

1.81

2.0

2.21

2.42

2.65

2.88

3.13

3.38

3.65

3.92

4.21

4.5

4.81

5.12

5.45

5.78

6.13

6.48

6.85

7.22

7.61

8.0

8.41

8.82

9.25

9.68

10.13

10.58

11.04

11.52

12.0

12.5

13.0

13.52

14.04

14.58

15.12

15.68

16.24

16.82

17.4

18.0

18.6

19.22

19.84

20.48

21.12

21.78

22.44

23.12

23.8

6.66

7.03

7.41

7.8

8.2

8.61

9.03

9.46

9.9

10.35

10.81

11.28

11.76

12.25

12.75

13.26

13.78

14.31

14.85

15.4

15.96

16.53

17.11

17.7

18.3

18.91

19.53

20.16

20.8

21.45

22.11

22.78

23.46





299

**Chapter 13: Discovering Three Fail-Proof Numerical Methods**

7.0

7.1

7.2

7.3

7.4

7.5

7.6

7.7

7.8

7.9

8.0

8.1

8.2

8.3

8.4

8.5

8.6

8.7

8.8

8.9

9.0

9.1

9.2

9.3

9.4

9.5

9.6

9.7

9.8

9.9

24.15

24.85

25.56

26.28

27.01

27.75

28.5

29.26

30.03

30.81

31.6

24.5

25.2

25.92

26.64

27.38

28.12

28.88

29.64

30.42

31.2

32.0

32.8

32.4

33.21

34.03

34.86

35.7

33.62

34.44

35.28

36.12

36.98

37.84

38.72

39.6

36.55

37.41

38.28

39.16

40.05

40.95

41.86

42.78

43.71

44.65

45.6

40.5

41.4

42.32

43.24

44.18

45.12

46.08

47.04

48.02

49.0

46.56

47.53

48.51

Not bad. Euler’s method came pretty close to the exact solution. In fact, at a

value of x = 9.9, Euler’s method is still within 1% of the exact solution.

Moving On Up with the Improved

Euler’s Method

As I explain in the earlier section “The fundamentals of the method,” the

recurrence relation for the Euler method is given by:

yn + 1 = y + f(x , y ) h

n

n

n

where the differential equation you’re trying to solve is:

dy

dx

\_

i

= f x,y





300

**Part III: The Power Stuff: Advanced Techniques**

This is a fairly simplistic method; it just extrapolates from the current point

to the next point using the known slope. What if the actual solution varies

faster than the Euler method takes into account?

Well, it turns out that an improved Euler method exists. This method, which

is also called the Heun formula, can be more accurate. I explain everything

you need to know in the following sections.

Understanding the improvements

The standard Euler method assumes that the difference between yn+1 and yn is:

∆y = f(xn) h

For simplicity’s sake, assume that f(x, y) is only a function of x, f(x).

This method doesn’t take into account possible steep increases — or

decreases — in the slope. A better solution would not only take the current

slope, f(xn), into account, but it also would take the slope at the next point

along the curve, f(xn + h), into account. You could then take the average of

those two slopes, like this:

~~\_~~

~~i~~

~~\_~~

~~i~~

f x + f x + h

m =

n

n

2

This is a better approximation than simply using the slope at xn, which the

standard Euler’s method does. Now you can multiply the average slope by

the interval length, h, to find the change in y:

9 \_

i

\_

iC

h

∆y = f x + f x + h

2

n

n

So you can express the recurrence relation for the (new and) improved

Euler’s method like this:

9 \_

i

\_

iC

h

y

= yn + f x + f x + h

n + 1

2

n

n

Coming up with new code

In this section, I show you how to create a new program, e2.java, that will put

the improved Euler method to work. The program will display the traditional

Euler result, the improved Euler result, and the exact result. To illustrate the

new code, I use the same equation from the earlier section “Using code to see

the method in action” in the following sections.





301

**Chapter 13: Discovering Three Fail-Proof Numerical Methods**

Changes in the new code

The code for the improved Euler’s method is different from the one in the earlier

section “Using code to see the method in action.” Here, you create a new vari-

able, yimp, in which you store the improved Euler results, and then you make

these changes to the calculate method (the **bold** indicates changes in the code):

public void calculate()

{

double x = x0;

double y = y0;

**double yimp = y0;**

double k;

**System.out.println(“x\t\tEuler\t\tImproved\t\tExact”);**

for (int i = 1; i < n; i++){

k = f(x, y);

y = y + h \* k;

**yimp = y + (f(x, y) + f(x + h, y))\* (h/2);**

x = x + h;

**System.out.println(round(x) + “\t\t” + round(y) +**

**“\t\t” + round(yimp) + “\t\t”**

**+ round(exact(x, 0)));**

}

}

Here’s what the program looks like now:

public class e2

{

double x0 = 0.0;

double y0 = 0.0;

double h = 0.1;

double n = 100;

public e2()

{

}

public double f(double x, double y)

{

return x;

}

public double exact(double x, double y)

{

return x \* x / 2;

}





302

**Part III: The Power Stuff: Advanced Techniques**

public static void main(String [] argv)

{

e2 de = new e2();

de.calculate();

}

public void calculate()

{

double x = x0;

double y = y0;

double yimp = y0;

double k;

System.out.println(“x\t\tEuler\t\tImproved\t\tExact”);

for (int i = 1; i < n; i++){

k = f(x, y);

y = y + h \* k;

yimp = y + (f(x, y) + f(x + h, y))\* (h/2);

x = x + h;

System.out.println(round(x) + “\t\t” + round(y) +

“\t\t” + round(yimp) + “\t\t”

\+ round(exact(x, 0)));

}

}

public double round(double val)

{

double divider = 100;

val = val \* divider;

double temp = Math.round(val);

return (double)temp / divider;

}

}

The results of the new code

So how does the code work out? Take a look:

C:\>java e2

x

Euler

0.0

0.01

0.03

0.06

0.1

0.15

0.21

0.28

0.36

0.45

Improved

0.01

0.03

0.06

0.1

0.15

0.21

0.28

0.36

0.45

0.55

Exact

0.01

0.02

0.05

0.08

0.13

0.18

0.24

0.32

0.4

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1.0

0.5





303

**Chapter 13: Discovering Three Fail-Proof Numerical Methods**

1.1

1.2

1.3

1.4

1.5

1.6

1.7

1.8

1.9

2.0

2.1

2.2

2.3

2.4

2.5

2.6

2.7

2.8

2.9

3.0

3.1

3.2

3.3

3.4

3.5

3.6

3.7

3.8

3.9

4.0

4.1

4.2

4.3

4.4

4.5

4.6

4.7

4.8

4.9

5.0

5.1

5.2

5.3

5.4

5.5

5.6

5.7

5.8

5.9

6.0

6.1

6.2

0.55

0.66

0.78

0.91

1.05

1.2

1.36

1.53

1.71

1.9

0.66

0.78

0.91

1.05

1.2

1.36

1.53

1.71

1.9

0.6

0.72

0.85

0.98

1.13

1.28

1.45

1.62

1.81

2.0

2.21

2.42

2.65

2.88

3.13

3.38

3.65

3.92

4.21

4.5

4.81

5.12

5.45

5.78

6.13

6.48

6.85

7.22

7.61

8.0

8.41

8.82

9.25

9.68

10.13

10.58

11.04

11.52

12.0

12.5

13.0

13.52

14.04

14.58

15.12

15.68

16.24

16.82

17.4

18.0

18.6

19.22

2.1

2.1

2.31

2.53

2.76

3.0

2.31

2.53

2.76

3.0

3.25

3.51

3.78

4.06

4.35

4.65

4.96

5.28

5.61

5.95

6.3

3.25

3.51

3.78

4.06

4.35

4.65

4.96

5.28

5.61

5.95

6.3

6.66

7.03

7.41

7.8

6.66

7.03

7.41

7.8

8.2

8.2

8.61

9.03

9.46

9.9

8.61

9.03

9.46

9.9

10.35

10.81

11.28

11.76

12.25

12.75

13.26

13.78

14.31

14.85

15.4

15.96

16.53

17.11

17.7

18.29

18.9

19.52

10.35

10.81

11.28

11.76

12.25

12.75

13.26

13.78

14.31

14.85

15.4

15.96

16.53

17.11

17.7

18.3

18.91





304

**Part III: The Power Stuff: Advanced Techniques**

6.3

6.4

6.5

6.6

6.7

6.8

6.9

7.0

7.1

7.2

7.3

7.4

7.5

7.6

7.7

7.8

7.9

8.0

8.1

8.2

8.3

8.4

8.5

8.6

8.7

8.8

8.9

9.0

9.1

9.2

9.3

9.4

9.5

9.6

9.7

9.8

9.9

19.53

20.16

20.8

20.15

20.79

21.44

22.1

22.77

23.45

24.14

24.84

25.55

26.27

27.0

27.74

28.49

29.25

30.02

30.8

31.59

32.39

33.2

34.02

34.85

35.69

36.54

37.4

38.27

39.15

40.04

40.94

41.85

42.77

43.7

44.64

45.59

46.55

47.52

48.5

19.84

20.48

21.12

21.78

22.44

23.12

23.8

21.45

22.11

22.78

23.46

24.15

24.85

25.56

26.28

27.01

27.75

28.5

24.5

25.2

25.92

26.64

27.38

28.12

28.88

29.64

30.42

31.2

29.26

30.03

30.81

31.6

32.0

32.8

32.4

33.21

34.03

34.86

35.7

33.62

34.44

35.28

36.12

36.98

37.84

38.72

39.6

36.55

37.41

38.28

39.16

40.05

40.95

41.86

42.78

43.71

44.65

45.6

40.5

41.4

42.32

43.24

44.18

45.12

46.08

47.04

48.02

49.0

46.56

47.53

48.51

49.49

As you can see, Euler’s method and the improved Euler’s method come out

about the same here. They’re both off by 1% at x = 9.9.

Plugging a steep slope into the new code

The improvement in the improved Euler’s method isn’t often visible until you

have steep or quickly varying slopes. For example, take a look at this differen-

tial equation:

dy

dx

= x

6

where y(0) = 0.





305

**Chapter 13: Discovering Three Fail-Proof Numerical Methods**

Here’s the exact solution (I’ll spare you the calculations so you can get to the

coding faster):

x

7

y =

7

Okay, so if the improved Euler method is truly improved, you should be able

to see difference in this example, where the slope changes faster than in the

differential equation in the previous section. Keep reading to find out what

happens.

Checking out the results

As you can see, when you use the steeply sloping differential equation, there’s

a difference between the Euler method and the improved Euler method:

x

Euler

.

Improved

Exact

.

.

6.0

6.1

6.2

6.3

6.4

6.5

6.6

6.7

6.8

6.9

7.0

7.1

7.2

7.3

7.4

7.5

7.6

7.7

7.8

7.9

8.0

8.1

8.2

8.3

8.4

8.5

8.6

8.7

8.8

8.9

9.0

9.1

9.2

37696.93

42362.53

47514.57

53194.59

59446.94

66318.89

73860.78

82126.18

91172.01

101058.76

111850.58

123615.48

136425.51

150356.91

165490.34

181910.99

199708.84

218978.83

239821.07

262341.03

286649.77

312864.17

341107.13

371507.8

404201.83

439331.64

477046.59

517503.31

560865.93

607306.34

657004.47

710148.57

766935.49

42138.76

47271.35

52930.6

39990.86

44896.33

50308.78

56271.15

62829.24

70031.83

77930.87

86581.59

96042.7

59160.78

66009.09

73525.81

81764.42

90781.79

100638.31

111398.05

123128.94

135902.94

149796.23

164889.33

181267.37

199020.24

218242.76

239034.95

261502.17

285755.38

311911.35

340092.85

370428.94

403055.15

438113.75

475754.01

516132.42

559412.98

605767.45

655375.61

708425.58

765114.08

825646.71

106376.48

117649.0

129930.29

143294.47

157819.98

173589.72

190691.27

209217.07

229264.62

250936.7

274341.56

299593.14

326811.32

356122.1

387657.87

421557.64

457967.27

497039.75

538935.42

583822.28

631876.21

683281.29

738230.03

796923.72





306

**Part III: The Power Stuff: Advanced Techniques**

9.3

9.4

9.5

9.6

9.7

9.8

9.9

827570.99

892270.01

961256.99

1034766.18

1113041.96

1196339.16

1284923.4

890238.25

959113.01

1032505.07

1110658.66

1193828.45

1282279.88

1376289.52

859572.67

926396.56

997624.71

1073496.4

1154261.21

1240179.33

1331521.93

Even though there is indeed a difference here (at x = 9.9, the Euler method

is off by 3.5% and the improved Euler method is off by 3.4%), the difference

isn’t huge.

Increasing your accuracy with a decreased step size

One way to increase your accuracy is to decrease your step size. For instance,

decrease the step size from h = 0.1 to h = 0.01. Also increase the number of

steps from n = 100 to n = 1,000. Here are the changes to make in the code in

e2.java:

public class e2

{

double x0 = 0.0;

double y0 = 0.0;

**double h = 0.01;**

**double n = 1000;**

.

.

.

And here’s what the results look like:

x

Euler

.

Improved

Exact

.

.

9.0

680627.03

685941.44

691291.38

696677.04

702098.63

707556.34

713050.38

718580.94

724148.23

729752.45

735393.8

741072.49

746788.73

752542.72

685923.78

691273.62

696659.18

702080.67

707538.28

713032.22

718562.68

724129.87

729733.98

735375.23

741053.82

746769.96

752523.84

758315.69

683281.29

688613.44

693981.23

699384.84

704824.47

710300.33

715812.61

721361.52

726947.25

732570.02

738230.03

743927.48

749662.57

755435.52

9.01

9.02

9.03

9.04

9.05

9.06

9.07

9.08

9.09

9.1

9.11

9.12

9.13





307

**Chapter 13: Discovering Three Fail-Proof Numerical Methods**

9.14

9.15

9.16

9.17

9.18

9.19

9.2

9.21

9.22

9.23

9.24

9.25

9.26

9.27

9.28

9.29

9.3

9.31

9.32

9.33

9.34

9.35

9.36

9.37

9.38

9.39

9.4

9.41

9.42

9.43

9.44

9.45

9.46

9.47

9.48

9.49

9.5

758334.67

764164.78

770033.28

775940.36

781886.24

787871.12

793895.24

799958.79

806061.99

812205.06

818388.22

824611.67

830875.66

837180.38

843526.06

849912.93

856341.2

764145.7

761246.54

767095.82

772983.59

778910.05

784875.42

790879.9

796923.72

803007.07

809130.19

815293.29

821496.58

827740.28

834024.61

840349.8

770014.09

775921.06

781866.84

787851.62

793875.62

799939.07

806042.16

812185.13

818368.17

824591.52

830855.39

837160.01

843505.58

849892.34

856320.5

862790.29

869301.93

875855.65

882451.68

889090.24

895771.56

902495.87

909263.4

916074.38

922929.04

929827.62

936770.36

943757.47

950789.21

957865.82

964987.51

972154.55

979367.16

986625.59

993930.09

1001280.88

1008678.23

1016122.37

1023613.55

1031152.02

1038738.02

1046371.82

1054053.64

1061783.76

1069562.41

1077389.87

1085266.37

1093192.17

1101167.54

1109192.73

846716.05

853123.6

859572.67

866063.48

872596.26

879171.23

885788.61

892448.65

899151.56

905897.57

912686.92

919519.84

926396.56

933317.32

940282.34

947291.87

954346.14

961445.39

968589.85

975779.78

983015.4

990296.96

997624.71

1004998.88

1012419.73

1019887.49

1027402.42

1034964.76

1042574.76

1050232.67

1057938.75

1065693.24

1073496.4

1081348.48

1089249.74

1097200.43

1105200.82

862811.1

869322.86

875876.69

882472.83

889111.5

895792.94

902517.36

909285.01

916096.1

922950.88

929849.58

936792.43

943779.67

950811.53

957888.25

965010.06

972177.22

979389.95

986648.5

993953.12

1001304.04

1008701.51

1016145.77

1023637.07

1031175.66

1038761.79

1046395.71

1054077.66

1061807.9

1069586.69

1077414.26

1085290.89

1093216.82

1101192.32

9.51

9.52

9.53

9.54

9.55

9.56

9.57

9.58

9.59

9.6

9.61

9.62

9.63

9.64





308

**Part III: The Power Stuff: Advanced Techniques**

9.65

9.66

9.67

9.68

9.69

9.7

9.71

9.72

9.73

9.74

9.75

9.76

9.77

9.78

9.79

9.8

9.81

9.82

9.83

9.84

9.85

9.86

9.87

9.88

9.89

9.9

1109217.64

1117293.04

1125418.77

1133595.11

1141822.31

1150100.64

1158430.36

1166811.74

1175245.04

1183730.53

1192268.48

1200859.17

1209502.85

1218199.81

1226950.31

1235754.64

1244613.06

1253525.86

1262493.31

1271515.69

1280593.28

1289726.36

1298915.22

1308160.14

1317461.39

1326819.28

1117268.0

1125393.6

1133569.81

1141796.88

1150075.08

1158404.66

1166785.91

1175219.08

1183704.43

1192242.25

1200832.8

1209476.35

1218173.17

1226923.54

1235727.73

1244586.02

1253498.68

1262465.99

1271488.23

1280565.68

1289698.62

1298887.33

1308132.11

1317433.22

1326790.97

1336205.62

1113251.15

1121351.7

1129502.71

1137704.46

1145957.2

1154261.21

1162616.73

1171024.05

1179483.42

1187995.12

1196559.42

1205176.58

1213846.88

1222570.59

1231347.98

1240179.33

1249064.92

1258005.02

1266999.91

1276049.87

1285155.19

1294316.13

1303533.0

1312806.06

1322135.61

1331521.93

When using the smaller step size, the Euler method and the improved Euler

method are only off by about 0.35% at x = 9.9. Much better.

Adding Even More Precision with

the Runge-Kutta Method

If you don’t want to use either of the Euler methods, you’re in luck. There’s

another numerical method that you can use to solve differential equations:

the Runge-Kutta method. This method gives excellent results that are even

more accurate than the Euler or improved Euler methods.

The method’s recurrence relation

In the Runge-Kutta method, the recurrence relation is a weighted average of

terms:

7

A

h

y

= yn + c + c + c + c

n + 1

6

1

2

3

4





309

**Chapter 13: Discovering Three Fail-Proof Numerical Methods**

**The story of Runge and Kutta**

Carl David Tolmé Runge was a German mathe- continued to work in Munich. He also spent a

matician. He was born in Havana, Cuba, on year at the University of Cambridge. He became

August 30, 1856, where his father was the Danish a professor in Stuttgart, Germany, in 1911. Kutta

consul. The family later moved to Bremen, died on December 25, 1944.

Germany. Runge died on January 3, 1927.

In 1901, Runge and Kutta co-developed the

Martin Wilhelm Kutta was also a German math- Runge-Kutta method, which is the powerful

ematician. He was born in Pitschen, Germany method that’s used to solve ordinary differential

(which today is part of Poland), on November 3, equations numerically.

\1867. He went to the University of Breslau and

where:

c = f(x y )

1

n

n

c

h

hm

hm

2

c = f x + , yn + c

2

n

2

1

2

2

c

h

c = f x + , yn + c

3

n

2

c = f(x + h, y + c h)

4

n

n

3

This method can easily be adapted to the code you use earlier in the chapter,

because f(x, y) doesn’t depend on y — it’s just f(x). In this case, the recur-

rence relation becomes:

= \_

i

c

m

c

m

\_

iG

h

h

2

h

2

y

= yn + f x + f x +

\+ f x +

\+ f x + h

n

\+

1

6

n

n

n

n

Working with the method in code

Here, you put the Runge-Kutta technique to work, solving the same differen-

tial equation that you saw earlier in the chapter:

dy

dx

= x

Inputting the code

The recurrence relation of the Runge-Kutta method looks easy enough to

implement in a new Java program, e3.java. This new program will put the

Runge-Kutta method to work. The new code is shown in **bold.**





310

**Part III: The Power Stuff: Advanced Techniques**

public class e3

{

double x0 = 0.0;

double y0 = 0.0;

double h = 0.1;

double n = 100;

public e3()

{

}

public double f(double x, double y)

{

return x;

}

public double exact(double x, double y)

{

return x \* x / 2;

}

public static void main(String [] argv)

{

e3 de = new e3();

de.calculate();

}

public void calculate()

{

double x = x0;

double y = y0;

**double yrk = y0;**

double k;

**System.out.println(“x\t\tEuler\t\tRunge-**

**Kutta\t\tExact”);**

for (int i = 1; i < n; i++){

k = f(x, y);

y = y + h \* k;

**yrk = y + (f(x, y) + f(x + h/2, y)/2 + f(x + h/2, y)/2**

**+ f(x + h, y))\* (h/6);**

x = x + h;

**System.out.println(round(x) + “\t\t” + round(y) +**

**“\t\t” + round(yrk) + “\t\t”**

**+ round(exact(x, 0)));**

}

}

public double round(double val)





311

**Chapter 13: Discovering Three Fail-Proof Numerical Methods**

{

double divider = 100;

val = val \* divider;

double temp = Math.round(val);

return (double)temp / divider;

}

}

Examining the results

Here are the results of e3.java:

C:\>java e3

x

Euler

0.0

0.01

0.03

0.06

0.1

0.15

0.21

0.28

0.36

0.45

0.55

0.66

0.78

0.91

1.05

1.2

Runge-Kutta

0.0

Exact

0.01

0.02

0.05

0.08

0.13

0.18

0.24

0.32

0.4

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1.0

1.1

1.2

1.3

1.4

1.5

1.6

1.7

1.8

1.9

2.0

2.1

2.2

2.3

2.4

2.5

2.6

2.7

2.8

2.9

3.0

3.1

3.2

3.3

3.4

3.5

3.6

3.7

3.8

0.02

0.04

0.08

0.12

0.18

0.24

0.32

0.4

0.5

0.6

0.5

0.6

0.72

0.84

0.98

1.12

1.28

1.44

1.62

1.8

0.72

0.85

0.98

1.13

1.28

1.45

1.62

1.81

2.0

2.21

2.42

2.65

2.88

3.13

3.38

3.65

3.92

4.21

4.5

4.81

5.12

5.45

5.78

6.13

6.48

6.85

7.22

1.36

1.53

1.71

1.9

2.0

2.2

2.1

2.31

2.53

2.76

3.0

2.42

2.64

2.88

3.12

3.38

3.64

3.92

4.2

3.25

3.51

3.78

4.06

4.35

4.65

4.96

5.28

5.61

5.95

6.3

4.5

4.8

5.12

5.44

5.78

6.12

6.48

6.84

7.22

6.66

7.03





312

**Part III: The Power Stuff: Advanced Techniques**

3.9

4.0

4.1

4.2

4.3

4.4

4.5

4.6

4.7

4.8

4.9

5.0

5.1

5.2

5.3

5.4

5.5

5.6

5.7

5.8

5.9

6.0

6.1

6.2

6.3

6.4

6.5

6.6

6.7

6.8

6.9

7.0

7.1

7.2

7.3

7.4

7.5

7.6

7.7

7.8

7.9

8.0

8.1

8.2

8.3

8.4

8.5

8.6

8.7

8.8

7.41

7.8

8.2

8.61

9.03

9.46

9.9

10.35

10.81

11.28

11.76

12.25

12.75

13.26

13.78

14.31

14.85

15.4

7.6

8.0

8.4

8.82

9.24

9.68

10.12

10.58

11.04

11.52

12.0

7.61

8.0

8.41

8.82

9.25

9.68

10.13

10.58

11.04

11.52

12.0

12.5

13.0

12.5

13.0

13.52

14.04

14.58

15.12

15.68

16.24

16.82

17.4

13.52

14.04

14.58

15.12

15.68

16.24

16.82

17.4

15.96

16.53

17.11

17.7

18.0

18.6

18.0

18.6

18.3

18.91

19.53

20.16

20.8

19.22

19.84

20.48

21.12

21.78

22.44

23.12

23.8

19.22

19.84

20.48

21.12

21.78

22.44

23.12

23.8

21.45

22.11

22.78

23.46

24.15

24.85

25.56

26.28

27.01

27.75

28.5

24.5

25.2

24.5

25.2

25.92

26.64

27.38

28.12

28.88

29.64

30.42

31.2

25.92

26.64

27.38

28.12

28.88

29.64

30.42

31.2

29.26

30.03

30.81

31.6

32.0

32.8

32.0

32.8

32.4

33.21

34.03

34.86

35.7

36.55

37.41

38.28

33.62

34.44

35.28

36.12

36.98

37.84

38.72

33.62

34.44

35.28

36.12

36.98

37.84

38.72





313

**Chapter 13: Discovering Three Fail-Proof Numerical Methods**

8.9

9.0

9.1

9.2

9.3

9.4

9.5

9.6

9.7

9.8

9.9

39.16

40.05

40.95

41.86

42.78

43.71

44.65

45.6

39.6

40.5

41.4

39.6

40.5

41.4

42.32

43.24

44.18

45.12

46.08

47.04

48.02

49.0

42.32

43.24

44.18

45.12

46.08

47.04

48.02

49.0

46.56

47.53

48.51

When you look at the results, you can see that the Runge-Kutta method beat

the Euler method hands down. In fact, to two decimal places, the Runge-Kutta

method nearly always nailed the correct answer. Very cool.





314

**Part III: The Power Stuff: Advanced Techniques**





**Par t IV**

**The Part of Tens**





In this part . . .

E

who am I to break with tradition? This part is full of

very For Dummies book features a Part of Tens, and

cool stuff. You discover the ten top differential equation

online tutorials as well as the ten top online tools for solv-

ing differential equations. If you want to get more info on a

specific aspect of differential equations, try the tutorials.

If you want to work with challenging differential equations

and need a little help, take a look at the tools available

online.





**Chapter 14**

**Ten Super-Helpful Online**

**Differential Equation Tutorials**

In This Chapter

` `Understanding different aspects of differential equations with tutorials

` `Checking out helpful notes and videos

E

ven if you think of yourself as a math whiz, you still may find yourself

scratching your head at certain aspects of differential equations. Fear not:

A number of differential equation tutorials are available on the Internet — and

this chapter lists ten of my favorites. Each site deals with various aspects of

differential equations.

AnalyzeMath.com’s Introduction

to Differential Equations

If you’re new to differential equations, you may be looking for a brief

overview of the topic. The Web site AnalyzeMath.com offers just that. If

you visit www.analyzemath.com/calculus/Differential\_Equations/

introduction.html, you can read an introductory tutorial on differential

equations. The site is run by Abdelkader Dendane, PhD, a lecturer in mathe-

matics at United Arab Emirates University.





318

**Part IV: The Part of Tens**

Harvey Mudd College Mathematics

Online Tutorial

If you’re looking for a tutorial that gives good coverage of solving first order

ordinary differential equations, be sure to check out the Harvey Mudd

College Mathematics Online Tutorial at www.math.hmc.edu/calculus/

tutorials/odes.

John Appleby’s Introduction

to Differential Equations

John Appleby, a professor in the School of Mathematical Sciences at Dublin

City University in Ireland, maintains a helpful tutorial at webpages.dcu.ie/

~applebyj/ms225/ms225.html. Be sure to click the links under the Tutorial

Sheets and the Supplementary Notes headers. On his site, Appleby covers

separable and homogeneous equations, first order linear differential equa-

tions, second order linear differential equations, variation of parameters,

and more.

Kardi Teknomo’s Page

Dr. Kardi Teknomo is a research fellow at Human Centered Mobility

Technologies in Arsenal Research (which is located in Austria). Teknomo’s

tutorial focuses on solving differential equations using numerical methods.

You can find this great tutorial at people.revoledu.com/kardi/tutorial/

ODE/index.html.

Martin J. Osborne’s Differential

Equation Tutorial

Martin J. Osborne, a professor of economics at the University of Toronto, has

created a superb, multipart differential equation tutorial at www.economics.

utoronto.ca/osborne/MathTutorial/IDEF.HTM.





319

**Chapter 14: Ten Super-Helpful Online Differential Equation Tutorials**

Midnight Tutor’s Video Tutorial

If you’re looking for something fun and different, check out the Midnight

Tutor’s Video Tutorial, which is a video tutorial solving y' – ycos(t) = cos(t)

using separation of variables. To view the video, visit www.midnighttutor.

com/de\_xprime-xcost-xcost.html.

The Ohio State University Physics

Department’s Introduction

to Differential Equations

If you struggle with homogeneous and nonhomogeneous linear differential

equations, there’s still hope! Check out the Ohio State University Physics

Department tutorial on these types of differential equations. You can find

the site at www.physics.ohio-state.edu/~physedu/mapletutorial/

tutorials/diff\_eqs/intro.html.

Paul’s Online Math Notes

Paul’s Online Math Notes is an extensive set of online explanations of differ-

ential equations. You can visit this site at tutorial.math.lamar.edu/

Classes/DE/DE.aspx. (Who’s Paul? He’s Paul Dawkins, who teaches at

Lamar University in Beaumont, Texas.)

S.O.S. Math

S.O.S. Math (www.sosmath.com/diffeq/diffeq.html) is an all-purpose

resource for all of mathematics, but it has an entire section on differential

equations. S.O.S Math is a great, multipart tutorial — it’s as complete a tutor-

ial as you’ll find online.





320

**Part IV: The Part of Tens**

University of Surrey Tutorial

England’s University of Surrey provides an excellent tutorial on first and

second order differential equations. You can view this site at www.maths.

surrey.ac.uk/explore/vithyaspages. Vithya Nanthakumaar, who studies

at the University of Surrey, created the site.





**Chapter 15**

**Ten Really Cool Online Differential**

**Equation Solving Tools**

In This Chapter

` `Solving equations with handy online tools

` `Plotting direction fields and graphing functions

S

uppose you’re working on a particularly hairy differential equation that

requires some busywork. Do you need to sit and do pages of calcula-

tions? Heck no! That’s what differential equation solving tools are for! And

tons are available. Some programs cost money — and sometimes, they cost a

great deal of money. However, a bunch of good tools also are available for

free online. This chapter has a sampling of those great freebies.

AnalyzeMath.com’s Runge-Kutta

Method Applet

The AnalyzeMath.com Runge-Kutta Applet solves a number of representative

differential equations using the Runge-Kutta method that I explain in

Chapter 13. You can find this applet at www.analyzemath.com/calculus/

RungeKutta/RungeKutta.html. A couple of cool features of this applet:

You can increase the number of points used in the calculation, and you can

zoom in and out.

Coolmath.com’s Graphing Calculator

The Coolmath.com graphing calculator is a fabulous online graphing applet

that draws functions for you. You can find this calculator at www.coolmath.

com/graphit/index.html.





322

**Part IV: The Part of Tens**

Direction Field Plotter

Want to see what the direction field for a differential equation’s solution looks

like? You’re in luck! You can find a great direction field plotter at www.math.

ubc.ca/~israel/applet/dfplotter/dfplotter.html. (Flip to Chapter 1

for an introduction to direction fields.)

An Equation Solver from QuickMath

Automatic Math Solutions

The solver from QuickMath Automatic Math Solutions is an equation solver,

not a differential equation solver. But it’s still a great tool when you need to

factor an equation, such as a characteristic equation, to find the roots. Here’s

the Web site where you can find the solver: www.hostsrv.com/webmab/app1/

MSP/quickmath/02/pageGenerate?site=quickmath&s1=equations&s2=

solve&s3=basic.

First Order Differential Equation Solver

Here’s a cool one: the First Order Differential Equation Solver at www.cs.

gordon.edu/~senning/desolver/index.html. With this solver you can

use the Euler, Improved Euler, and Runge-Kutta methods to solve differential

equations. Just select the method you want to use from the drop-down box,

enter your equation, and then click the Submit button. You couldn’t find a

niftier math tool.

GCalc Online Graphing Calculator

If you’re working on a tough problem and don’t have a graphing

calculator handy, you can find a good graphing calculator applet at www.

calculator.com/calcs/GCalc.html. Just enter the function you want to

graph and press Enter on your keyboard. It doesn’t get easier than that!





323

**Chapter 15: Ten Really Cool Online Differential Equation Solving Tools**

JavaView Ode Solver

The JavaView Ode Solver at www.javaview.de/services/odeSolver/

index.html is a numerical differential equation solver that uses the

Runge-Kutta method in Chapter 13. (“Ode” stands for “ordinary differential

equation.”)

Math @ CowPi’s System Solver

The Math @ CowPi’s System Solver lets you solve simultaneous equations —

from 2 × 2 to 5 × 5. Just fill in all the blanks, and presto! You have your

answer. This great tool is available at math.cowpi.com/systemsolver.

This tool also can be useful when you break a higher-order differential equa-

tion into a system of lower-order ones.

A Matrix Inverter from QuickMath

Automatic Math Solutions

When working with systems of differential equations, you work with equa-

tions like **Ax** = **b**. The solution to an equation like this is **x** = **A**–1**b**, where **A**–1 is

the inverse of the matrix **A**. Don’t feel like solving all that? Here’s a tool that

finds the inverse of matrices for you in a snap: www.hostsrv.com/webmab/

app1/MSP/quickmath/02/pageGenerate?site=quickmath&s1=matrices&

s2=inverse&s3=basic. All you have to do is enter the matrix and click the

Inverse button.

Visual Differential Equation

Solving Applet

The Visual Differential Equation Solving Applet at www.falstad.com/diffeq

(which runs in browsers) lets you solve some common differential equations

and adjust numeric parameters.





324

**Part IV: The Part of Tens**





**Index**

• Symbols & Numerics • classifying differential equations

linear versus nonlinear equations, 18–19

by order, 17

ordinary versus partial equations, 17–18

overview, 17

\* operator, 260

1 function, 244

• A •

coefficients, undetermined. See method of

undetermined coefficients

complex conjugates of matrices, 269

complex roots, 100, 164–166, 223–224

compound interest rate problem, 55–59

conjugates of matrices, complex, 269

connecting slopes into integral curve,

14–15

constant coefficients, second order linear

homogeneous differential equations

with

elementary solutions, 94–95

linear equations, 95–96

absolute convergence of series, 192

adjoints of matrices, 269

advanced techniques, 21

Airy, George Biddell, 208

Airy’s equation

differentiating and substituting power

series into differential equation,

207–208

ensuring same index value, 208

overview, 207

putting together solution, 210–211

using recurrence relation to find

coefficients, 209–210

overview, 94

constants, 11–12, 26

continuous functions, 35, 93, 195

conventions used in this book, 1–2

convergence, radius of, 193

convolution integrals, 259–261

Coolmath.com graphing calculator, 321

cos at function, 244

cosh at function, 244

cosine, finding particular solutions in

cosine form, 185

AnalyzeMath.com

introduction to differential equations, 317

Runge-Kutta applet, 321

angles

of pendulum equations, 18

phase, 149

Appleby, John, 318

augmented matrices, 267

curve, 14–15. See also Euler’s method

• B •

• D •

bank interest rate problem, 55–59

body falling through air example, 13–14

boldfaced text in book, 2

damping, 148

Dawkins, Paul, 319

Dendane, Abdelkader, 317

derivatives

• C •

of cos(x), 12

calculator, graphing

Coolmath.com, 321

GCalc, 322

involving multiple functions, 12–13

involving trigonometry, 12

Laplace transform of, 247

overview, 8

chain rule, 44, 65





326

**Differential Equations For Dummies**

derivatives (continued)

partial, 17–18

identical complex roots, 170–171

identical imaginary roots, 169–170

overview, 166

of product of two functions, 13

of quotient of two functions, 13

of sin(x), 12

of sum (or difference) of two functions, 12

that are constants, 11–12

that are powers, 12

determinants, of matrices, 274

difference equations

equilibrium solutions

• E •

e, raising to certain power, 12

ea, inverse of, 12

eat cos bt function, 244

eat function, 242, 244

eat sin bt function, 244

overview, 85

e.class, 81

working with constant, 86–87

working without constant, 86

iterative solutions, 84–85

overview, 83

terminology related to, 84

direction fields

connecting slopes into integral curve,

14–15

equilibrium value in, 16

and first derivative, 20

of flow problem solution, 54

graphs

eigenvalues and eigenvectors

calculating eigenvectors, 282–283,

286–287

changing matrix to right form, 282

figuring out eigenvalues, 282

overview, 281

equal roots, 222–223

equilibrium value, 16

erx, g(x) in form of, 127–128, 176–179

Euler equations

complex roots, 223–224

overview, 219–220

of advanced solution, 34

equilibrium value in, 16

of flow problem solution, 54

of nonlinear separable solution, 45

of separable equation with hard-to-find

explicit solution, 49

of separable equation with initial

conditions, 47

solution in, 15

real and distinct roots, 220–221

real and equal roots, 222–223

recognizing, 227

Euler, Leonhard Paul, 76

Euler’s method

checking method’s accuracy on computer

defining initial conditions and functions,

78–79

examining entire code, 79

example at work, 80–83

overview, 77–78

of nonlinear separable equation, 45

overview, 13

plotter for, 322

fundamentals of method, 294–295

graph, 77

plotting, 13–14

recognizing equilibrium value, 16

of separable equations, 47

distinct roots, 220–221. See also real and

distinct roots

drag coefficient, 14

drag force, mass with, 148–150

duplicate roots

fifth order equation with identical real

roots, 167–168

fourth order equation with identical real

roots, 166–167

improved

coming up with new code, 300–304

overview, 299–300

plugging steep slope into new code,

304–308

understanding improvements, 300

overview, 75, 294

understanding method, 76–77

using code to see method in action

overview, 295





327

**Index**

surveying results, 297–299

typing in code, 295–297

exact differential equations. See also

nonexact differential equations

defining, 64

determining whether equation is exact,

66–70

force

drag force, mass with, 148–150

periodic, 145, 146

restorative, 144

fourth order equation with identical real

roots, 166–167

fractions

solving, 74–75

factoring Laplace transforms into,

258–259

partial, using in first order differential

equations, 59–61

typical, working out, 65–66

existence and uniqueness theorem,

35, 37–40

explicit solution, 44

exponents at the singularity, 232

friction, mass without, 144–148

functions

continuous, 93, 195

cos at, 244

cosh at, 244

• F •

e

e

e

at, 244

F = ma (Newton’s second law), 14

falling body example, 13–14

f(ct) function, 244

fifth order equation with identical real

roots, 167–168

at cos bt, 244

at sin bt, 244

f(ct), 244

f

(n)(t), 244

multiple, derivatives involving, 12–13

piecewise continuous, 241

product of two, derivatives of, 13

quotient of two, derivatives of, 13

sin at, 244

sinh at, 244

solving differential equations involving,

25–26

first order difference equations, 84

first order differential equations, 19–20.

See also systems of first order linear

differential equations

linear, 23–40

basics of solving, 24–26

determining if solution exists for, 35–38

solving with integrating factors, 26–34

nonlinear, 38–40

online solver for, 322

separable, 41–61

step, 261–263

sum (or difference) of two,

derivatives of, 12

t

t

n

, 244

e

finding explicit solutions from implicit

solutions, 45–47

implicit solutions, 43–45

n

at, 244

f'(x), 11

sample flow problem, 52–55

sample monetary problem, 55–59

turning nonlinear separable equations

into linear separable equations, 49–51

using partial fractions in, 59–61

when can’t find explicit solution, 48–49

flow problem solution, 52–55

direction field of, 54

• G •

GCalc online graphing calculator, 322

general solutions, 36

graphing calculator

Coolmath.com, 321

GCalc, 322

graphs

direction fields

graph, 55

f

(n)(t) function, 244

of advanced solution, 34

equilibrium value in, 16





328

**Differential Equations For Dummies**

graphs (continued)

overview, 153

solutions as related to Wronskian, 156

different types of

complex roots, 164–166

duplicate roots, 166–171

of flow problem solution, 54

of nonlinear separable solution, 45

of separable equation with hard-to-find

explicit solution, 49

of separable equation with initial

conditions, 47

solution in, 15

overview, 156

real and distinct roots, 156–161

real and imaginary roots, 161–164

notation of, 152–153

Euler’s method, 77

of flow problem solution, 55

math behind mass

with drag force, 150

overview, 151

higher order linear nonhomogeneous

differential equations. See also second

order linear nonhomogeneous

differential equations

method of undetermined coefficients for

overview, 174–175

without friction, 148

solution to equation, 105

with complex roots, 105

with real and distinct roots, 100

with real and imaginary roots, 164

step function, 262

when g(x) is combination of sines and

cosines, 182–185

g(x)

when g(x) is in form erx, 176–179

when g(x) is polynomial of order n,

179–182

as combination of sines and cosines,

131–133, 182–185

in form of erx, 127–128, 176–179

as polynomial of order n, 128–131,

179–182

as product of two different forms,

133–134

overview, 173

solving with variation of parameters

basics of method, 185–186

overview, 185

working through example, 186–188

homogeneous differential equations. See

higher order linear homogeneous

differential equations; linear

homogeneous differential equations;

second order homogeneous equations;

second order linear homogeneous

differential equations; systems of first

order linear homogeneous differential

equations

• H •

Harvey Mudd College Mathematics Online

Tutorial, 318

heat conduction equation, 18

higher order differential equations

overview, 20–21

solving with Laplace transforms

figuring out equation’s Laplace

transform, 256

getting equation’s inverse Laplace

transform, 258

• I •

icons used in this book, 4

identical complex roots, 170–171

identical imaginary roots, 169–170

identity matrices, 272

overview, 255

unearthing function to match Laplace

transform, 256–258

higher order linear homogeneous

differential equations

basics of

imaginary roots, 161–164

indicial equations

distinct roots that don’t differ by positive

integer, 235–236

format, solutions, and initial conditions,

153–154

equal roots, 236

general solution of, 155





329

**Index**

overview, 235

roots that differ by positive integer,

236–237

initial conditions, separable equations

with, 47

integers, positive

• K •

Kardi Teknomo’s page, 318

kernel of Laplace transforms, 239

Kutta, Martin Wilhelm, 309

distinct roots that don’t

differ by, 235–236

roots that differ by, 236–237

integral curve, connecting slopes into,

14–15

integrals, convolution, 259–261

integrating factors

solving linear first order differential

equations with

• L •

Laplace, Pierre-Simon, 240

Laplace transforms

breaking down, 239–240

calculating, 241–244

transform of 1, 242

transform of eat, 242

transform of sin at, 242–243

of common functions, 244

convolution integrals, 259–261

deciding whether converges, 240–241

factoring into fractions, 258–259

kernel of, 239

overview, 239

solving differential equations with

overview, 245–246

solving higher order equation, 255–258

solving second order homogeneous

equation, 247–251

solving second order nonhomogeneous

equation, 251–255

overview, 26

solving advanced example, 32–34

solving for integrating factor, 27–28

trying special shortcut, 30–32

using integrating factor to solve

differential equation, 28–29

using integrating factors in differential

equations with functions, 29

using with nonexact differential equations

completing process, 72–73

multiplying by factor you want to find,

71–72

overview, 70

integration by parts, 30–31

interest rate problem, 55–59

italics in book, 2

iterates of difference equation’s

solution, 85

step functions, 261–263

Legendre, Adrien-Marie, 219

Legendre equation, 218, 219

limiting expressions, 11

line, slope of, 9

linear equations, versus nonlinear

equations, 18–19

linear first order differential equations.

See also nonlinear first order

differential equations

basics of solving

adding constants, 26

• J •

Java programming language, downloading,

78, 294

JavaView Ode Solver, 323

John Appleby’s introduction to differential

equations, 318

applying initial conditions from start,

24–25

juice flow problem, 52–55

overview, 24

solving differential equations involving

functions, 25–26





330

**Differential Equations For Dummies**

linear first order differential equations

(continued)

basics of

overview, 266

determining if solution exists for, 35–38

overview, 23

solving with integrating factors

overview, 26

setting up matrix, 266–267

working through algebra, 267–268

complex conjugates of, 269

identity matrices, 272

inverter from QuickMath Automatic Math

Solutions, 323

non-invertable, 277

operations

addition, 270

equality, 269

solving advanced example, 32–34

solving for integrating factor, 27–28

trying special shortcut, 30–32

using integrating factor to solve

differential equation, 28–29

using integrating factors in differential

equations with functions, 29

linear homogeneous differential equations,

second order

characteristic equations, 96–109

with constant coefficients, 94–96

getting second solution by reduction of

order, 109–113

identity, 272

inverse of a matrix, 272–278

multiplication of matrix and number, 270

multiplication of matrix and vector,

271–272

multiplication of two matrices, 270–271

overview, 269

overview, 91–93

theorems, 114–122

subtraction, 270

singular, 277

linear independence

assembling vectors into one matrix,

278–279

determining determinant, 279–281

overview, 115–117, 278

linear nonhomogeneous differential

equations. See higher order linear

nonhomogeneous differential

equations; second order linear

nonhomogeneous differential equations

linear separable equations, 49–51

transpose of, 269

triangular, 268

method of undetermined coefficients. See

undetermined coefficients, method of

methods. See also partial fractions;

reduction of order method

Euler’s

checking method’s accuracy on

computer, 77–83

fundamentals of method, 294–295

graph, 77

improved, 299–308

overview, 75, 294

understanding method, 76–77

using code to see method in action,

295–299

• M •

Martin J. Osborne’s differential equation

tutorial, 318

mass

with drag force, 148–150

without friction, 144–148

Math @ CowPi’s System Solver, 323

matrices

adjoints of, 269

assembling vectors into one matrix,

278–279

Runge-Kutta

method’s recurrence relation, 308–309

overview, 308

working with method in code, 309–313

Midnight Tutor’s Video Tutorial, 319

monetary problem, first order differential

equations, 55–59

monofont text in book, 2

µ(t), 26, 27

multiple functions, derivatives involving,

12–13

augmented, 267





331

**Index**

• N •

• O •

n, g(x) as polynomial of order n, 128–131,

179–182

Nanthakumaar, Vithya, 320

Newton’s second law (F = ma), 14

nonexact differential equations, using

integrating factors with. See also exact

differential equations

completing process, 72–73

multiplying by factor you want to find,

71–72

Ohio State University Physics

Department’s introduction to

differential equations, 319

online tutorials

AnalyzeMath.com’s introduction to

differential equations, 317

Harvey Mudd College Mathematics

Online Tutorial, 318

John Appleby’s introduction to

differential equations, 318

Kardi Teknomo’s page, 318

overview, 70

nonhomogeneous equation. See second

order nonhomogeneous equations;

systems of first order linear

nonhomogeneous equations

non-invertable matrices, 277

nonlinear equations, versus linear

equations, classifying by, 18–19

nonlinear first order differential equations,

determining if solution exists for,

38–40. See also linear first order

differential equations

Martin J. Osborne’s differential equation

tutorial, 318

Midnight Tutor’s Video Tutorial, 319

Ohio State University Physics

Department’s introduction to

differential equations, 319

overview, 317

Paul’s Online Math Notes, 319

S.O.S. Math, 319

University of Surrey Tutorial, 320

order, classifying by, 17

nonlinear separable equations

direction field of, 45

turning into linear separable equations,

49–51

ordinary (non-partial) derivatives, 17–18

ordinary equations, versus partial

equations, classifying by, 17–18

ordinary points, 196

non-partial (ordinary) derivatives, 17–18

numerical methods

Euler’s method

Osborne, Martin J., 318

• P •

checking method’s accuracy on

computer, 77–83

fundamentals of method, 294–295

improved, 299–308

parameters method

breaking down equations with variation of

applying method to any linear equation,

138–142

basics of method, 136

overview, 135

solving typical example, 137–138

variation of parameters method and

Wronskian, 142–143

overview, 75, 294

understanding method, 76–77

using code to see method in action,

295–299

overview, 293

Runge-Kutta method

method’s recurrence relation, 308–309

overview, 308

working with method in code, 309–313





332

**Differential Equations For Dummies**

parameters method (continued)

solving higher order linear

nonhomogeneous differential

equations, solving with variation of

basics of method, 185–186

overview, 185

working through example, 186–188

partial derivatives, 17–18

partial equations, versus ordinary

equations, classifying by, 17–18

partial fractions, using in first order

differential equations, 59–61

particular solution, 124

parts, integration by, 30–31

Paul’s Online Math Notes, 319

peanut butter price increase example, 8–10

pendulum angle equation, 18

periodic force, 145, 146

phase angle, 149

solving second order differential

equations with

Airy’s equation, 207–211

overview, 196

when already know solution, 198–204

when don’t know solution beforehand,

204–207

powering through singular points

behavior of singular points, 214–215

Euler equations

complex roots, 223–224

overview, 219

real and distinct roots, 220–221

real and equal roots, 222–223

finding singular points, 214

overview, 213

regular singular points

defined, 216

figuring series solutions near, 225–237

versus irregular, 215–219

powers, derivatives that are, 12

product of two functions, derivatives of, 13

piecewise continuous functions, 241

pitcher of water problem, 52–55

plotting direction fields, 13–14

points, singular

behavior of, 214–215

Euler equations

• Q •

complex roots, 223–224

overview, 219

real and distinct roots, 220–221

real and equal roots, 222–223

finding, 214

quadratic equations, 45

QuickMath Automatic Math Solutions, 322

quotient of two functions, derivatives of, 13

• R •

overview, 197, 213

regular

defined, 216

figuring series solutions near, 227–237

versus irregular, 215–219

severity of, 215

radius of convergence, 193

ratio test, determining whether power

series converges with

fundamentals of ratio test, 192–193

overview, 192

plugging in numbers, 193–195

real and distinct roots

fourth order equation, 159–161

overview, 156

third order equation, 156–159

real and imaginary roots, 161–164

recurrence relation, 201, 295

reduction of order method, 108

Remember icon, 4

positive integers

distinct roots that don’t differ by, 235–236

roots that differ by, 236–237

power series

basics of, 191–192

determining whether converges with

ratio test

fundamentals of ratio test, 192–193

overview, 192

plugging in numbers, 193–195





333

**Index**

resources

Runge, Carl David Tolmé, 309

Runge-Kutta method

method’s recurrence relation, 308–309

overview, 308

working with method in code

examining results, 311–313

inputting code, 309–311

overview, 309

AnalyzeMath.com’s introduction to

differential equations, 317

Harvey Mudd College Mathematics

Online Tutorial, 318

John Appleby’s introduction to

differential equations, 318

Kardi Teknomo’s page, 318

Martin J. Osborne’s differential equation

tutorial, 318

Midnight Tutor’s Video Tutorial, 319

Ohio State University Physics

Department’s introduction to

differential equations, 319

overview, 317

Paul’s Online Math Notes, 319

S.O.S. Math, 319

University of Surrey Tutorial, 320

restorative force, 144

rocket wobbling problem, 41

roots

complex, 164–166

distinct, 156–161

duplicate, 166–171

Euler equations

complex roots, 223–224

distinct roots, 220–221

equal roots, 222–223

• S •

second order differential equations

overview, 20–21

solving with power series

Airy’s equation, 207–211

overview, 196–197

when already know solution, 198–204

when don’t know solution beforehand,

204–207

second order homogeneous equations,

solving with Laplace transforms

finding Laplace transform of equation’s

unknown solution, 249–250

overview, 247

uncovering inverse Laplace transform to

get equation’s solution, 250–251

second order linear homogeneous

differential equations. See also second

order linear nonhomogeneous

differential equations

basics of

homogeneous equations, 93

linear equations, 92–93

overview, 91

characteristic equations

complex roots, 100–105

real roots, 220–223

imaginary, 161–164

indicial equations

distinct roots that don’t differ by

positive integer, 235–236

equal roots, 236

roots that differ by positive integer,

236–237

real and distinct

identical real roots, 106–109

overview, 96

real and distinct roots, 97–100

with constant coefficients

elementary solutions, 94–95

linear equations, 95–96

fourth order equation, 159–161

third order equation, 156–159

and solving equations near singular

points

applying first root, 232–233

overview, 229

overview, 94

plugging in second root, 233–235





334

**Differential Equations For Dummies**

second order linear homogeneous

differential equations (continued)

getting second solution by reduction of

order, 109–113

theorems

linear independence, 115–117

overview, 114

separable first order differential equations

basics of

finding explicit solutions from implicit

solutions, 45–47

implicit solutions, 43–45

turning nonlinear separable equations

into linear separable equations, 49–51

when can’t find explicit solution, 48–49

sample flow problem

superposition of solutions, 114–115

Wronskian, 117–122

second order linear nonhomogeneous

differential equations

breaking down equations with variation

of parameters method

determining basic numbers, 52–53

solving equation, 53–55

sample monetary problem

adding set amount of money, 58–59

compounding interest at set intervals,

56–57

applying method to any linear equation,

138–142

basics of method, 136

overview, 135

general solution, 55–56

using partial fractions in, 59–61

series index, shifting, 195

severity of singular points, 215

shifting the series index, 195

sin at function, 242–243

sine, 185

singular matrices, 277

solving typical example, 137–138

variation of parameters method and

Wronskian, 142–143

finding particular solutions with method

of undetermined coefficients

overview, 127

when g(x) is combination of sines and

cosines, 131–133

when g(x) is in form of erx, 127–128

when g(x) is polynomial of order n,

128–131

singular points, 197, 213–219

sinh at function, 244

sinusoidal, 149

sin(x), 12

slopes

when g(x) is product of two different

forms, 133–134

general solution of, 124–126

mass with drag force, 148–150

mass without friction, 144–148

overview, 123

connecting into, 14–15

of curves. See Euler’s method

of lines, 9

S.O.S. Math, 319

step functions, Laplace transforms,

261–263

second order nonhomogeneous equation,

solving with Laplace transforms

determining Laplace transform, 252–253

matching function to Laplace transform,

253–255

overview, 251

using table to find inverse Laplace

transform, 255

sum (or difference) of two functions,

derivatives of, 12

superposition of solutions theorem,

114–115

systems of first order linear differential

equations. See also systems of first

order linear nonhomogeneous

equations; systems of first order linear

homogeneous differential equations

eigenvalues and eigenvectors

calculating eigenvectors, 282–283

changing matrix to right form, 282

separable equations

with hard-to-find explicit solution,

direction field of, 47, 49

with initial conditions, direction field of, 47





335

**Index**

figuring out eigenvalues, 282

overview, 281

linear independence, 278–281

assembling vectors into one matrix,

278–279

determining determinant, 279–281

matrices, basics of

overview, 266

setting up matrix, 266–267

working through algebra, 267–268

matrix operations

addition, 270

equality, 269

tn function, 244

tools for solving differential equations

AnalyzeMath.com’s Runge-Kutta

Applet, 321

Coolmath.com graphing calculator, 321

direction field plotter, 322

equation solver from QuickMath

Automatic Math Solutions, 322

First Order Differential Equation Solver, 322

GCalc online graphing calculator, 322

JavaView Ode Solver, 323

Math @ CowPi’s System Solver, 323

matrix inverter from QuickMath

Automatic Math Solutions, 323

overview, 321

Visual Differential Equation Solving

Applet, 323

transpose of matrices, 269

triangular matrices, 268

trigonometry, derivatives involving, 12

tutorials, online

AnalyzeMath.com’s introduction to

differential equations, 317

Harvey Mudd College Mathematics

Online Tutorial, 318

John Appleby’s introduction to

differential equations, 318

Kardi Teknomo’s page, 318

Martin J. Osborne’s differential equation

tutorial, 318

identity, 272

inverse of a matrix, 272–278

multiplication of matrix and number, 270

multiplication of matrix and vector,

271–272

multiplication of two matrices, 270–271

overview, 269

subtraction, 270

overview, 265

systems of first order linear

nonhomogeneous equations

assuming correct form of particular

solution, 289

crunching numbers, 290–292

overview, 288

winding up work, 292

systems of first order linear homogeneous

differential equations

coming up with eigenvectors, 286–287

finding eigenvalues, 285–286

getting right matrix form, 285

overview, 283

summing up solution, 287–288

understanding basics, 284–285

Midnight Tutor’s Video Tutorial, 319

Ohio State University Physics

Department’s introduction to

differential equations, 319

overview, 317

Paul’s Online Math Notes, 319

S.O.S. Math, 319

University of Surrey Tutorial, 320

• T •

• U •

Taylor expansion, 215

Taylor series, 195–196

Technical Stuff icon, 4

Teknomo, Kardi, 318

Tip icon, 4

undetermined coefficients, method of

finding particular solutions with

overview, 127

when g(x) is combination of sines and

cosines, 131–133

n

t eat function, 244





336

**Differential Equations For Dummies**

undetermined coefficients, method of

(continued)

• W •

when g(x) is in form of erx, 127–128

when g(x) is polynomial of order n,

128–131

when g(x) is product of two different

forms, 133–134

for higher order linear nonhomogeneous

differential equations

overview, 174–175

when g(x) is combination of sines and

cosines, 182–185

when g(x) is in form erx, 176–179

when g(x) is polynomial of order n,

179–182

Warning icon, 4

Wronski, Jósef Maria Hoëné, 119

Wronskian

arrays and determinants, 117–119

formal theorem, 119–122

and higher order linear homogeneous

differential equation solutions, 156

overview, 117

and variation of parameters method,

142–143

• X •

University of Surrey Tutorial, 320

x, raising to power of n, 12

• V •

vectors, assembling into one matrix,

278–279

Visual Differential Equation Solving

Applet, 323





Notes

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_





Notes

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_





**BUSINESS, CAREERS & PERSONAL FINANCE**

**Also available:**

Business Plans Kit For Dummies

0-7645-9794-9

Economics For Dummies

0-7645-5726-2

Grant Writing For Dummies

0-7645-8416-2

Home Buying For Dummies

0-7645-5331-3

Managing For Dummies

0-7645-1771-6

Marketing For Dummies

0-7645-5600-2

Personal Finance For Dummies

0-7645-2590-5\*

Resumes For Dummies

0-7645-5471-9

Selling For Dummies

0-7645-5363-1

Six Sigma For Dummies

0-7645-6798-5

Small Business Kit For Dummies

0-7645-5984-2

Starting an eBay Business For Dummies

0-7645-6924-4

Your Dream Career For Dummies

0-7645-9795-7

0-7645-9847-3

0-7645-2431-3

**HOME & BUSINESS COMPUTER BASICS**

**Also available:**

Cleaning Windows Vista For Dummies

0-471-78293-9

Excel 2007 For Dummies

0-470-03737-7

Mac OS X Tiger For Dummies

0-7645-7675-5

Outlook 2007 For Dummies

0-470-03830-6

PCs For Dummies

0-7645-8958-X

Salesforce.com For Dummies

0-470-04893-X

Upgrading & Fixing Laptops For

Dummies

0-7645-8959-8

MacBook For Dummies

0-470-04859-X

Word 2007 For Dummies

0-470-03658-3

Macs For Dummies

0-470-04849-2

0-470-05432-8

0-471-75421-8

Office 2007 For Dummies

0-470-00923-3

Quicken 2007 For Dummies

0-470-04600-7

**FOOD, HOME, GARDEN, HOBBIES, MUSIC & PETS**

**Also available:**

Horses For Dummies

0-7645-9797-3

Jewelry Making & Beading

For Dummies

Candy Making For Dummies

0-7645-9734-5

Card Games For Dummies

0-7645-9910-0

0-7645-2571-9

Orchids For Dummies

0-7645-6759-4

Crocheting For Dummies

0-7645-4151-X

Puppies For Dummies

0-7645-5255-4

Dog Training For Dummies

0-7645-8418-9

Rock Guitar For Dummies

0-7645-5356-9

Sewing For Dummies

0-7645-6847-7

Healthy Carb Cookbook For Dummies

0-7645-8476-6

Home Maintenance For Dummies

0-7645-5215-5

0-7645-8404-9

0-7645-9904-6

Singing For Dummies

0-7645-2475-5

**INTERNET & DIGITAL MEDIA**

**Also available:**

Blogging For Dummies

0-471-77084-1

Digital Photography For Dummies

0-7645-9802-3

Digital Photography All-in-One Desk

Reference For Dummies

0-470-03743-1

Home Entertainment PCs For Dummies

0-470-05523-5

MySpace For Dummies

0-470-09529-6

Search Engine Optimization For

Dummies

0-471-97998-8

Skype For Dummies

0-470-04891-3

The Internet For Dummies

0-7645-8996-2

Digital SLR Cameras and Photography

For Dummies

0-7645-9803-1

0-470-04529-9

0-470-04894-8

eBay Business All-in-One Desk

Reference For Dummies

0-7645-8438-3

Wiring Your Digital Home For Dummies

0-471-91830-X

**\* Separate Canadian edition also available**

† **Separate U.K. edition also available**

HDTV For Dummies

0-470-09673-X

Available wherever books are sold. For more information or to order direct: U.S. customers visit www.dummies.com or call 1-877-762-2974.

U.K. customers visit www.wileyeurope.com or call 0800 243407. Canadian customers visit www.wiley.ca or call 1-800-567-4797.





**SPORTS, FITNESS, PARENTING, RELIGION & SPIRITUALITY**

**Also available:**

Pregnancy For Dummies

0-7645-4483-7 †

Catholicism For Dummies

0-7645-5391-7

Exercise Balls For Dummies

0-7645-5623-1

Fitness For Dummies

0-7645-7851-0

Football For Dummies

0-7645-3936-1

Judaism For Dummies

0-7645-5299-6

Potty Training For Dummies

0-7645-5417-4

Ten Minute Tone-Ups For Dummies

0-7645-7207-5

NASCAR For Dummies

0-7645-7681-X

Religion For Dummies

0-7645-5264-3

Soccer For Dummies

0-7645-5229-5

Women in the Bible For Dummies

0-7645-8475-8

0-471-76871-5

0-7645-7841-3

Buddhism For Dummies

0-7645-5359-3

**TRAVEL**

**Also available:**

Alaska For Dummies

0-7645-7746-8

Cruise Vacations For Dummies

0-7645-6941-4

England For Dummies

0-7645-4276-1

Europe For Dummies

0-7645-7529-5

Germany For Dummies

0-7645-7823-5

Hawaii For Dummies

0-7645-7402-7

Italy For Dummies

0-7645-7386-1

Las Vegas For Dummies

0-7645-7382-9

London For Dummies

0-7645-4277-X

Paris For Dummies

0-7645-7630-5

RV Vacations For Dummies

0-7645-4442-X

Walt Disney World & Orlando

For Dummies

0-7645-7749-2

0-7645-6945-7

0-7645-9660-8

**GRAPHICS, DESIGN & WEB DEVELOPMENT**

**Also available:**

3D Game Animation For Dummies

0-7645-8789-7

AutoCAD 2006 For Dummies

0-7645-8925-3

Building a Web Site For Dummies

0-7645-7144-3

InDesign CS2 For Dummies

0-7645-9572-5

Macromedia Flash 8 For Dummies

0-7645-9691-8

Photoshop CS2 and Digital

Photography For Dummies

0-7645-9580-6

Photoshop Elements 4 For Dummies

0-471-77483-9

Creating Web Pages For Dummies

0-470-08030-2

Syndicating Web Sites with RSS Feeds

For Dummies

0-7645-8848-6

Creating Web Pages All-in-One Desk

Reference For Dummies

0-7645-4345-8

0-7645-8815-X

0-7645-9571-7

Yahoo! SiteBuilder For Dummies

0-7645-9800-7

Dreamweaver 8 For Dummies

0-7645-9649-7

**NETWORKING, SECURITY, PROGRAMMING & DATABASES**

**Also available:**

Microsoft SQL Server 2005 For Dummies

0-7645-7755-7

Access 2007 For Dummies

0-470-04612-0

ASP.NET 2 For Dummies

0-7645-7907-X

Networking All-in-One Desk Reference

For Dummies

0-7645-9939-9

Preventing Identity Theft For Dummies

0-7645-7336-5

C# 2005 For Dummies

0-7645-9704-3

Telecom For Dummies

0-471-77085-X

Hacking For Dummies

0-470-05235-X

Visual Studio 2005 All-in-One Desk

Reference For Dummies

0-7645-9775-2

XML For Dummies

0-7645-8845-1

Hacking Wireless Networks

For Dummies

0-7645-9730-2

Java For Dummies

0-470-08716-1

0-7645-7728-X

0-471-74940-0





**HEALTH & SELF-HELP**

**Also available:**

Bipolar Disorder For Dummies

0-7645-8451-0

Chemotherapy and Radiation

For Dummies

0-7645-7832-4

Fibromyalgia For Dummies

0-7645-5441-7

Low-Calorie Dieting For Dummies

0-7645-9905-4

Meditation For Dummies

0-471-77774-9

Controlling Cholesterol For Dummies

0-7645-5440-9

Osteoporosis For Dummies

0-7645-7621-6

Diabetes For Dummies

0-7645-6820-5\* †

Overcoming Anxiety For Dummies

0-7645-5447-6

Divorce For Dummies

0-7645-8417-0 †

Reiki For Dummies

0-7645-9907-0

0-7645-8450-2

0-7645-4149-8

Stress Management For Dummies

0-7645-5144-2

**EDUCATION, HISTORY, REFERENCE & TEST PREPARATION**

**Also available:**

Freemasons For Dummies

0-7645-9796-5

The ACT For Dummies

0-7645-9652-7

Algebra For Dummies

0-7645-5325-9

Algebra Workbook For Dummies

0-7645-8467-7

Astronomy For Dummies

0-7645-8465-0

Calculus For Dummies

0-7645-2498-4

Chemistry For Dummies

0-7645-5430-1

Forensics For Dummies

0-7645-5580-4

French For Dummies

0-7645-5193-0

Geometry For Dummies

0-7645-5324-0

Organic Chemistry I For Dummies

0-7645-6902-3

The SAT I For Dummies

0-7645-7193-1

Spanish For Dummies

0-7645-5194-9

Statistics For Dummies

0-7645-5423-9

0-7645-8381-6

0-7645-9554-7

**Get smart @ dummies.com®**

**• Find a full list of Dummies titles**

**• Look into loads of FREE on-site articles**

**• Sign up for FREE eTips e-mailed to you weekly**

**• See what other products carry the Dummies name**

**• Shop directly from the Dummies bookstore**

**• Enter to win new prizes every month!**

**\* Separate Canadian edition also available**

† **Separate U.K. edition also available**

Available wherever books are sold. For more information or to order direct: U.S. customers visit www.dummies.com or call 1-877-762-2974.

U.K. customers visit www.wileyeurope.com or call 0800 243407. Canadian customers visit www.wiley.ca or call 1-800-567-4797.





**Instructional DVDs • Music Compilations**

**Games & Novelties • Culinary Kits**

**Crafts & Sewing Patterns**

**Home Improvement/DIY Kits • and more!**

**Check out the Dummies Specialty Shop at www.dummies.com for more information!**

